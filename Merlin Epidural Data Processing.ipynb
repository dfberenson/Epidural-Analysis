{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkobyQHnHmfr"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1510,
     "status": "ok",
     "timestamp": 1736530922442,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "aEvYxZF4wEa5"
   },
   "outputs": [],
   "source": [
    "# prompt: Import libraries and open CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import modules.testing as testing\n",
    "import modules.data_cleaning_utils as dcu\n",
    "from importlib import reload\n",
    "\n",
    "# my_computer_fpath = \"C:\\\\Users\\\\dfber\\\\OneDrive - Mass General Brigham\\\\Epidural project\\\\Data\\\\\"\n",
    "my_computer_fpath = \"C:\\\\Users\\\\User\\\\OneDrive - Mass General Brigham\\\\Epidural project\\\\Data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from October Merlin pull\n",
    "file_path = my_computer_fpath + \"e26f9ccc-68a4-42b4-9d0d-508a83026a1c.csv\"\n",
    "delivery_datetime_is_incorrect = True\n",
    "procedure_datetime_is_incorrect = True\n",
    "\n",
    "# # Data from January Merin pull\n",
    "# file_path = my_computer_fpath + \"befa2320-c0e0-476c-b66c-7fd2fb90179e.csv\"\n",
    "delivery_datetime_is_incorrect = False\n",
    "procedure_datetime_is_incorrect = True\n",
    "\n",
    "raw_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dcu)\n",
    "df = raw_df.copy()\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLFyVswb3COk"
   },
   "source": [
    "# Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "anes_procedure_cols: list = [\n",
    "    'anes_procedure_type_2253', \n",
    "    'anes_procedure_start_dts_2254', \n",
    "    'anes_procedure_anesthesiologist_2255', \n",
    "    'anes_procedure_resident_2256', \n",
    "    'anes_procedure_pt_position_2257', \n",
    "    'anes_procedure_approach_2258', \n",
    "    'anes_procedure_location_2259', \n",
    "    'anes_procedure_note_id_2260', \n",
    "    'anes_procedure_dos_dts_2261', \n",
    "    'anes_procedure_dpe_2262', \n",
    "    'anes_procedure_epidural_needle_2263', \n",
    "    'anes_procedure_epidural_needle_gauge_2264', \n",
    "    'anes_procedure_lor_depth_2265', \n",
    "    'anes_procedure_catheter_depth_2266', \n",
    "    'anes_procedure_spinal_needle_type_2267', \n",
    "    'anes_procedure_spinal_needle_gauge_2268', \n",
    "    'anes_procedure_spinal_needle_length_2269', \n",
    "    'anes_procedure_paresthesias_2270', \n",
    "    'anes_procedure_note_text_2271',\n",
    "    'anes_procedure_encounter_id_2273'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode |-separated notes\n",
    "df = dcu.explode_separated_procedure_notes(df, anes_procedure_cols=anes_procedure_cols, delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of procedures by type\n",
    "# Note that other procedure types, including Blood Patch but also A-lines,\n",
    "# nerve blocks, and POCUS orders, are currently parsed by Merlin to NaN\n",
    "df['anes_procedure_type_2253'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in RAW info\n",
    "# This is needed at the moment to get the NotePurposeDSC (to help eliminate near-duplicate notes)\n",
    "# and also to RegEx the Number of Attempts\n",
    "\n",
    "raw_info_fpath = my_computer_fpath + \"Full Identified raw anesthesia_procedure_notes.csv\"\n",
    "df = dcu.add_raw_info(df, raw_info_fpath, processed_note_id_col = 'anes_procedure_note_id_2260', raw_info_cols = ['NotePurposeDSC','NoteTXT'])\n",
    "df = dcu.regex_note_text(df, desired_col = 'number_of_neuraxial_attempts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ISNBfVtIQUV"
   },
   "source": [
    "## Handle datetime issues\n",
    "\n",
    "Bug: Merlin is bringing anes_procedure_dos_dts_2261 as Eastern times when in fact they are UTC. I resolve this by editing the raw strings before conversion to datetime objects.\n",
    "\n",
    "Bug: The same WAS true for delivery_time before it was corrected in Merlin in January. I resolve this by editing the raw strings before conversion to datetime objects.\n",
    "\n",
    "Bug: Because delivery_date is stored separately from delivery_time, if the UTC change causes the time to go to the next day, this is NOT reflected in the updated delivery_date. This was also fixed in Merlin in January.\n",
    "\n",
    "Bug: Merlin ignores AM/PM in anes_procedure_start_dts_2254 and assumes all entries are AM. I resolve this (for now) by ignoring these written start times and just using dos_dts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validated times:\n",
    "https://partnershealthcare-my.sharepoint.com/:x:/r/personal/dberenson_bwh_harvard_edu/_layouts/15/Doc.aspx?sourcedoc=%7BD674A3E1-815E-46B8-9AA4-16558C09411A%7D&file=Manually%20Verified%20Catheters.xlsx&action=default&mobileredirect=true&wdOrigin=OUTLOOK-METAOS.FILEBROWSER.FILES-FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['anes_procedure_note_id_2260'] == '2981389717',['delivery_date','delivery_time','anes_procedure_start_dts_2254','anes_procedure_dos_dts_2261']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "if delivery_datetime_is_incorrect:\n",
    "    df = dcu.fix_delivery_datetime(df)\n",
    "else:\n",
    "    df = dcu.add_delivery_datetime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['maternal_dob'] = pd.to_datetime(df['maternal_dob_2043'],utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "if procedure_datetime_is_incorrect:\n",
    "    df = dcu.fix_procedure_dos_datetime(df)\n",
    "else:\n",
    "    df['dos_dts'] = pd.to_datetime(df['anes_procedure_dos_dts_2261'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1736530972209,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "59dC3WB-ZH8-"
   },
   "outputs": [],
   "source": [
    "df['start_dts'] = pd.to_datetime(df['anes_procedure_start_dts_2254'],format='mixed',utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1736530972393,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "giGm_VZXdG5i",
    "outputId": "eec08e3c-c2d3-494f-ccb7-301cd698e376"
   },
   "outputs": [],
   "source": [
    "# Extract the time part of the 'start_dts' column to check whether it covers all 24 h or only 12 h due to AM/PM bug\n",
    "df[df['start_dts'].notna()]['start_dts'].dt.time.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736530972394,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "ohVRiD_RRohx"
   },
   "outputs": [],
   "source": [
    "# This code has been changed to avoid the AM/PM bug\n",
    "\n",
    "# df['best_timestamp'] = df['start_dts'].fillna(df['dos_dts'])\n",
    "df['best_timestamp'] = df['dos_dts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "anes_procedure_cols.extend(['best_timestamp', 'dos_dts', 'start_dts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JPfIBsGQjpd"
   },
   "source": [
    "## Handle near-duplicate notes\n",
    "\n",
    "There is also a column \"NotePurposeDSC\" in the raw EDW data that can be \"ADDENDUM\" or \"NORMAL\" or blank. When there are duplicate notes, the first one will be blank and subsequent ones will be ADDENDUM. I use this fact upstream and delete all the ones that are blank.\n",
    "\n",
    "Then, I go through and delete other notes that appear to be duplicates. The majority of these are apparently due to TWINS, where a single NoteID appears twice in the dataset due to how Merlin generates it birthwise rather than momwise. However, it CANNOT be done by just eliminating non-unique NoteIDs, as \"double-notes\" (which appear in Epic as one note that has two procedure descriptions concatenated together) also have the same NoteID. Instead, I drop rows where both the NoteID and the ProcedureType match.\n",
    "\n",
    " Instead, I look within each encounter and check if there are two notes that are the same procedure type and within a short minute_offset of each other. If so, I delete the less-complete note.\n",
    "\n",
    "IMPORTANT: It turns out to be the case that there are sometimes, genuinely in Epic, two procedures done within only a few mins of each other. I AM CURRENTLY WORKING ON FIGURING OUT WHAT IS GOING ON WITH THESE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop near-duplicate notes with blank NotePurposeDSC\n",
    "df = df.dropna(subset=['NotePurposeDSC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcu.print_encounter(df,'3128029077') # double note\n",
    "dcu.print_encounter(df,'3451276171') # known near-duplicate note (that is genuinely duplicated (actually, triplicated) in Epic)\n",
    "dcu.print_encounter(df,'3188356337') # known near-duplicate note (that is duplicated due to twins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['anes_procedure_type_2253','anes_procedure_note_id_2260'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcu.print_encounter(df,'3128029077') # double note\n",
    "dcu.print_encounter(df,'3451276171') # known near-duplicate note (that is genuinely duplicated (actually, triplicated) in Epic)\n",
    "dcu.print_encounter(df,'3188356337') # known near-duplicate note (that is duplicated due to twins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dcu)\n",
    "df = saved_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dcu.label_and_drop_worse_versions_of_duplicates(df, anes_procedure_cols, minute_offset=1, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['is_worse_near_duplicate'] == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When minute_offset = 60, there are 564 near-duplicates identified.\\\n",
    "When minute_offset = 10, there are 175 near-duplicates identified.\\\n",
    "When minute_offset = 2, there are 97 near-duplicates identified.\\\n",
    "When minute_offset = 1, there are 63 near-duplicates identified.\\\n",
    "When minute_offset = 0, there are 12 near-duplicates identified.\\\n",
    "Looking at just a couple of the short minute_offsets, these commonly represent immediate replacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['is_worse_near_duplicate'] == 1].sort_values('time_gap').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcu.print_encounter(df,'3128029077') # double note\n",
    "dcu.print_encounter(df,'3451276171') # known near-duplicate note (that is genuinely duplicated (actually, triplicated) in Epic)\n",
    "dcu.print_encounter(df,'3188356337') # known near-duplicate note (that is duplicated due to twins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = df.loc[df['anes_procedure_encounter_id_2273'] == '3451276171']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = enc.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_idx = indices[0]\n",
    "base_row = enc.loc[base_idx]\n",
    "has_near_duplicate = 0\n",
    "near_duplicates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_idx = indices[1]\n",
    "compare_row = enc.loc[compare_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcu.check_if_near_duplicate(base_row, compare_row, compare_cols=['anes_procedure_type_2253'], minute_offset = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_near_duplicate = 1\n",
    "near_duplicates.append(compare_row['anes_procedure_note_id_2260'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.at[base_idx, 'has_near_duplicate'] = has_near_duplicate\n",
    "enc.at[base_idx, 'near_duplicate_note_ids'] = str(sorted(near_duplicates))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(dcu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcu.label_near_duplicate_notes(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcu.check_if_near_duplicate(df.loc[30085],df.loc[30086],compare_cols=['anes_procedure_type_2253'], minute_offset = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtFesSAK1wsT"
   },
   "source": [
    "## Address cases where an epidural note followed by a spinal note is actually a planned CSE, not a failed catheter. Also address what 'epidural/intrathecal' really means.\n",
    "\n",
    "Secret CSEs are spinal and epidural within 5 mins\n",
    "\n",
    "Epidural/intrathecal notes are declared epidural unless ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736531157211,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "oAlkUSFd15mb"
   },
   "outputs": [],
   "source": [
    "# Functions to label secret_CSE procedures\n",
    "\n",
    "# Compare two rows and return True if exactly one is an epidural, exactly one is a spinal,\n",
    "# and if their timestamps are within minute_offset\n",
    "def check_if_secret_CSE(row1, row2, minute_offset):\n",
    "  if abs(row1['best_timestamp'] - row2['best_timestamp']) < pd.Timedelta(minutes=minute_offset):\n",
    "    if row1['anes_procedure_type_2253'] == 'epidural/intrathecal' or row1['anes_procedure_type_2253'] == 'epidural':\n",
    "      if row2['anes_procedure_type_2253'] == 'spinal':\n",
    "        return True\n",
    "    if row2['anes_procedure_type_2253'] == 'epidural/intrathecal' or row2['anes_procedure_type_2253'] == 'epidural':\n",
    "      if row1['anes_procedure_type_2253'] == 'spinal':\n",
    "        return True\n",
    "  return False\n",
    "\n",
    "# Label secret_CSE notes within an encounter using the check_if_secret_CSE function\n",
    "def label_secret_CSE_notes(encounter):\n",
    "\n",
    "  indices = encounter.index.tolist()\n",
    "\n",
    "  for i in range(len(indices)):\n",
    "    base_idx = indices[i]\n",
    "    base_row = encounter.loc[base_idx]\n",
    "    is_secret_CSE = 0\n",
    "    secret_CSEs = [base_row['anes_procedure_note_id_2260']]\n",
    "\n",
    "    for j in range(len(indices)):\n",
    "      if i == j:\n",
    "        continue # don't identify self-duplicates\n",
    "      compare_idx = indices[j]\n",
    "      compare_row = encounter.loc[compare_idx]\n",
    "\n",
    "      if check_if_secret_CSE(base_row, compare_row, minute_offset = 5):\n",
    "        is_secret_CSE = 1\n",
    "        secret_CSEs.append(compare_row['anes_procedure_note_id_2260'])\n",
    "\n",
    "    encounter.at[base_idx, 'is_secret_CSE'] = is_secret_CSE\n",
    "    encounter.at[base_idx, 'secret_CSE_note_ids'] = str(sorted(secret_CSEs))\n",
    "\n",
    "  return encounter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105396,
     "status": "ok",
     "timestamp": 1736531262605,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "fUFcrD6XD55I",
    "outputId": "5ee4c703-2ed9-4c80-eeab-a4814c32ea2f"
   },
   "outputs": [],
   "source": [
    "# Label secret_CSE procedures\n",
    "# Takes ~2 mins\n",
    "\n",
    "df_anes_procedure_cols['is_secret_CSE'] = 0\n",
    "df_anes_procedure_cols['secret_CSE_note_ids'] = None\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(label_secret_CSE_notes, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "ZuMTbsM8FEyp",
    "outputId": "5c5dce82-576e-4a0e-924a-708fa1f9426b"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_secret_CSE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "eTslzEhqFQ0i",
    "outputId": "0fdc2f29-c26e-412e-cde0-1a23158a35ce"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols[df_anes_procedure_cols['is_secret_CSE'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "cVHEDdpkITEk"
   },
   "outputs": [],
   "source": [
    "# Eliminate the separately-documented spinals that are really part of CSEs\n",
    "\n",
    "# Delete rows where procedure_type is spinal and is_secret_CSE is true\n",
    "df_anes_procedure_cols = df_anes_procedure_cols[~((df_anes_procedure_cols['anes_procedure_type_2253'] == 'spinal') & (df_anes_procedure_cols['is_secret_CSE'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "1APs69qNJtY2",
    "outputId": "0e5eb7f6-c9ed-479a-99c5-414e37d3098c"
   },
   "outputs": [],
   "source": [
    "# Label true intrathecal catheters\n",
    "# NOTE: DOES NOT YET RECLASSIFY EPIDURAL/INTRATHECALS BY CSF ASPIRATION OR ANY OTHER METHOD\n",
    "\n",
    "df_anes_procedure_cols['is_intrathecal_catheter'] = (df_anes_procedure_cols['anes_procedure_type_2253'] == 'intrathecal').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1736531262822,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "_3REoY6SKHwu",
    "outputId": "3f78d9e6-2e30-4187-b04b-5437fc7a5dd4"
   },
   "outputs": [],
   "source": [
    "# prompt: label true_procedure_type by reclassifying based on is_secret_CSE and is_intrathecal_catheter\n",
    "\n",
    "# Create the 'true_procedure_type' column based on the conditions\n",
    "df_anes_procedure_cols['true_procedure_type'] = np.where(\n",
    "    df_anes_procedure_cols['is_secret_CSE'] == True,'cse',\n",
    "    df_anes_procedure_cols['anes_procedure_type_2253'])\n",
    "\n",
    "# Update 'true_procedure_type' based on 'is_intrathecal_catheter'\n",
    "df_anes_procedure_cols.loc[\n",
    "    (df_anes_procedure_cols['true_procedure_type'].isin(['epidural/intrathecal', 'intrathecal'])) &\n",
    "    (df_anes_procedure_cols['is_intrathecal_catheter'] == True),\n",
    "    'true_procedure_type'] = 'intrathecal'\n",
    "\n",
    "df_anes_procedure_cols.loc[\n",
    "    (df_anes_procedure_cols['true_procedure_type'] == 'epidural/intrathecal') &\n",
    "    (df_anes_procedure_cols['is_intrathecal_catheter'] == False),\n",
    "    'true_procedure_type'] = 'epidural'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anes_procedure_type_2253'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['true_procedure_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1736531262822,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "xMX_LrGBJUg9",
    "outputId": "448f07ea-ef57-4287-8afb-f2cc33f9a2dc"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nlc5uOLquoP_"
   },
   "source": [
    "# Classify failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1736531262823,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "VglLLyHlvMy0"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_neuraxial_catheter'] = (df_anes_procedure_cols['true_procedure_type'].isin(['cse', 'epidural', 'intrathecal'])).astype(int)\n",
    "df_anes_procedure_cols['is_spinal'] = (df_anes_procedure_cols['true_procedure_type'] == 'spinal').astype(int)\n",
    "df_anes_procedure_cols['is_airway'] = (df_anes_procedure_cols['true_procedure_type'] == 'airway').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "DmRHrn9durRv"
   },
   "outputs": [],
   "source": [
    "# Vectorized method to classify as successes or failures\n",
    "# takes ~10 mins\n",
    "\n",
    "def classify_encounter_failures(encounter):\n",
    "\n",
    "    # Identify rows where 'is_neuraxial_catheter' == 1\n",
    "    neuraxial_rows = encounter[encounter['is_neuraxial_catheter'] == 1]\n",
    "\n",
    "    # If no neuraxial catheter procedures, return encounter as is\n",
    "    if neuraxial_rows.empty:\n",
    "        return encounter\n",
    "\n",
    "    # Create a mask for failure-defining events within the encounter\n",
    "    # Failure-defining events are neuraxial catheters, spinals, and airways\n",
    "    failure_defining_event_mask = encounter[['is_neuraxial_catheter','is_spinal','is_airway']].any(axis=1)\n",
    "\n",
    "    # Get the indices of events\n",
    "    failure_defining_event_indices = encounter.index[failure_defining_event_mask]\n",
    "\n",
    "    # Iterate over neuraxial catheter rows\n",
    "    for idx in neuraxial_rows.index:\n",
    "        current_time = encounter.at[idx, 'best_timestamp']\n",
    "\n",
    "        # Find subsequent events\n",
    "        # This relies on correct ordering by best_timestamp\n",
    "        subsequent_failure_defining_events = encounter.loc[failure_defining_event_indices]\n",
    "        subsequent_failure_defining_events = subsequent_failure_defining_events[subsequent_failure_defining_events['best_timestamp'] > current_time]\n",
    "\n",
    "        # Initialize flags\n",
    "        has_subsequent_neuraxial_catheter = 0\n",
    "        has_subsequent_spinal = 0\n",
    "        has_subsequent_airway = 0\n",
    "        failed_catheter = 0\n",
    "        subsequent_proof_of_failure_note_id = None\n",
    "\n",
    "        # Check for subsequent procedures\n",
    "        if not subsequent_failure_defining_events.empty:\n",
    "            # Update flags based on any occurrence in subsequent events\n",
    "            has_subsequent_neuraxial_catheter = int((subsequent_failure_defining_events['is_neuraxial_catheter'] == 1).any())\n",
    "            has_subsequent_spinal = int((subsequent_failure_defining_events['is_spinal'] == 1).any())\n",
    "            has_subsequent_airway = int((subsequent_failure_defining_events['is_airway'] == 1).any())\n",
    "            failed_catheter = int(has_subsequent_neuraxial_catheter or has_subsequent_spinal or has_subsequent_airway)\n",
    "            subsequent_proof_of_failure_note_id = subsequent_failure_defining_events['anes_procedure_note_id_2260'].tolist()\n",
    "\n",
    "            encounter.at[idx, 'has_subsequent_neuraxial_catheter'] = has_subsequent_neuraxial_catheter\n",
    "            encounter.at[idx, 'has_subsequent_spinal'] = has_subsequent_spinal\n",
    "            encounter.at[idx, 'has_subsequent_airway'] = has_subsequent_airway\n",
    "            encounter.at[idx, 'failed_catheter'] = failed_catheter\n",
    "            encounter.at[idx, 'subsequent_proof_of_failure_note_id'] = str(subsequent_proof_of_failure_note_id)\n",
    "\n",
    "    return encounter\n",
    "\n",
    "df_anes_procedure_cols['has_subsequent_neuraxial_catheter'] = 0\n",
    "df_anes_procedure_cols['has_subsequent_spinal'] = 0\n",
    "df_anes_procedure_cols['has_subsequent_airway'] = 0\n",
    "df_anes_procedure_cols['failed_catheter'] = 0\n",
    "df_anes_procedure_cols['subsequent_proof_of_failure_note_id'] = None\n",
    "\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(classify_encounter_failures, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY63Lf9aV-cZ"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuild df by merging with df_anes_procedure_cols\n",
    "\n",
    "Note that rows have been eliminated from df_anes_procedure_cols in two steps: as is_worse_near_duplicate, and as is_secret_cse (note that only the spinal half of the is_secret_cse cases are removed since the epidural half become the CSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "gzPV1CsfnsJD"
   },
   "outputs": [],
   "source": [
    "# prompt: concatenate new columns from df_anes_procedure_cols into df. only bring the new columns, leave behind the matching ones. Select the new columns via code.\n",
    "\n",
    "# Identify new columns in df_anes_procedure_cols that are not in df\n",
    "new_cols = [col for col in df_anes_procedure_cols.columns if col not in df.columns]\n",
    "\n",
    "# Merge df with df_anes_procedure_cols on the index, only keeping rows that exist in both\n",
    "df = pd.merge(df, df_anes_procedure_cols[new_cols], left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "WqfMMOV8Do1r"
   },
   "outputs": [],
   "source": [
    "df['is_neuraxial_catheter'] = df['is_neuraxial_catheter'] == 1\n",
    "df['failed_catheter'] = df['failed_catheter'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns to move 'is_neuraxial_catheter' and 'failed_catheter' to the front\n",
    "cols = ['is_neuraxial_catheter', 'failed_catheter'] + [col for col in df.columns if col not in ['is_neuraxial_catheter', 'failed_catheter']]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "likLZC_lwNhJ"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCec8U6S0QeF"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known double-note\n",
    "known_double_note = df.loc[df['anes_procedure_note_id_2260'] == '1188076153']\n",
    "known_double_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP0RDHaa0rmz"
   },
   "outputs": [],
   "source": [
    "df[df['failed_catheter'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "In0JgcPXBgtB"
   },
   "outputs": [],
   "source": [
    "known_failed_catheter_encounter_ids = ['3259099621','3081317750', '3081399139', '3081675427', '3081686082', '3081711691', '3081729928', '3081884584', '3081893356', '3082275619', '3082349091']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Xawf8qwCPXj"
   },
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'].isin(known_failed_catheter_encounter_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPBvuAV6NRli"
   },
   "source": [
    "# Additional Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count prior failed neuraxials in this encounter and failed and total across all encounters\n",
    "\n",
    "Takes ~4 mins for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='best_timestamp', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are separate functions so that they can be applied to the DataFrame in a vectorized manner without needing to take the new_column_name as an argument,\n",
    "# which doesn't work well with the .apply() method\n",
    "\n",
    "def count_prior_failed_catheters_this_enc(group):\n",
    "    group['prior_failed_catheters_this_enc'] = (group['failed_catheter'].cumsum() - group['failed_catheter']).astype(float)\n",
    "    return group\n",
    "\n",
    "def count_prior_failed_catheters_all_enc(group):\n",
    "    group['prior_failed_catheters_all_enc'] = (group['failed_catheter'].cumsum() - group['failed_catheter']).astype(float)\n",
    "    return group\n",
    "\n",
    "def count_prior_all_catheters_all_enc(group):\n",
    "    group['prior_all_catheters_all_enc'] = (group['is_neuraxial_catheter'].cumsum() - group['is_neuraxial_catheter']).astype(float)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('anes_procedure_encounter_id_2273').apply(count_prior_failed_catheters_this_enc, include_groups = False)\n",
    "df = df.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('epic_pmrn').apply(count_prior_failed_catheters_all_enc, include_groups = False)\n",
    "df = df.reset_index('epic_pmrn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('epic_pmrn').apply(count_prior_all_catheters_all_enc, include_groups = False)\n",
    "df = df.reset_index('epic_pmrn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prior_failed_catheters_prev_enc'] = df['prior_failed_catheters_all_enc'] - df['prior_failed_catheters_this_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'] == '3258959083']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'] == '3147096491']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'] == '3227352323']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "757vQkZucKbN"
   },
   "source": [
    "## Handle timeseries data (e.g., pain scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VUtFAxcFdliC"
   },
   "outputs": [],
   "source": [
    "# Extracts the pain scores prior to the timestamp\n",
    "# Takes ~ 1 minute\n",
    "def get_pain_scores_prior_to_timestamp(row, best_timestamp_col=\"best_timestamp\"):\n",
    "    \"\"\"\n",
    "    Extract all pain scores that have timestamp < row[best_timestamp_col].\n",
    "\n",
    "    row: a single row of your DataFrame (a pd.Series)\n",
    "    best_timestamp_col: name of the column in your DataFrame that contains\n",
    "                       the 'best_timestamp' to compare against\n",
    "\n",
    "    Returns a list of 'prior' scores or NaN if none exist.\n",
    "    \"\"\"\n",
    "    # Extract the raw strings\n",
    "    times_str = row[\"timeseries_intrapartum_pain_score_datetime_2242\"]\n",
    "    scores_str = row[\"timeseries_intrapartum_pain_score_2242\"]\n",
    "\n",
    "    # If either is missing, return NaN\n",
    "    if pd.isna(times_str) or pd.isna(scores_str):\n",
    "        return np.nan\n",
    "\n",
    "    # Convert to lists\n",
    "    times_list = times_str.split(\"|\")\n",
    "    scores_list = scores_str.split(\"|\")\n",
    "\n",
    "    # Safely convert both times and best_timestamp to datetime\n",
    "    try:\n",
    "        times_dt = pd.to_datetime(times_list)\n",
    "        # This assumes your row also has a column called best_timestamp_col\n",
    "        best_dt = pd.to_datetime(row[best_timestamp_col])\n",
    "    except:\n",
    "        # If conversion fails, return NaN\n",
    "        return np.nan\n",
    "\n",
    "    # Filter out all scores whose timestamp is strictly less than best_timestamp\n",
    "    prior_scores = []\n",
    "    for t, s in zip(times_dt, scores_list):\n",
    "        if t < best_dt:\n",
    "            prior_scores.append(float(s))\n",
    "\n",
    "    # If no scores remain, return NaN, else return them joined or as list\n",
    "    return prior_scores if prior_scores else np.nan\n",
    "\n",
    "df['prior_pain_scores'] = df.apply(get_pain_scores_prior_to_timestamp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Dto2g0HfeCuC"
   },
   "outputs": [],
   "source": [
    "df[\"prior_pain_scores_max\"] = df[\"prior_pain_scores\"].apply(\n",
    "    lambda scores: max(map(float, scores)) if isinstance(scores, list) and scores else np.nan) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "x6LMgIHofOYD"
   },
   "outputs": [],
   "source": [
    "df['prior_pain_scores_max'].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3n9mBjG2mKn"
   },
   "source": [
    "## Clean DPE and LOR_Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "18FwO5sbNj3r"
   },
   "outputs": [],
   "source": [
    "# make 'dpe' True/False\n",
    "df['dpe'] = df['anes_procedure_dpe_2262'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['true_procedure_type_incl_dpe'] = df['true_procedure_type']\n",
    "df.loc[df['dpe'] == True, 'true_procedure_type_incl_dpe'] = 'dpe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7ldb0bDxNTGo"
   },
   "outputs": [],
   "source": [
    "# make 'lor_depth' numeric\n",
    "df['lor_depth'] = df['anes_procedure_lor_depth_2265'].replace('', np.nan).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZuSyUaAeN4r1"
   },
   "outputs": [],
   "source": [
    "# Code to evaluate suspiciously high LORs\n",
    "# For these, if we divide LOR by 10, the the catheter is taped around 4-5 cm deeper\n",
    "# So most likely these suspiciously high LORs are missing decimal points\n",
    "high_LORs = df.sort_values(by='lor_depth',ascending=False).head(100)['lor_depth']\n",
    "print(high_LORs.to_list())\n",
    "plt.hist(high_LORs)\n",
    "\n",
    "print(df.sort_values(by='lor_depth',ascending=False).head(100)['anes_procedure_catheter_depth_2266'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7YS3I4MEN8OG"
   },
   "outputs": [],
   "source": [
    "# prompt: lor_depth = lor_depth / 10 if lor_depth > 20\n",
    "\n",
    "df['lor_depth'] = np.where(df['lor_depth'] > 20, df['lor_depth'] / 10, df['lor_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EALlbR6-OUaQ"
   },
   "outputs": [],
   "source": [
    "# Code to evaluate suspiciously high LORs\n",
    "high_LORs = df.sort_values(by='lor_depth',ascending=False).head(100)['lor_depth']\n",
    "print(high_LORs.to_list())\n",
    "plt.hist(high_LORs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjq02Q_U2ucI"
   },
   "source": [
    "## Make numerical columns numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "RH4BDg1__d1h"
   },
   "outputs": [],
   "source": [
    "# prompt: set these columns to dtype float: bmi_end_pregnancy_2044, maternal_weight_end_pregnancy_2045, maternal_height_2046,gravidity_2047,parity_2048\n",
    "\n",
    "# Convert specified columns to float dtype\n",
    "columns_to_convert = ['gestational_age_2052','bmi_end_pregnancy_2044', 'maternal_weight_end_pregnancy_2045', 'maternal_height_2046', 'gravidity_2047', 'parity_2048','baby_weight_2196','bmi_before_pregnancy_2161','secs_rom_thru_delivery_2197']\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "        except KeyError:\n",
    "            print(f\"Column '{col}' not found in the DataFrame.\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' not found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and plausibilify elapsed times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rom_thru_delivery_hours'] = df['secs_rom_thru_delivery_2197'] / 3600\n",
    "df['rom_thru_delivery_hours'].describe(percentiles=[0.01,0.05,0.25,0.5,0.75,0.95,0.98,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "gkTCwVcyOtX3"
   },
   "outputs": [],
   "source": [
    "# If ROM through Delivery is more than 30 days, assume erroneous and make it NaN\n",
    "df['rom_thru_delivery_hours'] = np.where(df['rom_thru_delivery_hours'] <= 30*24, df['rom_thru_delivery_hours'],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['maternal_age_years'] = (df['delivery_datetime'] - df['maternal_dob']).dt.days / 365.25\n",
    "df['maternal_age_years'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gestational_age_weeks'] = df['gestational_age_2052'] / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['placement_to_delivery_hours'] = (df['delivery_datetime'] - df['best_timestamp']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['true_procedure_type'] == 'epidural']['placement_to_delivery_hours'].describe(percentiles=[0.01,0.02,0.05,0.10,0.15,0.25,0.2,0.5,0.75,0.95,0.98,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['placement_to_delivery_hours'] = np.where((df['placement_to_delivery_hours'] > -1) & (df['placement_to_delivery_hours'] <= 7*24),\n",
    "                                             df['placement_to_delivery_hours'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['true_procedure_type'] == 'epidural']['placement_to_delivery_hours'].describe(percentiles=[0.01,0.02,0.05,0.10,0.15,0.25,0.2,0.5,0.75,0.95,0.98,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['placement_to_delivery_hours'].sort_values(ascending=True).head().index,:][['anes_procedure_note_id_2260','anes_procedure_type_2253','placement_to_delivery_hours','delivery_datetime','best_timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['placement_to_delivery_hours'].sort_values(ascending=False).head().index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analyses, procedures where many days elapse between placement and delivery are NOT labor analgesia procedures. They can be totally unrelated procedures like knee surgery, or obstetrical procedures like ECVs, or (rarely) analgesia for false labor. In the latter case, if labor does not progress and the patient returns to antepartum, the anesthesia encounter will termiante and a new encounter will be used for subsequent labor. In that case, an epidural placed in the second encounter will NOT prove failure of the first since it will have a different encounter_id.\n",
    "\n",
    "For these reasons, I eliminate rows where there is more than 7 days between placement and delivery.\n",
    "\n",
    "Due to the UTC bug discussed above, a true 1859 EPL followed by 1900 delivery would be translated to 2359 EPL AFTER 0000 delivery (without the delivery_date incrementing appropriately)\n",
    "\n",
    "A more thorough algorithm could look at the timing of Anesthesia Stop compared to delivery, and/or confirm that the title of the anesthesia encounter is Labor Epidural or Cesarean Section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['placement_to_delivery_hours']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include other limits on plausible data for each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rdMZOcI2xZH"
   },
   "source": [
    "## Handle proceduralist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "K44x6YG-9GCD"
   },
   "outputs": [],
   "source": [
    "# Function to regulate names\n",
    "def regulate_name(name):\n",
    "\n",
    "    # Remove degrees and titles\n",
    "    name = re.sub(r',?\\s*(md|do|mbbs|phd|ms|mba|mph|msc|crna)\\b', '', name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Split last name and first name if comma exists\n",
    "    if ',' in name:\n",
    "        last, first = name.split(',', 1)\n",
    "        name = f\"{first.strip()} {last.strip()}\"\n",
    "\n",
    "    # Remove extra spaces\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "    # Remove middle names\n",
    "    parts = name.split()\n",
    "    if len(parts) > 2 :\n",
    "      name = f\"{parts[0]} {parts[-1]}\"\n",
    "\n",
    "    # Capitalize each part of the name\n",
    "    name = name.title()\n",
    "\n",
    "    return name\n",
    "\n",
    "# Apply the function to regulate names\n",
    "df['Regulated_Anesthesiologist_Name'] = df['anes_procedure_anesthesiologist_2255'].dropna().apply(regulate_name)\n",
    "df['Regulated_Resident_Name'] = df['anes_procedure_resident_2256'].dropna().apply(regulate_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "oXOr9Udky9qK"
   },
   "outputs": [],
   "source": [
    "# prompt: set all blank Regulated_Anesthesiologist_Name and Regulated_Resident_Name to NaN\n",
    "\n",
    "df['Regulated_Anesthesiologist_Name'] = df['Regulated_Anesthesiologist_Name'].replace('', np.nan)\n",
    "df['Regulated_Resident_Name'] = df['Regulated_Resident_Name'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Lm5KJJXfZaPD"
   },
   "outputs": [],
   "source": [
    "# prompt: For each catheter, count how many (i.e., earlier best_timestamp) catheters were done by that provider (including the current one)\n",
    "\n",
    "df = df.sort_values('best_timestamp')\n",
    "\n",
    "df['current_anesthesiologist_catheter_count'] = (\n",
    "    df.groupby('Regulated_Anesthesiologist_Name')['is_neuraxial_catheter']\n",
    "      .cumsum()\n",
    ")\n",
    "\n",
    "df['current_resident_catheter_count'] = (\n",
    "    df.groupby('Regulated_Resident_Name')['is_neuraxial_catheter']\n",
    "      .cumsum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "czc7KflO5Laq"
   },
   "outputs": [],
   "source": [
    "df['highly_experienced_anesthesiologist'] = np.where(df['current_anesthesiologist_catheter_count'] > 500, 'yes',\n",
    "                                                    np.where(df['current_anesthesiologist_catheter_count'] <= 500, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "_Flgn1iczuHP"
   },
   "outputs": [],
   "source": [
    "df['moderately_experienced_anesthesiologist'] = np.where(df['current_anesthesiologist_catheter_count'] > 100, 'yes',\n",
    "                                                        np.where(df['current_anesthesiologist_catheter_count'] <= 100, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "EOo7CtAq5Y6X"
   },
   "outputs": [],
   "source": [
    "# prompt: set df['highly_experienced_resident'] to 1 if current_resident_catheter_count > 50, to 0 if <= 50, and to -1 if NaN\n",
    "\n",
    "df['highly_experienced_resident'] = np.where(df['current_resident_catheter_count'] > 50, 'yes',\n",
    "                                                    np.where(df['current_resident_catheter_count'] <= 50, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqbNsz2U26MN"
   },
   "source": [
    "## Feature engineering on categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "Cd-k3VRq4r1e"
   },
   "outputs": [],
   "source": [
    "df['has_scoliosis'] = df['icd_scoliosis_2053'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "tsUb1icS5IAj"
   },
   "outputs": [],
   "source": [
    "df['has_dorsalgia'] = df['icd_dorsalgia_2104'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "zKT4Wd683p7p"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column \"has_back_problems\" that is 1 where any of the following are True, else 0. Handle NaN.\n",
    "\n",
    "# Define the columns related to back problems\n",
    "back_problem_cols = [\n",
    "    'icd_scoliosis_2053',\n",
    "    'icd_spinal_fusion_2056',\n",
    "    'icd_congenital_deformity_spine_2059',\n",
    "    'icd_ra_and_sctds_2086',\n",
    "    'icd_kyphosis_and_lordosis_2089',\n",
    "    'icd_spinal_osteochondrosis_2092',\n",
    "    'icd_spondylopathies_and_deforming_dorsopathies_2095',\n",
    "    'icd_intervertebral_disc_disorders_2098',\n",
    "    'icd_ehlers_minus_danlos_2101',\n",
    "]\n",
    "\n",
    "# Note that spondyolopathies_and_deforming_dorsopathies are by far the biggest contributors\n",
    "\n",
    "# Create the 'has_back_problems' column\n",
    "df['has_back_problems'] = df[back_problem_cols].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "zLsKQUhDDGtI"
   },
   "outputs": [],
   "source": [
    "df['maternal_race'] = np.select(\n",
    "    [\n",
    "        df['maternal_race_2111'] == 'White',\n",
    "        df['maternal_race_2111'] == 'Asian',\n",
    "        df['maternal_race_2111'] == 'Black'\n",
    "    ],\n",
    "    [\n",
    "        'White',\n",
    "        'Asian',\n",
    "        'Black'\n",
    "    ],\n",
    "    default='Other/Unknown'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['maternal_ethnicity_2112'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for maternal ethnicity, using Regex to look at the start of each line to find \"Hispanic\" or \"Not Hispanic\" (to avoid concatenations like \"Hispanic|Hispanic\")\n",
    "df['maternal_ethnicity'] = np.where(df['maternal_ethnicity_2112'].str.contains(r'^Hispanic', regex=True), 'Hispanic', np.where(df['maternal_ethnicity_2112'].str.contains(r'^Not Hispanic', regex=True), 'Non-Hispanic', 'Unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "5av_qh2lmXoe"
   },
   "outputs": [],
   "source": [
    "composite_social_columns = [\n",
    "    \"drug_abuse_during_parent_2144\",\n",
    "    \"high_risk_social_problems_parent_2154\",\n",
    "    \"high_risk_insufficient_antenatal_care_parent_2157\",\n",
    "    \"icd_major_mental_health_disorder_2178\",\n",
    "    \"education_problems_2203\",\n",
    "    \"employment_problems_2206\",\n",
    "    \"adverse_occupational_2209\",\n",
    "    \"housing_problems_2212\",\n",
    "    \"adjustment_problems_2215\",\n",
    "    \"relationship_problems_2218\",\n",
    "    \"other_psychosocial_2221\",\n",
    "    \"smoker_during_pregnancy_parent_2117\",\n",
    "    \"drug_abuse_before_parent_2142\",\n",
    "    \"alcohol_during_parent_2147\",\n",
    "]\n",
    "\n",
    "df['composite_psychosocial_problems'] = df[composite_social_columns].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "nf7G1is51Ipc"
   },
   "outputs": [],
   "source": [
    "# prompt: create column 'only_private_insurance' for any row where public_insurance_2114 does NOT contains the string \"public\", ignore case\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['only_private_insurance'] = ~df['public_insurance_2114'].str.contains('public', case=False, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "Vmdv_72612D3"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column maternal_language_english for any row where maternal_language is english\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['maternal_language_english'] = df['maternal_language_2113'] == 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "IbQIty854NCO"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column marital_status_married_or_partner for any row where marital_status_2184 is 'married' or 'partner'\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['marital_status_married_or_partner'] = df['marital_status_2184'].apply(lambda x: True if x in ['married', 'partner'] else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "S1gl61Vo5z9D"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column country_of_origin_USA that is country_of_origin_2186 == united states\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['country_of_origin_USA'] = df['country_of_origin_2186'] == 'united states'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "RDTPeP9U6VUZ"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column employment_status_fulltime that is employment_status_2187 == full time\n",
    "\n",
    "df['employment_status_fulltime'] = df['employment_status_2187'] == 'full time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_SES_columns = [\n",
    "    \"only_private_insurance\",\n",
    "    \"maternal_language_english\",\n",
    "    \"marital_status_married_or_partner\",\n",
    "    \"country_of_origin_USA\",\n",
    "    \"employment_status_fulltime\",\n",
    "]\n",
    "df['composite_SES_advantage'] = df[composite_SES_columns].all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jR7Kx62O8BNX"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column epidural_needle_type based on anes_procedure_epidural_needle_2263 that can have values \"tuohy\",\"weiss\", or \"other\"\n",
    "\n",
    "# Create the 'epidural_needle_type' column based on 'anes_procedure_epidural_needle_2263'\n",
    "df['epidural_needle_type'] = df['anes_procedure_epidural_needle_2263'].map({\n",
    "    'tuohy': 'tuohy',\n",
    "    'weiss': 'weiss',\n",
    "}).fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "g5Kp4dAM8pQ7"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column paresthesias_present that is anes_procedure_paresthesias_2270 either \"transient\" or \"yes\"\n",
    "\n",
    "# Create the 'paresthesias_present' column\n",
    "df['paresthesias_present'] = df['anes_procedure_paresthesias_2270'].apply(lambda x: True if x == 'yes' or x == 'transient' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_site'] = np.where(df['delivery_site_2188'] == 'mgb', np.nan, df['delivery_site_2188'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_site'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_site_bwh'] = df['delivery_site'] == 'bwh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labor_induction'] = df[[\n",
    "    'induction_oxytocin_2189','induction_cervical_balloon_2190','induction_misoprostol_2191','induction_arom_2192','induction_foley_easy_2193']].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fetal_presentation_position_2247'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['position_posterior_or_transverse'] = (df['fetal_presentation_position_2247'] == 'posterior') | (df['fetal_presentation_position_2247'] == 'transverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['position_posterior_or_transverse'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fetal_presentation_category_2243'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['presentation_cephalic'] = df['fetal_presentation_category_2243'] == 'cephalic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['presentation_cephalic'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new unique identifier based on epic_pmrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define identifier range (6-digit numbers)\n",
    "id_len = 8\n",
    "min_id, max_id = 10**(id_len-1), 10**id_len - 1\n",
    "\n",
    "# Create mapping of unique MRNs to unique random identifiers\n",
    "unique_mrns = df['epic_pmrn'].unique()\n",
    "mapping = dict(zip(unique_mrns, random.sample(range(min_id, max_id+1), len(unique_mrns))))\n",
    "\n",
    "# Map to a new column in DataFrame\n",
    "df['unique_pt_id'] = df['epic_pmrn'].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5mjv9mmfl2r"
   },
   "source": [
    "# Save processed data prior to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "LAF1Cqkc04aE"
   },
   "outputs": [],
   "source": [
    "complete_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "SWdKTtPTflV9"
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a pickle file\n",
    "complete_data.to_pickle(my_computer_fpath + \"processed_merlin_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "3AIT25V7f_vj"
   },
   "outputs": [],
   "source": [
    "# prompt: Import libraries and open CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pxsgBzbfzOz"
   },
   "outputs": [],
   "source": [
    "# Load the pickled DataFrame\n",
    "complete_data = pd.read_pickle(my_computer_fpath + \"processed_merlin_data.pkl\")\n",
    "\n",
    "# Now you can work with the DataFrame\n",
    "complete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "zwIzc7441Cot"
   },
   "outputs": [],
   "source": [
    "df = complete_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KddNYcoUiEWD"
   },
   "source": [
    "# Reduce Table to Chosen Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wouftr6X4Z57"
   },
   "outputs": [],
   "source": [
    "# prompt: print all columns as a list and make it easy to read over multiple lines\n",
    "\n",
    "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
    "all_columns = df.columns.tolist()\n",
    "\n",
    "# Print the list of columns, formatted for readability\n",
    "print(\"Columns of the DataFrame:\")\n",
    "for i, col in enumerate(all_columns):\n",
    "    print(f\"{i+1}. {col} ||| {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "EFrTx2-X-Jyx"
   },
   "outputs": [],
   "source": [
    "chosen_features = [\n",
    "#    \"id\",\n",
    "    \"unique_pt_id\",\n",
    "    \"anes_procedure_encounter_id_2273\",\n",
    "    \"gestational_age_weeks\",\n",
    "    \"delivery_site\",\n",
    "    \"delivery_site_bwh\",\n",
    "    \"baby_weight_2196\",\n",
    "    \"rom_thru_delivery_hours\",\n",
    "    \"fetal_presentation_category_2243\",\n",
    "    \"fetal_presentation_position_2247\",\n",
    "    \"bmi_end_pregnancy_2044\",\n",
    "    \"maternal_weight_end_pregnancy_2045\",\n",
    "    \"bmi_before_pregnancy_2161\",\n",
    "#    \"zipcode_2185\",\n",
    "    \"gravidity_2047\",\n",
    "    \"parity_2048\",\n",
    "#    \"anes_procedure_note_text_2271\",\n",
    "#    \"best_timestamp\",\n",
    "#    \"true_procedure_type\",\n",
    "    \"is_neuraxial_catheter\",\n",
    "    \"failed_catheter\",\n",
    "#    \"dpe\",\n",
    "    \"lor_depth\",\n",
    "    \"current_resident_catheter_count\",\n",
    "    \"highly_experienced_anesthesiologist\",\n",
    "    \"highly_experienced_resident\",\n",
    "    \"current_anesthesiologist_catheter_count\",\n",
    "    \"moderately_experienced_anesthesiologist\",\n",
    "    \"has_scoliosis\",\n",
    "    \"has_dorsalgia\",\n",
    "    \"has_back_problems\",\n",
    "    \"maternal_race\",\n",
    "    \"maternal_ethnicity\",\n",
    " #   \"prior_pain_scores\",\n",
    "    \"prior_pain_scores_max\",\n",
    "    \"composite_psychosocial_problems\",\n",
    "    \"only_private_insurance\",\n",
    "    \"maternal_language_english\",\n",
    "    \"marital_status_married_or_partner\",\n",
    "    \"country_of_origin_USA\",\n",
    "    \"employment_status_fulltime\",\n",
    "    \"composite_SES_advantage\",\n",
    "    \"epidural_needle_type\",\n",
    "    \"paresthesias_present\",\n",
    "    \"number_of_neuraxial_attempts\",\n",
    "    \"prior_failed_catheters_this_enc\",\n",
    "    \"prior_failed_catheters_prev_enc\",\n",
    "    \"prior_all_catheters_all_enc\",\n",
    "    \"true_procedure_type_incl_dpe\",\n",
    "    \"maternal_age_years\",\n",
    "    \"placement_to_delivery_hours\",\n",
    "    \"labor_induction\",\n",
    "    \"position_posterior_or_transverse\",\n",
    "    \"presentation_cephalic\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "Nr0wa_Zq-RfA"
   },
   "outputs": [],
   "source": [
    "df = df[chosen_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIr75B_tGNEV"
   },
   "outputs": [],
   "source": [
    "# prompt: print all columns as a list and make it easy to read over multiple lines\n",
    "\n",
    "all_columns = df.columns.tolist()\n",
    "\n",
    "# Print the list of columns, formatted for readability\n",
    "print(\"Columns of the DataFrame:\")\n",
    "for i, col in enumerate(all_columns):\n",
    "    print(f\"{i+1}. {col} ||| {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(my_computer_fpath + 'processed_merlin_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKPV6NaW7+ZRxbDtLw/frD",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
