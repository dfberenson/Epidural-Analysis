{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkobyQHnHmfr"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1510,
     "status": "ok",
     "timestamp": 1736530922442,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "aEvYxZF4wEa5"
   },
   "outputs": [],
   "source": [
    "# prompt: Import libraries and open CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "my_computer_fpath = \"C:\\\\Users\\\\dfber\\\\OneDrive - Mass General Brigham\\\\Epidural project\\\\Data\\\\\"\n",
    "# my_computer_fpath = \"C:\\\\Users\\\\User\\\\OneDrive - Mass General Brigham\\\\Epidural project\\\\Data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = my_computer_fpath + \"e26f9ccc-68a4-42b4-9d0d-508a83026a1c.csv\"\n",
    "\n",
    "raw_df = pd.read_csv(file_path)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOA_rFqsHpti"
   },
   "source": [
    "# Initialize dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1736530959963,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "3JVX6R_71rmO"
   },
   "outputs": [],
   "source": [
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1736530959963,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "a8iWzW6vNMw_",
    "outputId": "7aad273b-378d-4227-fba4-658a36b093c3"
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLFyVswb3COk"
   },
   "source": [
    "# Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKsF6foXHuki"
   },
   "source": [
    "## Explode |-separated notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "anes_procedure_cols = ['anes_procedure_type_2253', 'anes_procedure_start_dts_2254', 'anes_procedure_anesthesiologist_2255', 'anes_procedure_resident_2256', 'anes_procedure_pt_position_2257', 'anes_procedure_approach_2258', 'anes_procedure_location_2259', 'anes_procedure_note_id_2260', 'anes_procedure_dos_dts_2261', 'anes_procedure_dpe_2262', 'anes_procedure_epidural_needle_2263', 'anes_procedure_epidural_needle_gauge_2264', 'anes_procedure_lor_depth_2265', 'anes_procedure_catheter_depth_2266', 'anes_procedure_spinal_needle_type_2267', 'anes_procedure_spinal_needle_gauge_2268', 'anes_procedure_spinal_needle_length_2269', 'anes_procedure_paresthesias_2270', 'anes_procedure_note_text_2271','anes_procedure_encounter_id_2273']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "executionInfo": {
     "elapsed": 10728,
     "status": "ok",
     "timestamp": 1736530970931,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "o31L3yCtyk8b",
    "outputId": "94d1b142-bb7f-4c30-a3a5-1ffe281d48a2"
   },
   "outputs": [],
   "source": [
    "# Expand the items in anes_procedure_cols separated by \"|\" into a separate row\n",
    "# Requires that within a row, each element in these columns has the same number of |-separated values\n",
    "\n",
    "# Split the columns with '|' delimiter\n",
    "for col in anes_procedure_cols:\n",
    "    df[col] = df[col].str.split('\\|')\n",
    "\n",
    "# Explode the DataFrame\n",
    "df = df.explode(anes_procedure_cols)\n",
    "\n",
    "# Reset the index after exploding the DataFrame so each individual note will be its own unique row and index\n",
    "df = df.reset_index(drop=True)\n",
    "df[['id','anes_procedure_type_2253']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that other procedure types, including Blood Patch but also A-lines, nerve blocks, and POCUS orders, are currently parsed by Merlin to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anes_procedure_type_2253'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in RAW info\n",
    "\n",
    "This is needed at the moment to get the NotePurposeDSC (to help eliminate near-duplicate notes)\n",
    "and also to RegEx the Number of Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_identified_data = pd.read_csv(my_computer_fpath + \"Full Identified raw anesthesia_procedure_notes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NotePurposeDSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_to_purpose = raw_identified_data.set_index('NoteID')['NotePurposeDSC'].to_dict()\n",
    "df['NotePurposeDSC'] = df['anes_procedure_note_id_2260'].map(note_to_purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['NotePurposeDSC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NoteTXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_to_text = raw_identified_data.set_index('NoteID')['NoteTXT'].to_dict()\n",
    "df['NoteTXT'] = df['anes_procedure_note_id_2260'].map(note_to_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numeric_structured_info_from_full_note(regex, note_text):\n",
    "  # Use RegEx to capture the requested structured data\n",
    "  # If no matches, return NaN\n",
    "  # If multiple matches, will ensure they are all equal, else return NaN\n",
    "  matches = re.findall(regex, note_text)\n",
    "  if len(matches) == 0:\n",
    "    return np.nan\n",
    "\n",
    "  if len(matches) == 1:\n",
    "    return float(matches[0])\n",
    "\n",
    "  if len(matches) > 1:\n",
    "    match_list = []\n",
    "    for match in matches:\n",
    "      match_list.append(match)\n",
    "\n",
    "    if all(x == match_list[0] for x in match_list):\n",
    "      return float(match_list[0])\n",
    "    else:\n",
    "      return np.nan\n",
    "\n",
    "\n",
    "\n",
    "def get_number_of_neuraxial_attempts(note_text):\n",
    "  return get_numeric_structured_info_from_full_note('Number of attempts: (\\\\d+)', note_text)\n",
    "  # Note: the CSE template does not include this info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_of_neuraxial_attempts'] = df['NoteTXT'].apply(get_number_of_neuraxial_attempts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ISNBfVtIQUV"
   },
   "source": [
    "## Handle datetime issues\n",
    "\n",
    "Bug: Merlin is bringing anes_procedure_dos_dts_2261 as Eastern times when in fact they are UTC. I resolve this by editing the raw strings before conversion to datetime objects.\n",
    "\n",
    "Bug: The same is true for delivery_time. I resolve this by editing the raw strings before conversion to datetime objects.\n",
    "\n",
    "Bug: Because delivery_date is stored separately from delivery_time, if the UTC change causes the time to go to the next day, this is NOT reflected in the updated delivery_date.\n",
    "\n",
    "Bug: Merlin ignores AM/PM in anes_procedure_start_dts_2254 and assumes all entries are AM. I resolve this (for now) by ignoring these written start times and just using dos_dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_time'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_time_stripped'] = df['delivery_time'].str.replace(r'[+-]\\d{2}:*\\d{2}$', '+0000', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_time_stripped'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_datetime_unadjusted'] = pd.to_datetime(df['delivery_date'] + ' ' + df['delivery_time_stripped'],utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_datetime_unadjusted'].iloc[1].tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to adjust by one day if time is before 0400 (DST) or 0500 (ST)\n",
    "def adjust_time_based_on_dst(timestamp):\n",
    "    # Adjust cutoff time based on DST or standard time\n",
    "    cutoff_time = pd.Timestamp('04:00:00').time() if timestamp.tz_convert('US/Eastern').dst() != pd.Timedelta(0) else pd.Timestamp('05:00:00').time()\n",
    "    # Add 24 hours if the time is earlier than the cutoff\n",
    "    return timestamp + pd.Timedelta(hours=24) if timestamp.time() < cutoff_time else timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_datetime'] = df['delivery_datetime_unadjusted'].apply(adjust_time_based_on_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['delivery_datetime', 'delivery_datetime_unadjusted']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['maternal_dob'] = pd.to_datetime(df['maternal_dob_2043'],utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736530971128,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "wvOG3uHacl8a",
    "outputId": "8073b0ad-ce09-4bf8-b263-4e33328c614c"
   },
   "outputs": [],
   "source": [
    "df['anes_procedure_dos_dts_2261'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1736530971354,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "7wXrBA3dqi9-"
   },
   "outputs": [],
   "source": [
    "df['dos_dts_tz_stripped'] = df['anes_procedure_dos_dts_2261'].str.replace(r'[+-]\\d{2}:*\\d{2}$', '+0000', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736530971354,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "Xr3WN2fPqt0s",
    "outputId": "02555a21-792e-4eb9-f467-48cacf199f08"
   },
   "outputs": [],
   "source": [
    "df['dos_dts_tz_stripped'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1736530971541,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "DCHq2py6nN7m"
   },
   "outputs": [],
   "source": [
    "df['dos_dts'] = pd.to_datetime(df['dos_dts_tz_stripped'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1736530971541,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "SmhS28lCbYIn",
    "outputId": "09720cfa-430c-4aa9-fdb8-9cfdee75f903"
   },
   "outputs": [],
   "source": [
    "df[['dos_dts','anes_procedure_dos_dts_2261']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1736530972209,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "59dC3WB-ZH8-"
   },
   "outputs": [],
   "source": [
    "df['start_dts'] = pd.to_datetime(df['anes_procedure_start_dts_2254'],format='mixed',utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1736530972393,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "giGm_VZXdG5i",
    "outputId": "eec08e3c-c2d3-494f-ccb7-301cd698e376"
   },
   "outputs": [],
   "source": [
    "# Extract the time part of the 'start_dts' column to check whether it covers all 24 h or only 12 h due to AM/PM bug\n",
    "df[df['start_dts'].notna()]['start_dts'].dt.time.sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736530972394,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "ohVRiD_RRohx"
   },
   "outputs": [],
   "source": [
    "# This code has been changed to avoid the AM/PM bug\n",
    "\n",
    "# df['best_timestamp'] = df['start_dts'].fillna(df['dos_dts'])\n",
    "df['best_timestamp'] = df['dos_dts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['best_timestamp'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JPfIBsGQjpd"
   },
   "source": [
    "## Handle near-duplicate notes\n",
    "\n",
    "There is also a column \"NotePurposeDSC\" in the raw EDW data that can be \"ADDENDUM\" or \"NORMAL\" or blank. When there are duplicate notes, the first one will be blank and subsequent ones will be ADDENDUM. I use this fact upstream and delete all the ones that are blank.\n",
    "\n",
    "IMPORTANT: It turns out to be the case that there are sometimes, genuinely in Epic, two procedures done within only a few mins of each other - and these represent a repeat procedure, not a duplicate note. Therefore I now only call notes duplicates if their timestamps EXACTLY match (minute_offset == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1736530972582,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "NWaRarfN02K-",
    "outputId": "ae5481b2-a589-4186-dbae-c795cb6b4fbc"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known double-note\n",
    "df.loc[df['anes_procedure_note_id_2260'] == '1188076153']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736530972582,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "mnHDJKKiRXbP"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known near-duplicate note\n",
    "df[df['anes_procedure_note_id_2260'] == '2250605132']\n",
    "known_near_duplicate_encounter_id = df[df['anes_procedure_note_id_2260'] == '2250605132']['anes_procedure_encounter_id_2273'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1736530973222,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "TOPEviTcRkZh",
    "outputId": "aec51ac4-9ffc-4f1e-ba14-2d8e3f0c661f"
   },
   "outputs": [],
   "source": [
    "known_near_duplicate_group = df.groupby('anes_procedure_encounter_id_2273').get_group(known_near_duplicate_encounter_id)\n",
    "known_near_duplicate_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1736530973223,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "JSG6sdjYiQUt"
   },
   "outputs": [],
   "source": [
    "# prompt: add 'best_timestamp', 'dos_dts', and 'start_dts' to anes_procedure_cols\n",
    "\n",
    "anes_procedure_cols.extend(['best_timestamp', 'dos_dts', 'start_dts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736530973223,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "HYmiFDuGhkWU"
   },
   "outputs": [],
   "source": [
    "# need to narrow operations to a smaller group of columns for efficiency\n",
    "\n",
    "df_anes_procedure_cols = df[anes_procedure_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736530973223,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "eu4qZbZoSOzk"
   },
   "outputs": [],
   "source": [
    "# Functions to label near_duplicate procedures\n",
    "\n",
    "# Compare two rows and return True if their timestamps are within minute_offset\n",
    "# and their compare_cols match\n",
    "def check_if_near_duplicate(row1, row2, compare_cols, minute_offset):\n",
    "  for col in compare_cols:\n",
    "    if not pd.isnull(row1[col]) and not pd.isnull(row2[col]):\n",
    "      if row1[col] != row2[col]:\n",
    "        return False\n",
    "  if abs(row1['best_timestamp'] - row2['best_timestamp']) > pd.Timedelta(minutes=minute_offset):\n",
    "    # if abs(row1['best_timestamp'] - row2['best_timestamp']) < pd.Timedelta(minutes=60):\n",
    "    #   print(row1['anes_procedure_note_id_2260'], row2['anes_procedure_note_id_2260'], row1['best_timestamp'], row2['best_timestamp'])\n",
    "    return False\n",
    "  return True\n",
    "\n",
    "\n",
    "# Label near_duplicate notes within an encounter using the check_if_near_duplicate function\n",
    "def label_near_duplicate_notes(encounter):\n",
    "\n",
    "  indices = encounter.index.tolist()\n",
    "\n",
    "  for i in range(len(indices)):\n",
    "    base_idx = indices[i]\n",
    "    base_row = encounter.loc[base_idx]\n",
    "    has_near_duplicate = 0\n",
    "    near_duplicates = [base_row['anes_procedure_note_id_2260']]\n",
    "\n",
    "    for j in range(len(indices)):\n",
    "      if i == j:\n",
    "        continue # don't identify self-duplicates\n",
    "      compare_idx = indices[j]\n",
    "      compare_row = encounter.loc[compare_idx]\n",
    "\n",
    "\n",
    "      if check_if_near_duplicate(base_row, compare_row, ['anes_procedure_type_2253'], minute_offset = 0):\n",
    "        has_near_duplicate = 1\n",
    "        near_duplicates.append(compare_row['anes_procedure_note_id_2260'])\n",
    "\n",
    "    encounter.at[base_idx, 'has_near_duplicate'] = has_near_duplicate\n",
    "    encounter.at[base_idx, 'near_duplicate_note_ids'] = str(sorted(near_duplicates))\n",
    "\n",
    "  return encounter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101110,
     "status": "ok",
     "timestamp": 1736531074331,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "xEMrr-2XVCCh",
    "outputId": "483342da-f140-4e9a-8dc5-7f6732b07474"
   },
   "outputs": [],
   "source": [
    "# Label near_duplicate procedures\n",
    "# Takes ~2 mins\n",
    "\n",
    "df_anes_procedure_cols['has_near_duplicate'] = 0\n",
    "df_anes_procedure_cols['near_duplicate_note_ids'] = None\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(label_near_duplicate_notes, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1736531074332,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "G85sWqU4lqPU"
   },
   "outputs": [],
   "source": [
    "# prompt: sort df_anes_procedure_cols by index\n",
    "\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1736531074693,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "x2GqpOxYjtZX"
   },
   "outputs": [],
   "source": [
    "# Count blank columns\n",
    "df_anes_procedure_cols['blank_anes_procedure_element_col_counts'] = df_anes_procedure_cols[anes_procedure_cols].isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 81883,
     "status": "ok",
     "timestamp": 1736531156575,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "hQS2Po3LY2ML"
   },
   "outputs": [],
   "source": [
    "# Within a group of duplicates, label the one with the fewest blank columns as NOT the worse duplicate (i.e., the best)\n",
    "# Takes ~2 mins\n",
    "def label_worse_near_duplicates(near_duplicate_set):\n",
    "  near_duplicate_set.at[near_duplicate_set['blank_anes_procedure_element_col_counts'].idxmin(), 'is_worse_near_duplicate'] = 0\n",
    "  return near_duplicate_set\n",
    "\n",
    "df_anes_procedure_cols['is_worse_near_duplicate'] = df_anes_procedure_cols['has_near_duplicate']\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('near_duplicate_note_ids').apply(label_worse_near_duplicates, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('near_duplicate_note_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1736531157076,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "RityoHtEpCUt",
    "outputId": "05a5e03d-0594-45d6-9308-7d4337556887"
   },
   "outputs": [],
   "source": [
    "known_near_duplicate_group = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').get_group(known_near_duplicate_encounter_id)\n",
    "known_near_duplicate_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1736531157077,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "wsvcrtEC00aO",
    "outputId": "8400b1c1-79eb-4cc8-9326-15c541f04197"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known double-note\n",
    "known_double_note = df_anes_procedure_cols.loc[df_anes_procedure_cols['anes_procedure_note_id_2260'] == '1188076153']\n",
    "known_double_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736531157077,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "bfpW-_GU1OMs",
    "outputId": "9accb36a-5455-4705-efe2-fecb239e3ab4"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_worse_near_duplicate'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1736531157211,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "U3D_vdCFpPVn"
   },
   "outputs": [],
   "source": [
    "# Remove worse duplicates\n",
    "df_anes_procedure_cols = df_anes_procedure_cols[df_anes_procedure_cols['is_worse_near_duplicate']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtFesSAK1wsT"
   },
   "source": [
    "## Address cases where an epidural note followed by a spinal note is actually a planned CSE, not a failed catheter. Also address what 'epidural/intrathecal' really means.\n",
    "\n",
    "Secret CSEs are spinal and epidural within 5 mins\n",
    "\n",
    "Epidural/intrathecal notes are declared epidural unless ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736531157211,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "oAlkUSFd15mb"
   },
   "outputs": [],
   "source": [
    "# Functions to label secret_CSE procedures\n",
    "\n",
    "# Compare two rows and return True if exactly one is an epidural, exactly one is a spinal,\n",
    "# and if their timestamps are within minute_offset\n",
    "def check_if_secret_CSE(row1, row2, minute_offset):\n",
    "  if abs(row1['best_timestamp'] - row2['best_timestamp']) < pd.Timedelta(minutes=minute_offset):\n",
    "    if row1['anes_procedure_type_2253'] == 'epidural/intrathecal' or row1['anes_procedure_type_2253'] == 'epidural':\n",
    "      if row2['anes_procedure_type_2253'] == 'spinal':\n",
    "        return True\n",
    "    if row2['anes_procedure_type_2253'] == 'epidural/intrathecal' or row2['anes_procedure_type_2253'] == 'epidural':\n",
    "      if row1['anes_procedure_type_2253'] == 'spinal':\n",
    "        return True\n",
    "  return False\n",
    "\n",
    "# Label secret_CSE notes within an encounter using the check_if_secret_CSE function\n",
    "def label_secret_CSE_notes(encounter):\n",
    "\n",
    "  indices = encounter.index.tolist()\n",
    "\n",
    "  for i in range(len(indices)):\n",
    "    base_idx = indices[i]\n",
    "    base_row = encounter.loc[base_idx]\n",
    "    is_secret_CSE = 0\n",
    "    secret_CSEs = [base_row['anes_procedure_note_id_2260']]\n",
    "\n",
    "    for j in range(len(indices)):\n",
    "      if i == j:\n",
    "        continue # don't identify self-duplicates\n",
    "      compare_idx = indices[j]\n",
    "      compare_row = encounter.loc[compare_idx]\n",
    "\n",
    "      if check_if_secret_CSE(base_row, compare_row, minute_offset = 5):\n",
    "        is_secret_CSE = 1\n",
    "        secret_CSEs.append(compare_row['anes_procedure_note_id_2260'])\n",
    "\n",
    "    encounter.at[base_idx, 'is_secret_CSE'] = is_secret_CSE\n",
    "    encounter.at[base_idx, 'secret_CSE_note_ids'] = str(sorted(secret_CSEs))\n",
    "\n",
    "  return encounter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105396,
     "status": "ok",
     "timestamp": 1736531262605,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "fUFcrD6XD55I",
    "outputId": "5ee4c703-2ed9-4c80-eeab-a4814c32ea2f"
   },
   "outputs": [],
   "source": [
    "# Label secret_CSE procedures\n",
    "# Takes ~2 mins\n",
    "\n",
    "df_anes_procedure_cols['is_secret_CSE'] = 0\n",
    "df_anes_procedure_cols['secret_CSE_note_ids'] = None\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(label_secret_CSE_notes, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "ZuMTbsM8FEyp",
    "outputId": "5c5dce82-576e-4a0e-924a-708fa1f9426b"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_secret_CSE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "eTslzEhqFQ0i",
    "outputId": "0fdc2f29-c26e-412e-cde0-1a23158a35ce"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols[df_anes_procedure_cols['is_secret_CSE'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "cVHEDdpkITEk"
   },
   "outputs": [],
   "source": [
    "# Eliminate the separately-documented spinals that are really part of CSEs\n",
    "\n",
    "# Delete rows where procedure_type is spinal and is_secret_CSE is true\n",
    "df_anes_procedure_cols = df_anes_procedure_cols[~((df_anes_procedure_cols['anes_procedure_type_2253'] == 'spinal') & (df_anes_procedure_cols['is_secret_CSE'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "1APs69qNJtY2",
    "outputId": "0e5eb7f6-c9ed-479a-99c5-414e37d3098c"
   },
   "outputs": [],
   "source": [
    "# Label true intrathecal catheters\n",
    "# NOTE: DOES NOT YET RECLASSIFY EPIDURAL/INTRATHECALS BY CSF ASPIRATION OR ANY OTHER METHOD\n",
    "\n",
    "df_anes_procedure_cols['is_intrathecal_catheter'] = (df_anes_procedure_cols['anes_procedure_type_2253'] == 'intrathecal').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1736531262822,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "_3REoY6SKHwu",
    "outputId": "3f78d9e6-2e30-4187-b04b-5437fc7a5dd4"
   },
   "outputs": [],
   "source": [
    "# prompt: label true_procedure_type by reclassifying based on is_secret_CSE and is_intrathecal_catheter\n",
    "\n",
    "# Create the 'true_procedure_type' column based on the conditions\n",
    "df_anes_procedure_cols['true_procedure_type'] = np.where(\n",
    "    df_anes_procedure_cols['is_secret_CSE'] == True,'cse',\n",
    "    df_anes_procedure_cols['anes_procedure_type_2253'])\n",
    "\n",
    "# Update 'true_procedure_type' based on 'is_intrathecal_catheter'\n",
    "df_anes_procedure_cols.loc[\n",
    "    (df_anes_procedure_cols['true_procedure_type'].isin(['epidural/intrathecal', 'intrathecal'])) &\n",
    "    (df_anes_procedure_cols['is_intrathecal_catheter'] == True),\n",
    "    'true_procedure_type'] = 'intrathecal'\n",
    "\n",
    "df_anes_procedure_cols.loc[\n",
    "    (df_anes_procedure_cols['true_procedure_type'] == 'epidural/intrathecal') &\n",
    "    (df_anes_procedure_cols['is_intrathecal_catheter'] == False),\n",
    "    'true_procedure_type'] = 'epidural'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anes_procedure_type_2253'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['true_procedure_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1736531262822,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "xMX_LrGBJUg9",
    "outputId": "448f07ea-ef57-4287-8afb-f2cc33f9a2dc"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nlc5uOLquoP_"
   },
   "source": [
    "# Classify failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1736531262823,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "VglLLyHlvMy0"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_neuraxial_catheter'] = (df_anes_procedure_cols['true_procedure_type'].isin(['cse', 'epidural', 'intrathecal'])).astype(int)\n",
    "df_anes_procedure_cols['is_spinal'] = (df_anes_procedure_cols['true_procedure_type'] == 'spinal').astype(int)\n",
    "df_anes_procedure_cols['is_airway'] = (df_anes_procedure_cols['true_procedure_type'] == 'airway').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "DmRHrn9durRv"
   },
   "outputs": [],
   "source": [
    "# Vectorized method to classify as successes or failures\n",
    "# takes ~10 mins\n",
    "\n",
    "def classify_encounter_failures(encounter):\n",
    "\n",
    "    # Identify rows where 'is_neuraxial_catheter' == 1\n",
    "    neuraxial_rows = encounter[encounter['is_neuraxial_catheter'] == 1]\n",
    "\n",
    "    # If no neuraxial catheter procedures, return encounter as is\n",
    "    if neuraxial_rows.empty:\n",
    "        return encounter\n",
    "\n",
    "    # Create a mask for failure-defining events within the encounter\n",
    "    # Failure-defining events are neuraxial catheters, spinals, and airways\n",
    "    failure_defining_event_mask = encounter[['is_neuraxial_catheter','is_spinal','is_airway']].any(axis=1)\n",
    "\n",
    "    # Get the indices of events\n",
    "    failure_defining_event_indices = encounter.index[failure_defining_event_mask]\n",
    "\n",
    "    # Iterate over neuraxial catheter rows\n",
    "    for idx in neuraxial_rows.index:\n",
    "        current_time = encounter.at[idx, 'best_timestamp']\n",
    "\n",
    "        # Find subsequent events\n",
    "        # This relies on correct ordering by best_timestamp\n",
    "        subsequent_failure_defining_events = encounter.loc[failure_defining_event_indices]\n",
    "        subsequent_failure_defining_events = subsequent_failure_defining_events[subsequent_failure_defining_events['best_timestamp'] > current_time]\n",
    "\n",
    "        # Initialize flags\n",
    "        has_subsequent_neuraxial_catheter = 0\n",
    "        has_subsequent_spinal = 0\n",
    "        has_subsequent_airway = 0\n",
    "        failed_catheter = 0\n",
    "        subsequent_proof_of_failure_note_id = None\n",
    "\n",
    "        # Check for subsequent procedures\n",
    "        if not subsequent_failure_defining_events.empty:\n",
    "            # Update flags based on any occurrence in subsequent events\n",
    "            has_subsequent_neuraxial_catheter = int((subsequent_failure_defining_events['is_neuraxial_catheter'] == 1).any())\n",
    "            has_subsequent_spinal = int((subsequent_failure_defining_events['is_spinal'] == 1).any())\n",
    "            has_subsequent_airway = int((subsequent_failure_defining_events['is_airway'] == 1).any())\n",
    "            failed_catheter = int(has_subsequent_neuraxial_catheter or has_subsequent_spinal or has_subsequent_airway)\n",
    "            subsequent_proof_of_failure_note_id = subsequent_failure_defining_events['anes_procedure_note_id_2260'].tolist()\n",
    "\n",
    "            encounter.at[idx, 'has_subsequent_neuraxial_catheter'] = has_subsequent_neuraxial_catheter\n",
    "            encounter.at[idx, 'has_subsequent_spinal'] = has_subsequent_spinal\n",
    "            encounter.at[idx, 'has_subsequent_airway'] = has_subsequent_airway\n",
    "            encounter.at[idx, 'failed_catheter'] = failed_catheter\n",
    "            encounter.at[idx, 'subsequent_proof_of_failure_note_id'] = str(subsequent_proof_of_failure_note_id)\n",
    "\n",
    "    return encounter\n",
    "\n",
    "df_anes_procedure_cols['has_subsequent_neuraxial_catheter'] = 0\n",
    "df_anes_procedure_cols['has_subsequent_spinal'] = 0\n",
    "df_anes_procedure_cols['has_subsequent_airway'] = 0\n",
    "df_anes_procedure_cols['failed_catheter'] = 0\n",
    "df_anes_procedure_cols['subsequent_proof_of_failure_note_id'] = None\n",
    "\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(classify_encounter_failures, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY63Lf9aV-cZ"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebuild df by merging with df_anes_procedure_cols\n",
    "\n",
    "Note that rows have been eliminated from df_anes_procedure_cols in two steps: as is_worse_near_duplicate, and as is_secret_cse (note that only the spinal half of the is_secret_cse cases are removed since the epidural half become the CSEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "gzPV1CsfnsJD"
   },
   "outputs": [],
   "source": [
    "# prompt: concatenate new columns from df_anes_procedure_cols into df. only bring the new columns, leave behind the matching ones. Select the new columns via code.\n",
    "\n",
    "# Identify new columns in df_anes_procedure_cols that are not in df\n",
    "new_cols = [col for col in df_anes_procedure_cols.columns if col not in df.columns]\n",
    "\n",
    "# Merge df with df_anes_procedure_cols on the index, only keeping rows that exist in both\n",
    "df = pd.merge(df, df_anes_procedure_cols[new_cols], left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "WqfMMOV8Do1r"
   },
   "outputs": [],
   "source": [
    "df['is_neuraxial_catheter'] = df['is_neuraxial_catheter'] == 1\n",
    "df['failed_catheter'] = df['failed_catheter'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns to move 'is_neuraxial_catheter' and 'failed_catheter' to the front\n",
    "cols = ['is_neuraxial_catheter', 'failed_catheter'] + [col for col in df.columns if col not in ['is_neuraxial_catheter', 'failed_catheter']]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "likLZC_lwNhJ"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCec8U6S0QeF"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known double-note\n",
    "known_double_note = df.loc[df['anes_procedure_note_id_2260'] == '1188076153']\n",
    "known_double_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP0RDHaa0rmz"
   },
   "outputs": [],
   "source": [
    "df[df['failed_catheter'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "In0JgcPXBgtB"
   },
   "outputs": [],
   "source": [
    "known_failed_catheter_encounter_ids = ['3259099621','3081317750', '3081399139', '3081675427', '3081686082', '3081711691', '3081729928', '3081884584', '3081893356', '3082275619', '3082349091']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Xawf8qwCPXj"
   },
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'].isin(known_failed_catheter_encounter_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPBvuAV6NRli"
   },
   "source": [
    "# Additional Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count prior failed neuraxials in this encounter and failed and total across all encounters\n",
    "\n",
    "Takes ~4 mins for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='best_timestamp', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are separate functions so that they can be applied to the DataFrame in a vectorized manner without needing to take the new_column_name as an argument,\n",
    "# which doesn't work well with the .apply() method\n",
    "\n",
    "def count_prior_failed_catheters_this_enc(group):\n",
    "    group['prior_failed_catheters_this_enc'] = (group['failed_catheter'].cumsum() - group['failed_catheter']).astype(float)\n",
    "    return group\n",
    "\n",
    "def count_prior_failed_catheters_all_enc(group):\n",
    "    group['prior_failed_catheters_all_enc'] = (group['failed_catheter'].cumsum() - group['failed_catheter']).astype(float)\n",
    "    return group\n",
    "\n",
    "def count_prior_all_catheters_all_enc(group):\n",
    "    group['prior_all_catheters_all_enc'] = (group['is_neuraxial_catheter'].cumsum() - group['is_neuraxial_catheter']).astype(float)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('anes_procedure_encounter_id_2273').apply(count_prior_failed_catheters_this_enc, include_groups = False)\n",
    "df = df.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('epic_pmrn').apply(count_prior_failed_catheters_all_enc, include_groups = False)\n",
    "df = df.reset_index('epic_pmrn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('epic_pmrn').apply(count_prior_all_catheters_all_enc, include_groups = False)\n",
    "df = df.reset_index('epic_pmrn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prior_failed_catheters_prev_enc'] = df['prior_failed_catheters_all_enc'] - df['prior_failed_catheters_this_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'] == '3258959083']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'] == '3147096491']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'] == '3227352323']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "757vQkZucKbN"
   },
   "source": [
    "## Handle timeseries data (e.g., pain scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VUtFAxcFdliC"
   },
   "outputs": [],
   "source": [
    "# Extracts the pain scores prior to the timestamp\n",
    "# Takes ~ 1 minute\n",
    "def get_pain_scores_prior_to_timestamp(row, best_timestamp_col=\"best_timestamp\"):\n",
    "    \"\"\"\n",
    "    Extract all pain scores that have timestamp < row[best_timestamp_col].\n",
    "\n",
    "    row: a single row of your DataFrame (a pd.Series)\n",
    "    best_timestamp_col: name of the column in your DataFrame that contains\n",
    "                       the 'best_timestamp' to compare against\n",
    "\n",
    "    Returns a list of 'prior' scores or NaN if none exist.\n",
    "    \"\"\"\n",
    "    # Extract the raw strings\n",
    "    times_str = row[\"timeseries_intrapartum_pain_score_datetime_2242\"]\n",
    "    scores_str = row[\"timeseries_intrapartum_pain_score_2242\"]\n",
    "\n",
    "    # If either is missing, return NaN\n",
    "    if pd.isna(times_str) or pd.isna(scores_str):\n",
    "        return np.nan\n",
    "\n",
    "    # Convert to lists\n",
    "    times_list = times_str.split(\"|\")\n",
    "    scores_list = scores_str.split(\"|\")\n",
    "\n",
    "    # Safely convert both times and best_timestamp to datetime\n",
    "    try:\n",
    "        times_dt = pd.to_datetime(times_list)\n",
    "        # This assumes your row also has a column called best_timestamp_col\n",
    "        best_dt = pd.to_datetime(row[best_timestamp_col])\n",
    "    except:\n",
    "        # If conversion fails, return NaN\n",
    "        return np.nan\n",
    "\n",
    "    # Filter out all scores whose timestamp is strictly less than best_timestamp\n",
    "    prior_scores = []\n",
    "    for t, s in zip(times_dt, scores_list):\n",
    "        if t < best_dt:\n",
    "            prior_scores.append(float(s))\n",
    "\n",
    "    # If no scores remain, return NaN, else return them joined or as list\n",
    "    return prior_scores if prior_scores else np.nan\n",
    "\n",
    "df['prior_pain_scores'] = df.apply(get_pain_scores_prior_to_timestamp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Dto2g0HfeCuC"
   },
   "outputs": [],
   "source": [
    "df[\"prior_pain_scores_max\"] = df[\"prior_pain_scores\"].apply(\n",
    "    lambda scores: max(map(float, scores)) if isinstance(scores, list) and scores else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "x6LMgIHofOYD"
   },
   "outputs": [],
   "source": [
    "df['prior_pain_scores_max'].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3n9mBjG2mKn"
   },
   "source": [
    "## Clean DPE and LOR_Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "18FwO5sbNj3r"
   },
   "outputs": [],
   "source": [
    "# make 'dpe' True/False\n",
    "df['dpe'] = df['anes_procedure_dpe_2262'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['true_procedure_type_incl_dpe'] = df['true_procedure_type']\n",
    "df.loc[df['dpe'] == True, 'true_procedure_type_incl_dpe'] = 'dpe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7ldb0bDxNTGo"
   },
   "outputs": [],
   "source": [
    "# make 'lor_depth' numeric\n",
    "df['lor_depth'] = df['anes_procedure_lor_depth_2265'].replace('', np.nan).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZuSyUaAeN4r1"
   },
   "outputs": [],
   "source": [
    "# Code to evaluate suspiciously high LORs\n",
    "# For these, if we divide LOR by 10, the the catheter is taped around 4-5 cm deeper\n",
    "# So most likely these suspiciously high LORs are missing decimal points\n",
    "high_LORs = df.sort_values(by='lor_depth',ascending=False).head(100)['lor_depth']\n",
    "print(high_LORs.to_list())\n",
    "plt.hist(high_LORs)\n",
    "\n",
    "print(df.sort_values(by='lor_depth',ascending=False).head(100)['anes_procedure_catheter_depth_2266'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7YS3I4MEN8OG"
   },
   "outputs": [],
   "source": [
    "# prompt: lor_depth = lor_depth / 10 if lor_depth > 20\n",
    "\n",
    "df['lor_depth'] = np.where(df['lor_depth'] > 20, df['lor_depth'] / 10, df['lor_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EALlbR6-OUaQ"
   },
   "outputs": [],
   "source": [
    "# Code to evaluate suspiciously high LORs\n",
    "high_LORs = df.sort_values(by='lor_depth',ascending=False).head(100)['lor_depth']\n",
    "print(high_LORs.to_list())\n",
    "plt.hist(high_LORs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjq02Q_U2ucI"
   },
   "source": [
    "## Make numerical columns numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "RH4BDg1__d1h"
   },
   "outputs": [],
   "source": [
    "# prompt: set these columns to dtype float: bmi_end_pregnancy_2044, maternal_weight_end_pregnancy_2045, maternal_height_2046,gravidity_2047,parity_2048\n",
    "\n",
    "# Convert specified columns to float dtype\n",
    "columns_to_convert = ['gestational_age_2052','bmi_end_pregnancy_2044', 'maternal_weight_end_pregnancy_2045', 'maternal_height_2046', 'gravidity_2047', 'parity_2048','baby_weight_2196','bmi_before_pregnancy_2161','secs_rom_thru_delivery_2197']\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "        except KeyError:\n",
    "            print(f\"Column '{col}' not found in the DataFrame.\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' not found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and plausibilify elapsed times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rom_thru_delivery_hours'] = df['secs_rom_thru_delivery_2197'] / 3600\n",
    "df['rom_thru_delivery_hours'].describe(percentiles=[0.01,0.05,0.25,0.5,0.75,0.95,0.98,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "gkTCwVcyOtX3"
   },
   "outputs": [],
   "source": [
    "# If ROM through Delivery is more than 30 days, assume erroneous and make it NaN\n",
    "df['rom_thru_delivery_hours'] = np.where(df['rom_thru_delivery_hours'] <= 30*24, df['rom_thru_delivery_hours'],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['maternal_age_years'] = (df['delivery_datetime'] - df['maternal_dob']).dt.days / 365.25\n",
    "df['maternal_age_years'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['placement_to_delivery_hours'] = (df['delivery_datetime'] - df['best_timestamp']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['true_procedure_type'] == 'epidural']['placement_to_delivery_hours'].describe(percentiles=[0.01,0.02,0.05,0.10,0.15,0.25,0.2,0.5,0.75,0.95,0.98,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['placement_to_delivery_hours'] = np.where((df['placement_to_delivery_hours'] > -1) & (df['placement_to_delivery_hours'] <= 7*24),\n",
    "                                             df['placement_to_delivery_hours'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['true_procedure_type'] == 'epidural']['placement_to_delivery_hours'].describe(percentiles=[0.01,0.02,0.05,0.10,0.15,0.25,0.2,0.5,0.75,0.95,0.98,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['placement_to_delivery_hours'].sort_values(ascending=True).head().index,:][['anes_procedure_note_id_2260','anes_procedure_type_2253','placement_to_delivery_hours','delivery_datetime','best_timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['placement_to_delivery_hours'].sort_values(ascending=False).head().index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analyses, procedures where many days elapse between placement and delivery are NOT labor analgesia procedures. They can be totally unrelated procedures like knee surgery, or obstetrical procedures like ECVs, or (rarely) analgesia for false labor. In the latter case, if labor does not progress and the patient returns to antepartum, the anesthesia encounter will termiante and a new encounter will be used for subsequent labor. In that case, an epidural placed in the second encounter will NOT prove failure of the first since it will have a different encounter_id.\n",
    "\n",
    "For these reasons, I eliminate rows where there is more than 7 days between placement and delivery.\n",
    "\n",
    "Due to the UTC bug discussed above, a true 1859 EPL followed by 1900 delivery would be translated to 2359 EPL AFTER 0000 delivery (without the delivery_date incrementing appropriately)\n",
    "\n",
    "A more thorough algorithm could look at the timing of Anesthesia Stop compared to delivery, and/or confirm that the title of the anesthesia encounter is Labor Epidural or Cesarean Section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['placement_to_delivery_hours']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include other limits on plausible data for each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rdMZOcI2xZH"
   },
   "source": [
    "## Handle proceduralist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "K44x6YG-9GCD"
   },
   "outputs": [],
   "source": [
    "# Function to regulate names\n",
    "def regulate_name(name):\n",
    "\n",
    "    # Remove degrees and titles\n",
    "    name = re.sub(r',?\\s*(md|do|mbbs|phd|ms|mba|mph|msc|crna)\\b', '', name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Split last name and first name if comma exists\n",
    "    if ',' in name:\n",
    "        last, first = name.split(',', 1)\n",
    "        name = f\"{first.strip()} {last.strip()}\"\n",
    "\n",
    "    # Remove extra spaces\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "    # Remove middle names\n",
    "    parts = name.split()\n",
    "    if len(parts) > 2 :\n",
    "      name = f\"{parts[0]} {parts[-1]}\"\n",
    "\n",
    "    # Capitalize each part of the name\n",
    "    name = name.title()\n",
    "\n",
    "    return name\n",
    "\n",
    "# Apply the function to regulate names\n",
    "df['Regulated_Anesthesiologist_Name'] = df['anes_procedure_anesthesiologist_2255'].dropna().apply(regulate_name)\n",
    "df['Regulated_Resident_Name'] = df['anes_procedure_resident_2256'].dropna().apply(regulate_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "oXOr9Udky9qK"
   },
   "outputs": [],
   "source": [
    "# prompt: set all blank Regulated_Anesthesiologist_Name and Regulated_Resident_Name to NaN\n",
    "\n",
    "df['Regulated_Anesthesiologist_Name'] = df['Regulated_Anesthesiologist_Name'].replace('', np.nan)\n",
    "df['Regulated_Resident_Name'] = df['Regulated_Resident_Name'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Lm5KJJXfZaPD"
   },
   "outputs": [],
   "source": [
    "# prompt: For each catheter, count how many (i.e., earlier best_timestamp) catheters were done by that provider (including the current one)\n",
    "\n",
    "df = df.sort_values('best_timestamp')\n",
    "\n",
    "df['current_anesthesiologist_catheter_count'] = (\n",
    "    df.groupby('Regulated_Anesthesiologist_Name')['is_neuraxial_catheter']\n",
    "      .cumsum()\n",
    ")\n",
    "\n",
    "df['current_resident_catheter_count'] = (\n",
    "    df.groupby('Regulated_Resident_Name')['is_neuraxial_catheter']\n",
    "      .cumsum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "czc7KflO5Laq"
   },
   "outputs": [],
   "source": [
    "df['highly_experienced_anesthesiologist'] = np.where(df['current_anesthesiologist_catheter_count'] > 500, 'yes',\n",
    "                                                    np.where(df['current_anesthesiologist_catheter_count'] <= 500, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "_Flgn1iczuHP"
   },
   "outputs": [],
   "source": [
    "df['moderately_experienced_anesthesiologist'] = np.where(df['current_anesthesiologist_catheter_count'] > 100, 'yes',\n",
    "                                                        np.where(df['current_anesthesiologist_catheter_count'] <= 100, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "EOo7CtAq5Y6X"
   },
   "outputs": [],
   "source": [
    "# prompt: set df['highly_experienced_resident'] to 1 if current_resident_catheter_count > 50, to 0 if <= 50, and to -1 if NaN\n",
    "\n",
    "df['highly_experienced_resident'] = np.where(df['current_resident_catheter_count'] > 50, 'yes',\n",
    "                                                    np.where(df['current_resident_catheter_count'] <= 50, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqbNsz2U26MN"
   },
   "source": [
    "## Feature engineering on categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "Cd-k3VRq4r1e"
   },
   "outputs": [],
   "source": [
    "df['has_scoliosis'] = df['icd_scoliosis_2053'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "tsUb1icS5IAj"
   },
   "outputs": [],
   "source": [
    "df['has_dorsalgia'] = df['icd_dorsalgia_2104'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "zKT4Wd683p7p"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column \"has_back_problems\" that is 1 where any of the following are True, else 0. Handle NaN.\n",
    "\n",
    "# Define the columns related to back problems\n",
    "back_problem_cols = [\n",
    "    'icd_scoliosis_2053',\n",
    "    'icd_spinal_fusion_2056',\n",
    "    'icd_congenital_deformity_spine_2059',\n",
    "    'icd_ra_and_sctds_2086',\n",
    "    'icd_kyphosis_and_lordosis_2089',\n",
    "    'icd_spinal_osteochondrosis_2092',\n",
    "    'icd_spondylopathies_and_deforming_dorsopathies_2095',\n",
    "    'icd_intervertebral_disc_disorders_2098',\n",
    "    'icd_ehlers_minus_danlos_2101',\n",
    "]\n",
    "\n",
    "# Note that spondyolopathies_and_deforming_dorsopathies are by far the biggest contributors\n",
    "\n",
    "# Create the 'has_back_problems' column\n",
    "df['has_back_problems'] = df[back_problem_cols].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "zLsKQUhDDGtI"
   },
   "outputs": [],
   "source": [
    "df['maternal_race'] = np.select(\n",
    "    [\n",
    "        df['maternal_race_2111'] == 'White',\n",
    "        df['maternal_race_2111'] == 'Asian',\n",
    "        df['maternal_race_2111'] == 'Black'\n",
    "    ],\n",
    "    [\n",
    "        'White',\n",
    "        'Asian',\n",
    "        'Black'\n",
    "    ],\n",
    "    default='Other/Unknown'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "5av_qh2lmXoe"
   },
   "outputs": [],
   "source": [
    "composite_social_columns = [\n",
    "    \"drug_abuse_during_parent_2144\",\n",
    "    \"high_risk_social_problems_parent_2154\",\n",
    "    \"high_risk_insufficient_antenatal_care_parent_2157\",\n",
    "    \"icd_major_mental_health_disorder_2178\",\n",
    "    \"education_problems_2203\",\n",
    "    \"employment_problems_2206\",\n",
    "    \"adverse_occupational_2209\",\n",
    "    \"housing_problems_2212\",\n",
    "    \"adjustment_problems_2215\",\n",
    "    \"relationship_problems_2218\",\n",
    "    \"other_psychosocial_2221\",\n",
    "    \"smoker_during_pregnancy_parent_2117\",\n",
    "    \"drug_abuse_before_parent_2142\",\n",
    "    \"alcohol_during_parent_2147\",\n",
    "]\n",
    "\n",
    "df['composite_psychosocial_problems'] = df[composite_social_columns].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "nf7G1is51Ipc"
   },
   "outputs": [],
   "source": [
    "# prompt: create column 'only_private_insurance' for any row where public_insurance_2114 does NOT contains the string \"public\", ignore case\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['only_private_insurance'] = ~df['public_insurance_2114'].str.contains('public', case=False, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "Vmdv_72612D3"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column maternal_language_english for any row where maternal_language is english\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['maternal_language_english'] = df['maternal_language_2113'] == 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "IbQIty854NCO"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column marital_status_married_or_partner for any row where marital_status_2184 is 'married' or 'partner'\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['marital_status_married_or_partner'] = df['marital_status_2184'].apply(lambda x: True if x in ['married', 'partner'] else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "S1gl61Vo5z9D"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column country_of_origin_USA that is country_of_origin_2186 == united states\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['country_of_origin_USA'] = df['country_of_origin_2186'] == 'united states'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "RDTPeP9U6VUZ"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column employment_status_fulltime that is employment_status_2187 == full time\n",
    "\n",
    "df['employment_status_fulltime'] = df['employment_status_2187'] == 'full time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite_SES_columns = [\n",
    "    \"only_private_insurance\",\n",
    "    \"maternal_language_english\",\n",
    "    \"marital_status_married_or_partner\",\n",
    "    \"country_of_origin_USA\",\n",
    "    \"employment_status_fulltime\",\n",
    "]\n",
    "df['composite_SES_advantage'] = df[composite_SES_columns].all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jR7Kx62O8BNX"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column epidural_needle_type based on anes_procedure_epidural_needle_2263 that can have values \"tuohy\",\"weiss\", or \"other\"\n",
    "\n",
    "# Create the 'epidural_needle_type' column based on 'anes_procedure_epidural_needle_2263'\n",
    "df['epidural_needle_type'] = df['anes_procedure_epidural_needle_2263'].map({\n",
    "    'tuohy': 'tuohy',\n",
    "    'weiss': 'weiss',\n",
    "}).fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "g5Kp4dAM8pQ7"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column paresthesias_present that is anes_procedure_paresthesias_2270 either \"transient\" or \"yes\"\n",
    "\n",
    "# Create the 'paresthesias_present' column\n",
    "df['paresthesias_present'] = df['anes_procedure_paresthesias_2270'].apply(lambda x: True if x == 'yes' or x == 'transient' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_site'] = np.where(df['delivery_site_2188'] == 'mgb', np.nan, df['delivery_site_2188'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['delivery_site'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labor_induction'] = df[[\n",
    "    'induction_oxytocin_2189','induction_cervical_balloon_2190','induction_misoprostol_2191','induction_arom_2192','induction_foley_easy_2193']].any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new unique identifier based on epic_pmrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define identifier range (6-digit numbers)\n",
    "id_len = 8\n",
    "min_id, max_id = 10**(id_len-1), 10**id_len - 1\n",
    "\n",
    "# Create mapping of unique MRNs to unique random identifiers\n",
    "unique_mrns = df['epic_pmrn'].unique()\n",
    "mapping = dict(zip(unique_mrns, random.sample(range(min_id, max_id+1), len(unique_mrns))))\n",
    "\n",
    "# Map to a new column in DataFrame\n",
    "df['unique_pt_id'] = df['epic_pmrn'].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5mjv9mmfl2r"
   },
   "source": [
    "# Save processed data prior to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "LAF1Cqkc04aE"
   },
   "outputs": [],
   "source": [
    "complete_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "SWdKTtPTflV9"
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a pickle file\n",
    "complete_data.to_pickle(my_computer_fpath + \"processed_merlin_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "3AIT25V7f_vj"
   },
   "outputs": [],
   "source": [
    "# prompt: Import libraries and open CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "my_computer_fpath = \"C:\\\\Users\\\\dfber\\\\OneDrive - Mass General Brigham\\\\Epidural project\\\\Data\\\\\"\n",
    "# my_computer_fpath = \"C:\\\\Users\\\\User\\\\OneDrive - Mass General Brigham\\\\Epidural project\\\\Data\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pxsgBzbfzOz"
   },
   "outputs": [],
   "source": [
    "# Load the pickled DataFrame\n",
    "complete_data = pd.read_pickle(my_computer_fpath + \"processed_merlin_data.pkl\")\n",
    "\n",
    "# Now you can work with the DataFrame\n",
    "complete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "zwIzc7441Cot"
   },
   "outputs": [],
   "source": [
    "df = complete_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KddNYcoUiEWD"
   },
   "source": [
    "# Reduce Table to Chosen Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wouftr6X4Z57"
   },
   "outputs": [],
   "source": [
    "# prompt: print all columns as a list and make it easy to read over multiple lines\n",
    "\n",
    "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
    "all_columns = df.columns.tolist()\n",
    "\n",
    "# Print the list of columns, formatted for readability\n",
    "print(\"Columns of the DataFrame:\")\n",
    "for i, col in enumerate(all_columns):\n",
    "    print(f\"{i+1}. {col} ||| {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "EFrTx2-X-Jyx"
   },
   "outputs": [],
   "source": [
    "chosen_features = [\n",
    "#    \"id\",\n",
    "    \"unique_pt_id\",\n",
    "    \"anes_procedure_encounter_id_2273\",\n",
    "    \"gestational_age_2052\",\n",
    "    \"delivery_site\",\n",
    "    \"baby_weight_2196\",\n",
    "    \"rom_thru_delivery_hours\",\n",
    "    \"fetal_presentation_category_2243\",\n",
    "    \"fetal_presentation_position_2247\",\n",
    "    \"bmi_end_pregnancy_2044\",\n",
    "    \"maternal_weight_end_pregnancy_2045\",\n",
    "    \"bmi_before_pregnancy_2161\",\n",
    "#    \"zipcode_2185\",\n",
    "    \"gravidity_2047\",\n",
    "    \"parity_2048\",\n",
    "#    \"anes_procedure_note_text_2271\",\n",
    "#    \"best_timestamp\",\n",
    "#    \"true_procedure_type\",\n",
    "    \"is_neuraxial_catheter\",\n",
    "    \"failed_catheter\",\n",
    "#    \"dpe\",\n",
    "    \"lor_depth\",\n",
    "    \"current_resident_catheter_count\",\n",
    "    \"highly_experienced_anesthesiologist\",\n",
    "    \"highly_experienced_resident\",\n",
    "    \"current_anesthesiologist_catheter_count\",\n",
    "    \"moderately_experienced_anesthesiologist\",\n",
    "    \"has_scoliosis\",\n",
    "    \"has_dorsalgia\",\n",
    "    \"has_back_problems\",\n",
    "    \"maternal_race\",\n",
    " #   \"prior_pain_scores\",\n",
    "    \"prior_pain_scores_max\",\n",
    "    \"composite_psychosocial_problems\",\n",
    "    \"only_private_insurance\",\n",
    "    \"maternal_language_english\",\n",
    "    \"marital_status_married_or_partner\",\n",
    "    \"country_of_origin_USA\",\n",
    "    \"employment_status_fulltime\",\n",
    "    \"composite_SES_advantage\",\n",
    "    \"epidural_needle_type\",\n",
    "    \"paresthesias_present\",\n",
    "    \"number_of_neuraxial_attempts\",\n",
    "    \"prior_failed_catheters_this_enc\",\n",
    "    \"prior_failed_catheters_prev_enc\",\n",
    "    \"prior_all_catheters_all_enc\",\n",
    "    \"true_procedure_type_incl_dpe\",\n",
    "    \"maternal_age_years\",\n",
    "    \"placement_to_delivery_hours\",\n",
    "    \"labor_induction\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "Nr0wa_Zq-RfA"
   },
   "outputs": [],
   "source": [
    "df = df[chosen_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIr75B_tGNEV"
   },
   "outputs": [],
   "source": [
    "# prompt: print all columns as a list and make it easy to read over multiple lines\n",
    "\n",
    "all_columns = df.columns.tolist()\n",
    "\n",
    "# Print the list of columns, formatted for readability\n",
    "print(\"Columns of the DataFrame:\")\n",
    "for i, col in enumerate(all_columns):\n",
    "    print(f\"{i+1}. {col} ||| {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(my_computer_fpath + 'minimal_merlin_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKPV6NaW7+ZRxbDtLw/frD",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
