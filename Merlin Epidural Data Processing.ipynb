{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkobyQHnHmfr"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1510,
     "status": "ok",
     "timestamp": 1736530922442,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "aEvYxZF4wEa5"
   },
   "outputs": [],
   "source": [
    "# prompt: Import libraries and open CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\dfber\\\\Downloads\\\\e26f9ccc-68a4-42b4-9d0d-508a83026a1c.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdfber\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124me26f9ccc-68a4-42b4-9d0d-508a83026a1c.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m raw_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m raw_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\dfber\\\\Downloads\\\\e26f9ccc-68a4-42b4-9d0d-508a83026a1c.csv'"
     ]
    }
   ],
   "source": [
    "file_path = 'C:\\\\Users\\\\dfber\\\\Downloads\\\\e26f9ccc-68a4-42b4-9d0d-508a83026a1c.csv'\n",
    "raw_df = pd.read_csv(file_path)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOA_rFqsHpti"
   },
   "source": [
    "# Initialize dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1736530959963,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "3JVX6R_71rmO"
   },
   "outputs": [],
   "source": [
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1736530959963,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "a8iWzW6vNMw_",
    "outputId": "7aad273b-378d-4227-fba4-658a36b093c3"
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLFyVswb3COk"
   },
   "source": [
    "# Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKsF6foXHuki"
   },
   "source": [
    "## Explode |-separated notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "executionInfo": {
     "elapsed": 10728,
     "status": "ok",
     "timestamp": 1736530970931,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "o31L3yCtyk8b",
    "outputId": "94d1b142-bb7f-4c30-a3a5-1ffe281d48a2"
   },
   "outputs": [],
   "source": [
    "# Expand the items in anes_procedure_cols separated by \"|\" into a separate row\n",
    "# Requires that within a row, each element in these columns has the same number of |-separated values\n",
    "\n",
    "anes_procedure_cols = ['anes_procedure_type_2253', 'anes_procedure_start_dts_2254', 'anes_procedure_anesthesiologist_2255', 'anes_procedure_resident_2256', 'anes_procedure_pt_position_2257', 'anes_procedure_approach_2258', 'anes_procedure_location_2259', 'anes_procedure_note_id_2260', 'anes_procedure_dos_dts_2261', 'anes_procedure_dpe_2262', 'anes_procedure_epidural_needle_2263', 'anes_procedure_epidural_needle_gauge_2264', 'anes_procedure_lor_depth_2265', 'anes_procedure_catheter_depth_2266', 'anes_procedure_spinal_needle_type_2267', 'anes_procedure_spinal_needle_gauge_2268', 'anes_procedure_spinal_needle_length_2269', 'anes_procedure_paresthesias_2270', 'anes_procedure_note_text_2271','anes_procedure_encounter_id_2273']\n",
    "\n",
    "# Split the columns with '|' delimiter\n",
    "for col in anes_procedure_cols:\n",
    "    df[col] = df[col].str.split('\\|')\n",
    "\n",
    "# Explode the DataFrame\n",
    "df = df.explode(anes_procedure_cols)\n",
    "\n",
    "# Reset the index after exploding the DataFrame so each individual note will be its own unique row and index\n",
    "df = df.reset_index(drop=True)\n",
    "df[['id','anes_procedure_type_2253']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ISNBfVtIQUV"
   },
   "source": [
    "## Handle datetime issues\n",
    "\n",
    "Bug: Merlin is bringing anes_procedure_dos_dts_2261 as Eastern times when in fact they are UTC. I resolve this by editing the raw strings before conversion to datetime objects.\n",
    "\n",
    "Bug: Merlin ignores AM/PM in anes_procedure_start_dts_2254 and assumes all entries are AM. I resolve this (for now) by ignoring these written start times and just using dos_dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736530971128,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "wvOG3uHacl8a",
    "outputId": "8073b0ad-ce09-4bf8-b263-4e33328c614c"
   },
   "outputs": [],
   "source": [
    "df['anes_procedure_dos_dts_2261'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1736530971354,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "7wXrBA3dqi9-"
   },
   "outputs": [],
   "source": [
    "df['dos_dts_tz_stripped'] = df['anes_procedure_dos_dts_2261'].str.replace(r'[+-]\\d{4}$', '+0000', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736530971354,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "Xr3WN2fPqt0s",
    "outputId": "02555a21-792e-4eb9-f467-48cacf199f08"
   },
   "outputs": [],
   "source": [
    "df['dos_dts_tz_stripped'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1736530971541,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "DCHq2py6nN7m"
   },
   "outputs": [],
   "source": [
    "df['dos_dts'] = pd.to_datetime(df['dos_dts_tz_stripped'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1736530971541,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "SmhS28lCbYIn",
    "outputId": "09720cfa-430c-4aa9-fdb8-9cfdee75f903"
   },
   "outputs": [],
   "source": [
    "df[['dos_dts','anes_procedure_dos_dts_2261']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1736530972209,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "59dC3WB-ZH8-"
   },
   "outputs": [],
   "source": [
    "df['start_dts'] = pd.to_datetime(df['anes_procedure_start_dts_2254'],format='mixed',utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1736530972393,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "giGm_VZXdG5i",
    "outputId": "eec08e3c-c2d3-494f-ccb7-301cd698e376"
   },
   "outputs": [],
   "source": [
    "# prompt: df['start_dts'].max() but ignore the date, look only at the time\n",
    "\n",
    "# Extract the time part of the 'start_dts' column\n",
    "df[df['start_dts'].notna()]['start_dts'].dt.time.sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736530972394,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "ohVRiD_RRohx"
   },
   "outputs": [],
   "source": [
    "# This code has been changed to avoid the AM/PM bug\n",
    "\n",
    "# df['best_timestamp'] = df['start_dts'].fillna(df['dos_dts'])\n",
    "df['best_timestamp'] = df['dos_dts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JPfIBsGQjpd"
   },
   "source": [
    "## Handle near-duplicate notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1736530972582,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "NWaRarfN02K-",
    "outputId": "ae5481b2-a589-4186-dbae-c795cb6b4fbc"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known double-note\n",
    "df.loc[df['anes_procedure_note_id_2260'] == '1188076153']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736530972582,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "mnHDJKKiRXbP"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known near-duplicate note\n",
    "df[df['anes_procedure_note_id_2260'] == '2250605132']\n",
    "known_near_duplicate_encounter_id = df[df['anes_procedure_note_id_2260'] == '2250605132']['anes_procedure_encounter_id_2273'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1736530973222,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "TOPEviTcRkZh",
    "outputId": "aec51ac4-9ffc-4f1e-ba14-2d8e3f0c661f"
   },
   "outputs": [],
   "source": [
    "known_near_duplicate_group = df.groupby('anes_procedure_encounter_id_2273').get_group(known_near_duplicate_encounter_id)\n",
    "known_near_duplicate_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1736530973223,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "JSG6sdjYiQUt"
   },
   "outputs": [],
   "source": [
    "# prompt: add 'best_timestamp', 'dos_dts', and 'start_dts' to anes_procedure_cols\n",
    "\n",
    "anes_procedure_cols.extend(['best_timestamp', 'dos_dts', 'start_dts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736530973223,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "HYmiFDuGhkWU"
   },
   "outputs": [],
   "source": [
    "# need to narrow operations to a smaller group of columns for efficiency\n",
    "\n",
    "df_anes_procedure_cols = df[anes_procedure_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736530973223,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "eu4qZbZoSOzk"
   },
   "outputs": [],
   "source": [
    "# Functions to label near_duplicate procedures\n",
    "\n",
    "# Compare two rows and return True if their timestamps are within minute_offset\n",
    "# and their compare_cols match\n",
    "def check_if_near_duplicate(row1, row2, compare_cols, minute_offset):\n",
    "  for col in compare_cols:\n",
    "    if not pd.isnull(row1[col]) and not pd.isnull(row2[col]):\n",
    "      if row1[col] != row2[col]:\n",
    "        return False\n",
    "  if abs(row1['best_timestamp'] - row2['best_timestamp']) > pd.Timedelta(minutes=minute_offset):\n",
    "    return False\n",
    "  return True\n",
    "\n",
    "\n",
    "# Label near_duplicate notes within an encounter using the check_if_near_duplicate function\n",
    "def label_near_duplicate_notes(encounter):\n",
    "\n",
    "  indices = encounter.index.tolist()\n",
    "\n",
    "  for i in range(len(indices)):\n",
    "    base_idx = indices[i]\n",
    "    base_row = encounter.loc[base_idx]\n",
    "    has_near_duplicate = 0\n",
    "    near_duplicates = [base_row['anes_procedure_note_id_2260']]\n",
    "\n",
    "    for j in range(len(indices)):\n",
    "      if i == j:\n",
    "        continue # don't identify self-duplicates\n",
    "      compare_idx = indices[j]\n",
    "      compare_row = encounter.loc[compare_idx]\n",
    "\n",
    "\n",
    "      if check_if_near_duplicate(base_row, compare_row, ['anes_procedure_type_2253'], minute_offset = 30):\n",
    "        has_near_duplicate = 1\n",
    "        near_duplicates.append(compare_row['anes_procedure_note_id_2260'])\n",
    "\n",
    "    encounter.at[base_idx, 'has_near_duplicate'] = has_near_duplicate\n",
    "    encounter.at[base_idx, 'near_duplicate_note_ids'] = str(sorted(near_duplicates))\n",
    "\n",
    "  return encounter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101110,
     "status": "ok",
     "timestamp": 1736531074331,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "xEMrr-2XVCCh",
    "outputId": "483342da-f140-4e9a-8dc5-7f6732b07474"
   },
   "outputs": [],
   "source": [
    "# Label near_duplicate procedures\n",
    "# Takes ~2 mins\n",
    "\n",
    "df_anes_procedure_cols['has_near_duplicate'] = 0\n",
    "df_anes_procedure_cols['near_duplicate_note_ids'] = None\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(label_near_duplicate_notes, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1736531074332,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "G85sWqU4lqPU"
   },
   "outputs": [],
   "source": [
    "# prompt: sort df_anes_procedure_cols by index\n",
    "\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1736531074693,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "x2GqpOxYjtZX"
   },
   "outputs": [],
   "source": [
    "# Count blank columns\n",
    "df_anes_procedure_cols['blank_anes_procedure_element_col_counts'] = df_anes_procedure_cols[anes_procedure_cols].isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 81883,
     "status": "ok",
     "timestamp": 1736531156575,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "hQS2Po3LY2ML"
   },
   "outputs": [],
   "source": [
    "# Within a group of duplicates, label the one with the fewest blank columns as NOT the worse duplicate (i.e., the best)\n",
    "# Takes ~2 mins\n",
    "def label_worse_near_duplicates(near_duplicate_set):\n",
    "  near_duplicate_set.at[near_duplicate_set['blank_anes_procedure_element_col_counts'].idxmin(), 'is_worse_near_duplicate'] = 0\n",
    "  return near_duplicate_set\n",
    "\n",
    "df_anes_procedure_cols['is_worse_near_duplicate'] = df_anes_procedure_cols['has_near_duplicate']\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('near_duplicate_note_ids').apply(label_worse_near_duplicates, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('near_duplicate_note_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1736531157076,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "RityoHtEpCUt",
    "outputId": "05a5e03d-0594-45d6-9308-7d4337556887"
   },
   "outputs": [],
   "source": [
    "known_near_duplicate_group = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').get_group(known_near_duplicate_encounter_id)\n",
    "known_near_duplicate_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1736531157077,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "wsvcrtEC00aO",
    "outputId": "8400b1c1-79eb-4cc8-9326-15c541f04197"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known double-note\n",
    "known_double_note = df_anes_procedure_cols.loc[df_anes_procedure_cols['anes_procedure_note_id_2260'] == '1188076153']\n",
    "known_double_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736531157077,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "bfpW-_GU1OMs",
    "outputId": "9accb36a-5455-4705-efe2-fecb239e3ab4"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_worse_near_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1736531157211,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "U3D_vdCFpPVn"
   },
   "outputs": [],
   "source": [
    "# Remove worse duplicates\n",
    "df_anes_procedure_cols = df_anes_procedure_cols[df_anes_procedure_cols['is_worse_near_duplicate']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtFesSAK1wsT"
   },
   "source": [
    "## Address cases where an epidural note followed by a spinal note is actually a planned CSE, not a failed catheter. Also address what 'epidural/intrathecal' really means.\n",
    "\n",
    "Secret CSEs are spinal and epidural within 5 mins\n",
    "\n",
    "Epidural/intrathecal notes are declared epidural unless ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736531157211,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "oAlkUSFd15mb"
   },
   "outputs": [],
   "source": [
    "# Functions to label secret_CSE procedures\n",
    "\n",
    "# Compare two rows and return True if exactly one is an epidural, exactly one is a spinal,\n",
    "# and if their timestamps are within minute_offset\n",
    "def check_if_secret_CSE(row1, row2, minute_offset):\n",
    "  if abs(row1['best_timestamp'] - row2['best_timestamp']) < pd.Timedelta(minutes=minute_offset):\n",
    "    if row1['anes_procedure_type_2253'] == 'epidural/intrathecal' or row1['anes_procedure_type_2253'] == 'epidural':\n",
    "      if row2['anes_procedure_type_2253'] == 'spinal':\n",
    "        return True\n",
    "    if row2['anes_procedure_type_2253'] == 'epidural/intrathecal' or row2['anes_procedure_type_2253'] == 'epidural':\n",
    "      if row1['anes_procedure_type_2253'] == 'spinal':\n",
    "        return True\n",
    "  return False\n",
    "\n",
    "# Label secret_CSE notes within an encounter using the check_if_secret_CSE function\n",
    "def label_secret_CSE_notes(encounter):\n",
    "\n",
    "  indices = encounter.index.tolist()\n",
    "\n",
    "  for i in range(len(indices)):\n",
    "    base_idx = indices[i]\n",
    "    base_row = encounter.loc[base_idx]\n",
    "    is_secret_CSE = 0\n",
    "    secret_CSEs = [base_row['anes_procedure_note_id_2260']]\n",
    "\n",
    "    for j in range(len(indices)):\n",
    "      if i == j:\n",
    "        continue # don't identify self-duplicates\n",
    "      compare_idx = indices[j]\n",
    "      compare_row = encounter.loc[compare_idx]\n",
    "\n",
    "      if check_if_secret_CSE(base_row, compare_row, minute_offset = 5):\n",
    "        is_secret_CSE = 1\n",
    "        secret_CSEs.append(compare_row['anes_procedure_note_id_2260'])\n",
    "\n",
    "    encounter.at[base_idx, 'is_secret_CSE'] = is_secret_CSE\n",
    "    encounter.at[base_idx, 'secret_CSE_note_ids'] = str(sorted(secret_CSEs))\n",
    "\n",
    "  return encounter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105396,
     "status": "ok",
     "timestamp": 1736531262605,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "fUFcrD6XD55I",
    "outputId": "5ee4c703-2ed9-4c80-eeab-a4814c32ea2f"
   },
   "outputs": [],
   "source": [
    "# Label secret_CSE procedures\n",
    "# Takes ~2 mins\n",
    "\n",
    "df_anes_procedure_cols['is_secret_CSE'] = 0\n",
    "df_anes_procedure_cols['secret_CSE_note_ids'] = None\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(label_secret_CSE_notes, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "ZuMTbsM8FEyp",
    "outputId": "5c5dce82-576e-4a0e-924a-708fa1f9426b"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_secret_CSE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "eTslzEhqFQ0i",
    "outputId": "0fdc2f29-c26e-412e-cde0-1a23158a35ce"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols[df_anes_procedure_cols['is_secret_CSE'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "cVHEDdpkITEk"
   },
   "outputs": [],
   "source": [
    "# Eliminate the separately-documented spinals that are really part of CSEs\n",
    "\n",
    "# Delete rows where procedure_type is spinal and is_secret_CSE is true\n",
    "df_anes_procedure_cols = df_anes_procedure_cols[~((df_anes_procedure_cols['anes_procedure_type_2253'] == 'spinal') & (df_anes_procedure_cols['is_secret_CSE'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "1APs69qNJtY2",
    "outputId": "0e5eb7f6-c9ed-479a-99c5-414e37d3098c"
   },
   "outputs": [],
   "source": [
    "# Label true intrathecal catheters\n",
    "# NOTE: DOES NOT YET RECLASSIFY EPIDURAL/INTRATHECALS BY CSF ASPIRATION OR ANY OTHER METHOD\n",
    "\n",
    "df_anes_procedure_cols['is_intrathecal_catheter'] = (df_anes_procedure_cols['anes_procedure_type_2253'] == 'intrathecal').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1736531262822,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "_3REoY6SKHwu",
    "outputId": "3f78d9e6-2e30-4187-b04b-5437fc7a5dd4"
   },
   "outputs": [],
   "source": [
    "# prompt: label true_procedure_type by reclassifying based on is_secret_CSE and is_intrathecal_catheter\n",
    "\n",
    "# Create the 'true_procedure_type' column based on the conditions\n",
    "df_anes_procedure_cols['true_procedure_type'] = np.where(\n",
    "    df_anes_procedure_cols['is_secret_CSE'] == True,'cse',\n",
    "    df_anes_procedure_cols['anes_procedure_type_2253'])\n",
    "\n",
    "# Update 'true_procedure_type' based on 'is_intrathecal_catheter'\n",
    "df_anes_procedure_cols.loc[\n",
    "    (df_anes_procedure_cols['true_procedure_type'].isin(['epidural/intrathecal', 'intrathecal'])) &\n",
    "    (df_anes_procedure_cols['is_intrathecal_catheter'] == True),\n",
    "    'true_procedure_type'] = 'intrathecal'\n",
    "\n",
    "df_anes_procedure_cols.loc[\n",
    "    (df_anes_procedure_cols['true_procedure_type'] == 'epidural/intrathecal') &\n",
    "    (df_anes_procedure_cols['is_intrathecal_catheter'] == False),\n",
    "    'true_procedure_type'] = 'epidural'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1736531262822,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "xMX_LrGBJUg9",
    "outputId": "448f07ea-ef57-4287-8afb-f2cc33f9a2dc"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nlc5uOLquoP_"
   },
   "source": [
    "# Classify failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1736531262823,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "VglLLyHlvMy0"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_neuraxial_catheter'] = (df_anes_procedure_cols['true_procedure_type'].isin(['cse', 'epidural', 'intrathecal'])).astype(int)\n",
    "df_anes_procedure_cols['is_spinal'] = (df_anes_procedure_cols['true_procedure_type'] == 'spinal').astype(int)\n",
    "df_anes_procedure_cols['is_airway'] = (df_anes_procedure_cols['true_procedure_type'] == 'airway').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "DmRHrn9durRv"
   },
   "outputs": [],
   "source": [
    "# Vectorized method to classify as successes or failures\n",
    "# takes ~10 mins\n",
    "\n",
    "def classify_encounter_failures(encounter):\n",
    "\n",
    "    # Identify rows where 'is_neuraxial_catheter' == 1\n",
    "    neuraxial_rows = encounter[encounter['is_neuraxial_catheter'] == 1]\n",
    "\n",
    "    # If no neuraxial catheter procedures, return encounter as is\n",
    "    if neuraxial_rows.empty:\n",
    "        return encounter\n",
    "\n",
    "    # Create a mask for failure-defining events within the encounter\n",
    "    # Failure-defining events are neuraxial catheters, spinals, and airways\n",
    "    failure_defining_event_mask = encounter[['is_neuraxial_catheter','is_spinal','is_airway']].any(axis=1)\n",
    "\n",
    "    # Get the indices of events\n",
    "    failure_defining_event_indices = encounter.index[failure_defining_event_mask]\n",
    "\n",
    "    # Iterate over neuraxial catheter rows\n",
    "    for idx in neuraxial_rows.index:\n",
    "        current_time = encounter.at[idx, 'best_timestamp']\n",
    "\n",
    "        # Find subsequent events\n",
    "        # This relies on correct ordering by best_timestamp\n",
    "        subsequent_failure_defining_events = encounter.loc[failure_defining_event_indices]\n",
    "        subsequent_failure_defining_events = subsequent_failure_defining_events[subsequent_failure_defining_events['best_timestamp'] > current_time]\n",
    "\n",
    "        # Initialize flags\n",
    "        has_subsequent_neuraxial_catheter = 0\n",
    "        has_subsequent_spinal = 0\n",
    "        has_subsequent_airway = 0\n",
    "        failed_catheter = 0\n",
    "        subsequent_proof_of_failure_note_id = None\n",
    "\n",
    "        # Check for subsequent procedures\n",
    "        if not subsequent_failure_defining_events.empty:\n",
    "            # Update flags based on any occurrence in subsequent events\n",
    "            has_subsequent_neuraxial_catheter = int((subsequent_failure_defining_events['is_neuraxial_catheter'] == 1).any())\n",
    "            has_subsequent_spinal = int((subsequent_failure_defining_events['is_spinal'] == 1).any())\n",
    "            has_subsequent_airway = int((subsequent_failure_defining_events['is_airway'] == 1).any())\n",
    "            failed_catheter = int(has_subsequent_neuraxial_catheter or has_subsequent_spinal or has_subsequent_airway)\n",
    "            subsequent_proof_of_failure_note_id = subsequent_failure_defining_events['anes_procedure_note_id_2260'].tolist()\n",
    "\n",
    "            encounter.at[idx, 'has_subsequent_neuraxial_catheter'] = has_subsequent_neuraxial_catheter\n",
    "            encounter.at[idx, 'has_subsequent_spinal'] = has_subsequent_spinal\n",
    "            encounter.at[idx, 'has_subsequent_airway'] = has_subsequent_airway\n",
    "            encounter.at[idx, 'failed_catheter'] = failed_catheter\n",
    "            encounter.at[idx, 'subsequent_proof_of_failure_note_id'] = str(subsequent_proof_of_failure_note_id)\n",
    "\n",
    "    return encounter\n",
    "\n",
    "df_anes_procedure_cols['has_subsequent_neuraxial_catheter'] = 0\n",
    "df_anes_procedure_cols['has_subsequent_spinal'] = 0\n",
    "df_anes_procedure_cols['has_subsequent_airway'] = 0\n",
    "df_anes_procedure_cols['failed_catheter'] = 0\n",
    "df_anes_procedure_cols['subsequent_proof_of_failure_note_id'] = None\n",
    "\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(classify_encounter_failures, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY63Lf9aV-cZ"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "gzPV1CsfnsJD"
   },
   "outputs": [],
   "source": [
    "# prompt: concatenate new columns from df_anes_procedure_cols into df. only bring the new columns, leave behind the matching ones. Select the new columns via code.\n",
    "\n",
    "# Identify new columns in df_anes_procedure_cols that are not in df\n",
    "new_cols = [col for col in df_anes_procedure_cols.columns if col not in df.columns]\n",
    "\n",
    "# Concatenate only the new columns from df_anes_procedure_cols to df\n",
    "df = pd.concat([df, df_anes_procedure_cols[new_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "WqfMMOV8Do1r"
   },
   "outputs": [],
   "source": [
    "df['is_neuraxial_catheter'] = df['is_neuraxial_catheter'] == 1\n",
    "df['failed_catheter'] = df['failed_catheter'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "likLZC_lwNhJ"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCec8U6S0QeF"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known double-note\n",
    "known_double_note = df.loc[df['anes_procedure_note_id_2260'] == '1188076153']\n",
    "known_double_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP0RDHaa0rmz"
   },
   "outputs": [],
   "source": [
    "df[df['failed_catheter'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "In0JgcPXBgtB"
   },
   "outputs": [],
   "source": [
    "known_failed_catheter_encounter_ids = ['3259099621','3081317750', '3081399139', '3081675427', '3081686082', '3081711691', '3081729928', '3081884584', '3081893356', '3082275619', '3082349091']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Xawf8qwCPXj"
   },
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'].isin(known_failed_catheter_encounter_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPBvuAV6NRli"
   },
   "source": [
    "# Additional Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "757vQkZucKbN"
   },
   "source": [
    "## Handle timeseries data (e.g., pain scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VUtFAxcFdliC"
   },
   "outputs": [],
   "source": [
    "# Extracts the pain scores prior to the timestamp\n",
    "# Takes ~ 1 minute\n",
    "def get_pain_scores_prior_to_timestamp(row, best_timestamp_col=\"best_timestamp\"):\n",
    "    \"\"\"\n",
    "    Extract all pain scores that have timestamp < row[best_timestamp_col].\n",
    "\n",
    "    row: a single row of your DataFrame (a pd.Series)\n",
    "    best_timestamp_col: name of the column in your DataFrame that contains\n",
    "                       the 'best_timestamp' to compare against\n",
    "\n",
    "    Returns a list of 'prior' scores or NaN if none exist.\n",
    "    \"\"\"\n",
    "    # Extract the raw strings\n",
    "    times_str = row[\"timeseries_intrapartum_pain_score_datetime_2242\"]\n",
    "    scores_str = row[\"timeseries_intrapartum_pain_score_2242\"]\n",
    "\n",
    "    # If either is missing, return NaN\n",
    "    if pd.isna(times_str) or pd.isna(scores_str):\n",
    "        return np.nan\n",
    "\n",
    "    # Convert to lists\n",
    "    times_list = times_str.split(\"|\")\n",
    "    scores_list = scores_str.split(\"|\")\n",
    "\n",
    "    # Safely convert both times and best_timestamp to datetime\n",
    "    try:\n",
    "        times_dt = pd.to_datetime(times_list)\n",
    "        # This assumes your row also has a column called best_timestamp_col\n",
    "        best_dt = pd.to_datetime(row[best_timestamp_col])\n",
    "    except:\n",
    "        # If conversion fails, return NaN\n",
    "        return np.nan\n",
    "\n",
    "    # Filter out all scores whose timestamp is strictly less than best_timestamp\n",
    "    prior_scores = []\n",
    "    for t, s in zip(times_dt, scores_list):\n",
    "        if t < best_dt:\n",
    "            prior_scores.append(float(s))\n",
    "\n",
    "    # If no scores remain, return NaN, else return them joined or as list\n",
    "    return prior_scores if prior_scores else np.nan\n",
    "\n",
    "df['prior_pain_scores'] = df.apply(get_pain_scores_prior_to_timestamp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Dto2g0HfeCuC"
   },
   "outputs": [],
   "source": [
    "df[\"prior_pain_scores_max\"] = df[\"prior_pain_scores\"].apply(\n",
    "    lambda scores: max(map(float, scores)) if isinstance(scores, list) and scores else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "x6LMgIHofOYD"
   },
   "outputs": [],
   "source": [
    "df['prior_pain_scores_max'].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3n9mBjG2mKn"
   },
   "source": [
    "## Clean DPE and LOR_Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "18FwO5sbNj3r"
   },
   "outputs": [],
   "source": [
    "# make 'dpe' True/False\n",
    "df['dpe'] = df['anes_procedure_dpe_2262'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7ldb0bDxNTGo"
   },
   "outputs": [],
   "source": [
    "# make 'lor_depth' numeric\n",
    "df['lor_depth'] = df['anes_procedure_lor_depth_2265'].replace('', np.nan).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZuSyUaAeN4r1"
   },
   "outputs": [],
   "source": [
    "# Code to evaluate suspiciously high LORs\n",
    "# For these, if we divide LOR by 10, the the catheter is taped around 4-5 cm deeper\n",
    "# So most likely these suspiciously high LORs are missing decimal points\n",
    "high_LORs = df.sort_values(by='lor_depth',ascending=False).head(100)['lor_depth']\n",
    "print(high_LORs.to_list())\n",
    "plt.hist(high_LORs)\n",
    "\n",
    "print(df.sort_values(by='lor_depth',ascending=False).head(100)['anes_procedure_catheter_depth_2266'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7YS3I4MEN8OG"
   },
   "outputs": [],
   "source": [
    "# prompt: lor_depth = lor_depth / 10 if lor_depth > 20\n",
    "\n",
    "df['lor_depth'] = np.where(df['lor_depth'] > 20, df['lor_depth'] / 10, df['lor_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EALlbR6-OUaQ"
   },
   "outputs": [],
   "source": [
    "# Code to evaluate suspiciously high LORs\n",
    "high_LORs = df.sort_values(by='lor_depth',ascending=False).head(100)['lor_depth']\n",
    "print(high_LORs.to_list())\n",
    "plt.hist(high_LORs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjq02Q_U2ucI"
   },
   "source": [
    "## Make numerical columns numerical and plausible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "RH4BDg1__d1h"
   },
   "outputs": [],
   "source": [
    "# prompt: set these columns to dtype float: bmi_end_pregnancy_2044, maternal_weight_end_pregnancy_2045, maternal_height_2046,gravidity_2047,parity_2048\n",
    "\n",
    "# Convert specified columns to float dtype\n",
    "columns_to_convert = ['gestational_age_2052','bmi_end_pregnancy_2044', 'maternal_weight_end_pregnancy_2045', 'maternal_height_2046', 'gravidity_2047', 'parity_2048','baby_weight_2196','bmi_before_pregnancy_2161','secs_rom_thru_delivery_2197']\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "        except KeyError:\n",
    "            print(f\"Column '{col}' not found in the DataFrame.\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' not found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "gkTCwVcyOtX3"
   },
   "outputs": [],
   "source": [
    "# If ROM through Delivery is more than 30 days, assume erroneous and make it NaN\n",
    "df['rom_thru_delivery_hours'] = df['secs_rom_thru_delivery_2197'] / 3600\n",
    "df['rom_thru_delivery_hours'] = np.where(df['rom_thru_delivery_hours'] <= 30*24, df['rom_thru_delivery_hours'],np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rdMZOcI2xZH"
   },
   "source": [
    "## Handle proceduralist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "K44x6YG-9GCD"
   },
   "outputs": [],
   "source": [
    "# Function to regulate names\n",
    "def regulate_name(name):\n",
    "\n",
    "    # Remove degrees and titles\n",
    "    name = re.sub(r',?\\s*(md|do|mbbs|phd|ms|mba|mph|msc|crna)\\b', '', name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Split last name and first name if comma exists\n",
    "    if ',' in name:\n",
    "        last, first = name.split(',', 1)\n",
    "        name = f\"{first.strip()} {last.strip()}\"\n",
    "\n",
    "    # Remove extra spaces\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "    # Remove middle names\n",
    "    parts = name.split()\n",
    "    if len(parts) > 2 :\n",
    "      name = f\"{parts[0]} {parts[-1]}\"\n",
    "\n",
    "    # Capitalize each part of the name\n",
    "    name = name.title()\n",
    "\n",
    "    return name\n",
    "\n",
    "# Apply the function to regulate names\n",
    "df['Regulated_Anesthesiologist_Name'] = df['anes_procedure_anesthesiologist_2255'].dropna().apply(regulate_name)\n",
    "df['Regulated_Resident_Name'] = df['anes_procedure_resident_2256'].dropna().apply(regulate_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "oXOr9Udky9qK"
   },
   "outputs": [],
   "source": [
    "# prompt: set all blank Regulated_Anesthesiologist_Name and Regulated_Resident_Name to NaN\n",
    "\n",
    "df['Regulated_Anesthesiologist_Name'] = df['Regulated_Anesthesiologist_Name'].replace('', np.nan)\n",
    "df['Regulated_Resident_Name'] = df['Regulated_Resident_Name'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Lm5KJJXfZaPD"
   },
   "outputs": [],
   "source": [
    "# prompt: For each catheter, count how many (i.e., earlier best_timestamp) catheters were done by that provider (including the current one)\n",
    "\n",
    "df = df.sort_values('best_timestamp')\n",
    "\n",
    "df['current_anesthesiologist_catheter_count'] = (\n",
    "    df.groupby('Regulated_Anesthesiologist_Name')['is_neuraxial_catheter']\n",
    "      .cumsum()\n",
    ")\n",
    "\n",
    "df['current_resident_catheter_count'] = (\n",
    "    df.groupby('Regulated_Resident_Name')['is_neuraxial_catheter']\n",
    "      .cumsum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "czc7KflO5Laq"
   },
   "outputs": [],
   "source": [
    "df['highly_experienced_anesthesiologist'] = np.where(df['current_anesthesiologist_catheter_count'] > 500, 'yes',\n",
    "                                                    np.where(df['current_anesthesiologist_catheter_count'] <= 500, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "_Flgn1iczuHP"
   },
   "outputs": [],
   "source": [
    "df['moderately_experienced_anesthesiologist'] = np.where(df['current_anesthesiologist_catheter_count'] > 100, 'yes',\n",
    "                                                        np.where(df['current_anesthesiologist_catheter_count'] <= 100, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "EOo7CtAq5Y6X"
   },
   "outputs": [],
   "source": [
    "# prompt: set df['highly_experienced_resident'] to 1 if current_resident_catheter_count > 50, to 0 if <= 50, and to -1 if NaN\n",
    "\n",
    "df['highly_experienced_resident'] = np.where(df['current_resident_catheter_count'] > 50, 'yes',\n",
    "                                                    np.where(df['current_resident_catheter_count'] <= 50, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqbNsz2U26MN"
   },
   "source": [
    "## Feature engineering on categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "Cd-k3VRq4r1e"
   },
   "outputs": [],
   "source": [
    "df['has_scoliosis'] = df['icd_scoliosis_2053'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "tsUb1icS5IAj"
   },
   "outputs": [],
   "source": [
    "df['has_dorsalgia'] = df['icd_dorsalgia_2104'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "zKT4Wd683p7p"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column \"has_back_problems\" that is 1 where any of the following are True, else 0. Handle NaN.\n",
    "\n",
    "# Define the columns related to back problems\n",
    "back_problem_cols = [\n",
    "    'icd_scoliosis_2053',\n",
    "    'icd_spinal_fusion_2056',\n",
    "    'icd_congenital_deformity_spine_2059',\n",
    "    'icd_ra_and_sctds_2086',\n",
    "    'icd_kyphosis_and_lordosis_2089',\n",
    "    'icd_spinal_osteochondrosis_2092',\n",
    "    'icd_spondylopathies_and_deforming_dorsopathies_2095',\n",
    "    'icd_intervertebral_disc_disorders_2098',\n",
    "    'icd_ehlers_minus_danlos_2101',\n",
    "]\n",
    "\n",
    "# Note that spondyolopathies_and_deforming_dorsopathies are by far the biggest contributors\n",
    "\n",
    "# Create the 'has_back_problems' column\n",
    "df['has_back_problems'] = df[back_problem_cols].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "zLsKQUhDDGtI"
   },
   "outputs": [],
   "source": [
    "df['maternal_race'] = np.select(\n",
    "    [\n",
    "        df['maternal_race_2111'] == 'White',\n",
    "        df['maternal_race_2111'] == 'Asian',\n",
    "        df['maternal_race_2111'] == 'Black'\n",
    "    ],\n",
    "    [\n",
    "        'White',\n",
    "        'Asian',\n",
    "        'Black'\n",
    "    ],\n",
    "    default='Other/Unknown'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "5av_qh2lmXoe"
   },
   "outputs": [],
   "source": [
    "composite_social_columns = [\n",
    "    \"drug_abuse_during_parent_2144\",\n",
    "    \"high_risk_social_problems_parent_2154\",\n",
    "    \"high_risk_insufficient_antenatal_care_parent_2157\",\n",
    "    \"icd_major_mental_health_disorder_2178\",\n",
    "    \"education_problems_2203\",\n",
    "    \"employment_problems_2206\",\n",
    "    \"adverse_occupational_2209\",\n",
    "    \"housing_problems_2212\",\n",
    "    \"adjustment_problems_2215\",\n",
    "    \"relationship_problems_2218\",\n",
    "    \"other_psychosocial_2221\",\n",
    "    \"smoker_during_pregnancy_parent_2117\",\n",
    "    \"drug_abuse_before_parent_2142\",\n",
    "    \"alcohol_during_parent_2147\",\n",
    "]\n",
    "\n",
    "df['composite_psychosocial_problems'] = df[composite_social_columns].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "nf7G1is51Ipc"
   },
   "outputs": [],
   "source": [
    "# prompt: create column 'any_public_insurance' for any row where public_insurance_2114 contains the string \"public\", ignore case\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['any_public_insurance'] = df['public_insurance_2114'].str.contains('public', case=False, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "Vmdv_72612D3"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column maternal_language_english for any row where maternal_language is english\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['maternal_language_english'] = df['maternal_language_2113'] == 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "IbQIty854NCO"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column marital_status_married_or_partner for any row where marital_status_2184 is 'married' or 'partner'\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['marital_status_married_or_partner'] = df['marital_status_2184'].apply(lambda x: True if x in ['married', 'partner'] else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "S1gl61Vo5z9D"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column country_of_origin_USA that is country_of_origin_2186 == united states\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['country_of_origin_USA'] = df['country_of_origin_2186'] == 'united states'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "RDTPeP9U6VUZ"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column employment_status_fulltime that is employment_status_2187 == full time\n",
    "\n",
    "df['employment_status_fulltime'] = df['employment_status_2187'] == 'full time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jR7Kx62O8BNX"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column epidural_needle_type based on anes_procedure_epidural_needle_2263 that can have values \"tuohy\",\"weiss\", or \"other\"\n",
    "\n",
    "# Create the 'epidural_needle_type' column based on 'anes_procedure_epidural_needle_2263'\n",
    "df['epidural_needle_type'] = df['anes_procedure_epidural_needle_2263'].map({\n",
    "    'tuohy': 'tuohy',\n",
    "    'weiss': 'weiss',\n",
    "}).fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "g5Kp4dAM8pQ7"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column paresthesias_present that is anes_procedure_paresthesias_2270 either \"transient\" or \"yes\"\n",
    "\n",
    "# Create the 'paresthesias_present' column\n",
    "df['paresthesias_present'] = df['anes_procedure_paresthesias_2270'].apply(lambda x: True if x == 'yes' or x == 'transient' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSroCYMT-ivC"
   },
   "source": [
    "# Manually analyze some successes and failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6ZbxgXCJ-oyn"
   },
   "outputs": [],
   "source": [
    "# prompt: Choose 10 random failed_catheters and 10 random non-failed_catheters\n",
    "\n",
    "# Assuming 'df' is your DataFrame and it contains a column 'failed_catheter'\n",
    "failed_catheters = df[df['failed_catheter'] == 1]\n",
    "non_failed_catheters = df[df['failed_catheter'] == 0]\n",
    "\n",
    "# Randomly choose 10 failed catheters\n",
    "random_failed_catheters = failed_catheters.sample(n=10, random_state=42)  # random_state for reproducibility\n",
    "chosen_failed_catheter_encounter_ids = ['3324914343','3272008150','3234765502','3305371022','3216449190','3186345033','3493903332','3285273066','3320528828','3191160118']\n",
    "chosen_failed_catheters = df[df['anes_procedure_encounter_id_2273'].isin(chosen_failed_catheter_encounter_ids)]\n",
    "\n",
    "# Randomly choose 10 non-failed catheters\n",
    "random_non_failed_catheters = non_failed_catheters.sample(n=10, random_state=42) # random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gL3Ch3cqssS8"
   },
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"anes_procedure_encounter_id_2273\",\n",
    "    \"best_timestamp\",\n",
    "    \"failed_catheter\",\n",
    "    \"true_procedure_type\",\n",
    "    \"anes_procedure_note_id_2260\",\n",
    "    \"subsequent_proof_of_failure_note_id\",\n",
    "    \"Regulated_Anesthesiologist_Name\",\n",
    "    \"Regulated_Resident_Name\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8zp4dCl5AETI"
   },
   "outputs": [],
   "source": [
    "random_failed_catheters[column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9P_kVEUcgp_z"
   },
   "outputs": [],
   "source": [
    "chosen_failed_catheters[column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sHxyrIgEAalV"
   },
   "outputs": [],
   "source": [
    "random_non_failed_catheters[column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KHxNRJ4YDEHO"
   },
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'] == '3191160118']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5mjv9mmfl2r"
   },
   "source": [
    "# Save processed data prior to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "LAF1Cqkc04aE"
   },
   "outputs": [],
   "source": [
    "complete_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "SWdKTtPTflV9"
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a pickle file\n",
    "complete_data.to_pickle('C:\\\\Users\\\\dfber\\\\Desktop\\\\processed_merlin_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3AIT25V7f_vj"
   },
   "outputs": [],
   "source": [
    "# prompt: Import libraries and open CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2pxsgBzbfzOz"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\dfber\\\\Desktop\\\\processed_merlin_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the pickled DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m complete_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdfber\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mprocessed_merlin_data.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Now you can work with the DataFrame\u001b[39;00m\n\u001b[0;32m      5\u001b[0m complete_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\dfber\\\\Desktop\\\\processed_merlin_data.pkl'"
     ]
    }
   ],
   "source": [
    "# Load the pickled DataFrame\n",
    "complete_data = pd.read_pickle('C:\\\\Users\\\\dfber\\\\Desktop\\\\processed_merlin_data.pkl')\n",
    "\n",
    "# Now you can work with the DataFrame\n",
    "complete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "zwIzc7441Cot"
   },
   "outputs": [],
   "source": [
    "df = complete_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KddNYcoUiEWD"
   },
   "source": [
    "# Reduce Table to Chosen Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wouftr6X4Z57"
   },
   "outputs": [],
   "source": [
    "# prompt: print all columns as a list and make it easy to read over multiple lines\n",
    "\n",
    "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
    "all_columns = df.columns.tolist()\n",
    "\n",
    "# Print the list of columns, formatted for readability\n",
    "print(\"Columns of the DataFrame:\")\n",
    "for i, col in enumerate(all_columns):\n",
    "    print(f\"{i+1}. {col} ||| {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "EFrTx2-X-Jyx"
   },
   "outputs": [],
   "source": [
    "chosen_features = [\n",
    "#    \"id\",\n",
    "    \"gestational_age_2052\",\n",
    "    \"delivery_site_2188\",\n",
    "    \"baby_weight_2196\",\n",
    "    \"rom_thru_delivery_hours\",\n",
    "    \"fetal_presentation_category_2243\",\n",
    "    \"fetal_presentation_subcategory_2244\",\n",
    "    \"fetal_presentation_position_2247\",\n",
    "    \"bmi_end_pregnancy_2044\",\n",
    "    \"maternal_weight_end_pregnancy_2045\",\n",
    "    \"bmi_before_pregnancy_2161\",\n",
    "#    \"zipcode_2185\",\n",
    "    \"gravidity_2047\",\n",
    "    \"parity_2048\",\n",
    "#    \"anes_procedure_note_text_2271\",\n",
    "#    \"best_timestamp\",\n",
    "    \"true_procedure_type\",\n",
    "    \"is_neuraxial_catheter\",\n",
    "    \"failed_catheter\",\n",
    "    \"dpe\",\n",
    "    \"lor_depth\",\n",
    "    \"current_resident_catheter_count\",\n",
    "    \"highly_experienced_anesthesiologist\",\n",
    "    \"highly_experienced_resident\",\n",
    "    \"current_anesthesiologist_catheter_count\",\n",
    "    \"moderately_experienced_anesthesiologist\",\n",
    "    \"has_scoliosis\",\n",
    "    \"has_dorsalgia\",\n",
    "    \"has_back_problems\",\n",
    "    \"maternal_race\",\n",
    " #   \"prior_pain_scores\",\n",
    "    \"prior_pain_scores_max\",\n",
    "    \"composite_psychosocial_problems\",\n",
    "    \"any_public_insurance\",\n",
    "    \"maternal_language_english\",\n",
    "    \"marital_status_married_or_partner\",\n",
    "    \"country_of_origin_USA\",\n",
    "    \"employment_status_fulltime\",\n",
    "    \"epidural_needle_type\",\n",
    "    \"paresthesias_present\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "Nr0wa_Zq-RfA"
   },
   "outputs": [],
   "source": [
    "df = df[chosen_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;28;01mTrue\u001b[39;00m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m: \u001b[38;5;241m0\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIr75B_tGNEV"
   },
   "outputs": [],
   "source": [
    "# prompt: print all columns as a list and make it easy to read over multiple lines\n",
    "\n",
    "all_columns = df.columns.tolist()\n",
    "\n",
    "# Print the list of columns, formatted for readability\n",
    "print(\"Columns of the DataFrame:\")\n",
    "for i, col in enumerate(all_columns):\n",
    "    print(f\"{i+1}. {col} ||| {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:\\\\Users\\\\dfber\\\\Desktop\\\\minimal_merlin_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKPV6NaW7+ZRxbDtLw/frD",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
