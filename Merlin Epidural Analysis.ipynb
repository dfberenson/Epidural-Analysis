{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkobyQHnHmfr"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1510,
     "status": "ok",
     "timestamp": 1736530922442,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "aEvYxZF4wEa5"
   },
   "outputs": [],
   "source": [
    "# prompt: Import libraries and open CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:\\\\Users\\\\dfber\\\\Downloads\\\\e26f9ccc-68a4-42b4-9d0d-508a83026a1c.csv'\n",
    "raw_df = pd.read_csv(file_path)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOA_rFqsHpti"
   },
   "source": [
    "# Initialize dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1736530959963,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "3JVX6R_71rmO"
   },
   "outputs": [],
   "source": [
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1736530959963,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "a8iWzW6vNMw_",
    "outputId": "7aad273b-378d-4227-fba4-658a36b093c3"
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLFyVswb3COk"
   },
   "source": [
    "# Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKsF6foXHuki"
   },
   "source": [
    "## Explode |-separated notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "executionInfo": {
     "elapsed": 10728,
     "status": "ok",
     "timestamp": 1736530970931,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "o31L3yCtyk8b",
    "outputId": "94d1b142-bb7f-4c30-a3a5-1ffe281d48a2"
   },
   "outputs": [],
   "source": [
    "# Expand the items in anes_procedure_cols separated by \"|\" into a separate row\n",
    "# Requires that within a row, each element in these columns has the same number of |-separated values\n",
    "\n",
    "anes_procedure_cols = ['anes_procedure_type_2253', 'anes_procedure_start_dts_2254', 'anes_procedure_anesthesiologist_2255', 'anes_procedure_resident_2256', 'anes_procedure_pt_position_2257', 'anes_procedure_approach_2258', 'anes_procedure_location_2259', 'anes_procedure_note_id_2260', 'anes_procedure_dos_dts_2261', 'anes_procedure_dpe_2262', 'anes_procedure_epidural_needle_2263', 'anes_procedure_epidural_needle_gauge_2264', 'anes_procedure_lor_depth_2265', 'anes_procedure_catheter_depth_2266', 'anes_procedure_spinal_needle_type_2267', 'anes_procedure_spinal_needle_gauge_2268', 'anes_procedure_spinal_needle_length_2269', 'anes_procedure_paresthesias_2270', 'anes_procedure_note_text_2271','anes_procedure_encounter_id_2273']\n",
    "\n",
    "# Split the columns with '|' delimiter\n",
    "for col in anes_procedure_cols:\n",
    "    df[col] = df[col].str.split('\\|')\n",
    "\n",
    "# Explode the DataFrame\n",
    "df = df.explode(anes_procedure_cols)\n",
    "\n",
    "# Reset the index after exploding the DataFrame so each individual note will be its own unique row and index\n",
    "df = df.reset_index(drop=True)\n",
    "df[['id','anes_procedure_type_2253']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ISNBfVtIQUV"
   },
   "source": [
    "## Handle datetime issues\n",
    "\n",
    "Bug: Merlin is bringing anes_procedure_dos_dts_2261 as Eastern times when in fact they are UTC. I resolve this by editing the raw strings before conversion to datetime objects.\n",
    "\n",
    "Bug: Merlin ignores AM/PM in anes_procedure_start_dts_2254 and assumes all entries are AM. I resolve this (for now) by ignoring these written start times and just using dos_dts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736530971128,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "wvOG3uHacl8a",
    "outputId": "8073b0ad-ce09-4bf8-b263-4e33328c614c"
   },
   "outputs": [],
   "source": [
    "df['anes_procedure_dos_dts_2261'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1736530971354,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "7wXrBA3dqi9-"
   },
   "outputs": [],
   "source": [
    "df['dos_dts_tz_stripped'] = df['anes_procedure_dos_dts_2261'].str.replace(r'[+-]\\d{4}$', '+0000', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736530971354,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "Xr3WN2fPqt0s",
    "outputId": "02555a21-792e-4eb9-f467-48cacf199f08"
   },
   "outputs": [],
   "source": [
    "df['dos_dts_tz_stripped'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1736530971541,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "DCHq2py6nN7m"
   },
   "outputs": [],
   "source": [
    "df['dos_dts'] = pd.to_datetime(df['dos_dts_tz_stripped'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1736530971541,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "SmhS28lCbYIn",
    "outputId": "09720cfa-430c-4aa9-fdb8-9cfdee75f903"
   },
   "outputs": [],
   "source": [
    "df[['dos_dts','anes_procedure_dos_dts_2261']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1736530972209,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "59dC3WB-ZH8-"
   },
   "outputs": [],
   "source": [
    "df['start_dts'] = pd.to_datetime(df['anes_procedure_start_dts_2254'],format='mixed',utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1736530972393,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "giGm_VZXdG5i",
    "outputId": "eec08e3c-c2d3-494f-ccb7-301cd698e376"
   },
   "outputs": [],
   "source": [
    "# prompt: df['start_dts'].max() but ignore the date, look only at the time\n",
    "\n",
    "# Extract the time part of the 'start_dts' column\n",
    "df[df['start_dts'].notna()]['start_dts'].dt.time.sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736530972394,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "ohVRiD_RRohx"
   },
   "outputs": [],
   "source": [
    "# This code has been changed to avoid the AM/PM bug\n",
    "\n",
    "# df['best_timestamp'] = df['start_dts'].fillna(df['dos_dts'])\n",
    "df['best_timestamp'] = df['dos_dts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JPfIBsGQjpd"
   },
   "source": [
    "## Handle near-duplicate notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1736530972582,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "NWaRarfN02K-",
    "outputId": "ae5481b2-a589-4186-dbae-c795cb6b4fbc"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known double-note\n",
    "df.loc[df['anes_procedure_note_id_2260'] == '1188076153']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736530972582,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "mnHDJKKiRXbP"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known near-duplicate note\n",
    "df[df['anes_procedure_note_id_2260'] == '2250605132']\n",
    "known_near_duplicate_encounter_id = df[df['anes_procedure_note_id_2260'] == '2250605132']['anes_procedure_encounter_id_2273'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1736530973222,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "TOPEviTcRkZh",
    "outputId": "aec51ac4-9ffc-4f1e-ba14-2d8e3f0c661f"
   },
   "outputs": [],
   "source": [
    "known_near_duplicate_group = df.groupby('anes_procedure_encounter_id_2273').get_group(known_near_duplicate_encounter_id)\n",
    "known_near_duplicate_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1736530973223,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "JSG6sdjYiQUt"
   },
   "outputs": [],
   "source": [
    "# prompt: add 'best_timestamp', 'dos_dts', and 'start_dts' to anes_procedure_cols\n",
    "\n",
    "anes_procedure_cols.extend(['best_timestamp', 'dos_dts', 'start_dts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736530973223,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "HYmiFDuGhkWU"
   },
   "outputs": [],
   "source": [
    "# need to narrow operations to a smaller group of columns for efficiency\n",
    "\n",
    "df_anes_procedure_cols = df[anes_procedure_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736530973223,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "eu4qZbZoSOzk"
   },
   "outputs": [],
   "source": [
    "# Functions to label near_duplicate procedures\n",
    "\n",
    "# Compare two rows and return True if their timestamps are within minute_offset\n",
    "# and their compare_cols match\n",
    "def check_if_near_duplicate(row1, row2, compare_cols, minute_offset):\n",
    "  for col in compare_cols:\n",
    "    if not pd.isnull(row1[col]) and not pd.isnull(row2[col]):\n",
    "      if row1[col] != row2[col]:\n",
    "        return False\n",
    "  if abs(row1['best_timestamp'] - row2['best_timestamp']) > pd.Timedelta(minutes=minute_offset):\n",
    "    return False\n",
    "  return True\n",
    "\n",
    "\n",
    "# Label near_duplicate notes within an encounter using the check_if_near_duplicate function\n",
    "def label_near_duplicate_notes(encounter):\n",
    "\n",
    "  indices = encounter.index.tolist()\n",
    "\n",
    "  for i in range(len(indices)):\n",
    "    base_idx = indices[i]\n",
    "    base_row = encounter.loc[base_idx]\n",
    "    has_near_duplicate = 0\n",
    "    near_duplicates = [base_row['anes_procedure_note_id_2260']]\n",
    "\n",
    "    for j in range(len(indices)):\n",
    "      if i == j:\n",
    "        continue # don't identify self-duplicates\n",
    "      compare_idx = indices[j]\n",
    "      compare_row = encounter.loc[compare_idx]\n",
    "\n",
    "\n",
    "      if check_if_near_duplicate(base_row, compare_row, ['anes_procedure_type_2253'], minute_offset = 30):\n",
    "        has_near_duplicate = 1\n",
    "        near_duplicates.append(compare_row['anes_procedure_note_id_2260'])\n",
    "\n",
    "    encounter.at[base_idx, 'has_near_duplicate'] = has_near_duplicate\n",
    "    encounter.at[base_idx, 'near_duplicate_note_ids'] = str(sorted(near_duplicates))\n",
    "\n",
    "  return encounter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101110,
     "status": "ok",
     "timestamp": 1736531074331,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "xEMrr-2XVCCh",
    "outputId": "483342da-f140-4e9a-8dc5-7f6732b07474"
   },
   "outputs": [],
   "source": [
    "# Label near_duplicate procedures\n",
    "# Takes ~2 mins\n",
    "\n",
    "df_anes_procedure_cols['has_near_duplicate'] = 0\n",
    "df_anes_procedure_cols['near_duplicate_note_ids'] = None\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(label_near_duplicate_notes, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1736531074332,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "G85sWqU4lqPU"
   },
   "outputs": [],
   "source": [
    "# prompt: sort df_anes_procedure_cols by index\n",
    "\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1736531074693,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "x2GqpOxYjtZX"
   },
   "outputs": [],
   "source": [
    "# Count blank columns\n",
    "df_anes_procedure_cols['blank_anes_procedure_element_col_counts'] = df_anes_procedure_cols[anes_procedure_cols].isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 81883,
     "status": "ok",
     "timestamp": 1736531156575,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "hQS2Po3LY2ML"
   },
   "outputs": [],
   "source": [
    "# Within a group of duplicates, label the one with the fewest blank columns as NOT the worse duplicate (i.e., the best)\n",
    "# Takes ~2 mins\n",
    "def label_worse_near_duplicates(near_duplicate_set):\n",
    "  near_duplicate_set.at[near_duplicate_set['blank_anes_procedure_element_col_counts'].idxmin(), 'is_worse_near_duplicate'] = 0\n",
    "  return near_duplicate_set\n",
    "\n",
    "df_anes_procedure_cols['is_worse_near_duplicate'] = df_anes_procedure_cols['has_near_duplicate']\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('near_duplicate_note_ids').apply(label_worse_near_duplicates, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('near_duplicate_note_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1736531157076,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "RityoHtEpCUt",
    "outputId": "05a5e03d-0594-45d6-9308-7d4337556887"
   },
   "outputs": [],
   "source": [
    "known_near_duplicate_group = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').get_group(known_near_duplicate_encounter_id)\n",
    "known_near_duplicate_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1736531157077,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "wsvcrtEC00aO",
    "outputId": "8400b1c1-79eb-4cc8-9326-15c541f04197"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known double-note\n",
    "known_double_note = df_anes_procedure_cols.loc[df_anes_procedure_cols['anes_procedure_note_id_2260'] == '1188076153']\n",
    "known_double_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1736531157077,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "bfpW-_GU1OMs",
    "outputId": "9accb36a-5455-4705-efe2-fecb239e3ab4"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_worse_near_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1736531157211,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "U3D_vdCFpPVn"
   },
   "outputs": [],
   "source": [
    "# Remove worse duplicates\n",
    "df_anes_procedure_cols = df_anes_procedure_cols[df_anes_procedure_cols['is_worse_near_duplicate']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtFesSAK1wsT"
   },
   "source": [
    "## Address cases where an epidural note followed by a spinal note is actually a planned CSE, not a failed catheter. Also address what 'epidural/intrathecal' really means.\n",
    "\n",
    "Secret CSEs are spinal and epidural within 5 mins\n",
    "\n",
    "Epidural/intrathecal notes are declared epidural unless ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736531157211,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "oAlkUSFd15mb"
   },
   "outputs": [],
   "source": [
    "# Functions to label secret_CSE procedures\n",
    "\n",
    "# Compare two rows and return True if exactly one is an epidural, exactly one is a spinal,\n",
    "# and if their timestamps are within minute_offset\n",
    "def check_if_secret_CSE(row1, row2, minute_offset):\n",
    "  if abs(row1['best_timestamp'] - row2['best_timestamp']) < pd.Timedelta(minutes=minute_offset):\n",
    "    if row1['anes_procedure_type_2253'] == 'epidural/intrathecal' or row1['anes_procedure_type_2253'] == 'epidural':\n",
    "      if row2['anes_procedure_type_2253'] == 'spinal':\n",
    "        return True\n",
    "    if row2['anes_procedure_type_2253'] == 'epidural/intrathecal' or row2['anes_procedure_type_2253'] == 'epidural':\n",
    "      if row1['anes_procedure_type_2253'] == 'spinal':\n",
    "        return True\n",
    "  return False\n",
    "\n",
    "# Label secret_CSE notes within an encounter using the check_if_secret_CSE function\n",
    "def label_secret_CSE_notes(encounter):\n",
    "\n",
    "  indices = encounter.index.tolist()\n",
    "\n",
    "  for i in range(len(indices)):\n",
    "    base_idx = indices[i]\n",
    "    base_row = encounter.loc[base_idx]\n",
    "    is_secret_CSE = 0\n",
    "    secret_CSEs = [base_row['anes_procedure_note_id_2260']]\n",
    "\n",
    "    for j in range(len(indices)):\n",
    "      if i == j:\n",
    "        continue # don't identify self-duplicates\n",
    "      compare_idx = indices[j]\n",
    "      compare_row = encounter.loc[compare_idx]\n",
    "\n",
    "      if check_if_secret_CSE(base_row, compare_row, minute_offset = 5):\n",
    "        is_secret_CSE = 1\n",
    "        secret_CSEs.append(compare_row['anes_procedure_note_id_2260'])\n",
    "\n",
    "    encounter.at[base_idx, 'is_secret_CSE'] = is_secret_CSE\n",
    "    encounter.at[base_idx, 'secret_CSE_note_ids'] = str(sorted(secret_CSEs))\n",
    "\n",
    "  return encounter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 105396,
     "status": "ok",
     "timestamp": 1736531262605,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "fUFcrD6XD55I",
    "outputId": "5ee4c703-2ed9-4c80-eeab-a4814c32ea2f"
   },
   "outputs": [],
   "source": [
    "# Label secret_CSE procedures\n",
    "# Takes ~2 mins\n",
    "\n",
    "df_anes_procedure_cols['is_secret_CSE'] = 0\n",
    "df_anes_procedure_cols['secret_CSE_note_ids'] = None\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(label_secret_CSE_notes, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "ZuMTbsM8FEyp",
    "outputId": "5c5dce82-576e-4a0e-924a-708fa1f9426b"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_secret_CSE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "eTslzEhqFQ0i",
    "outputId": "0fdc2f29-c26e-412e-cde0-1a23158a35ce"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols[df_anes_procedure_cols['is_secret_CSE'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "cVHEDdpkITEk"
   },
   "outputs": [],
   "source": [
    "# Eliminate the separately-documented spinals that are really part of CSEs\n",
    "\n",
    "# Delete rows where procedure_type is spinal and is_secret_CSE is true\n",
    "df_anes_procedure_cols = df_anes_procedure_cols[~((df_anes_procedure_cols['anes_procedure_type_2253'] == 'spinal') & (df_anes_procedure_cols['is_secret_CSE'] == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1736531262606,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "1APs69qNJtY2",
    "outputId": "0e5eb7f6-c9ed-479a-99c5-414e37d3098c"
   },
   "outputs": [],
   "source": [
    "# Label true intrathecal catheters\n",
    "# NOTE: DOES NOT YET RECLASSIFY EPIDURAL/INTRATHECALS BY CSF ASPIRATION OR ANY OTHER METHOD\n",
    "\n",
    "df_anes_procedure_cols['is_intrathecal_catheter'] = (df_anes_procedure_cols['anes_procedure_type_2253'] == 'intrathecal').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1736531262822,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "_3REoY6SKHwu",
    "outputId": "3f78d9e6-2e30-4187-b04b-5437fc7a5dd4"
   },
   "outputs": [],
   "source": [
    "# prompt: label true_procedure_type by reclassifying based on is_secret_CSE and is_intrathecal_catheter\n",
    "\n",
    "# Create the 'true_procedure_type' column based on the conditions\n",
    "df_anes_procedure_cols['true_procedure_type'] = np.where(\n",
    "    df_anes_procedure_cols['is_secret_CSE'] == True,'cse',\n",
    "    df_anes_procedure_cols['anes_procedure_type_2253'])\n",
    "\n",
    "# Update 'true_procedure_type' based on 'is_intrathecal_catheter'\n",
    "df_anes_procedure_cols.loc[\n",
    "    (df_anes_procedure_cols['true_procedure_type'].isin(['epidural/intrathecal', 'intrathecal'])) &\n",
    "    (df_anes_procedure_cols['is_intrathecal_catheter'] == True),\n",
    "    'true_procedure_type'] = 'intrathecal'\n",
    "\n",
    "df_anes_procedure_cols.loc[\n",
    "    (df_anes_procedure_cols['true_procedure_type'] == 'epidural/intrathecal') &\n",
    "    (df_anes_procedure_cols['is_intrathecal_catheter'] == False),\n",
    "    'true_procedure_type'] = 'epidural'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1736531262822,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "xMX_LrGBJUg9",
    "outputId": "448f07ea-ef57-4287-8afb-f2cc33f9a2dc"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nlc5uOLquoP_"
   },
   "source": [
    "# Classify failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1736531262823,
     "user": {
      "displayName": "Daniel Berenson",
      "userId": "01641759045451756668"
     },
     "user_tz": 300
    },
    "id": "VglLLyHlvMy0"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols['is_neuraxial_catheter'] = (df_anes_procedure_cols['true_procedure_type'].isin(['cse', 'epidural', 'intrathecal'])).astype(int)\n",
    "df_anes_procedure_cols['is_spinal'] = (df_anes_procedure_cols['true_procedure_type'] == 'spinal').astype(int)\n",
    "df_anes_procedure_cols['is_airway'] = (df_anes_procedure_cols['true_procedure_type'] == 'airway').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "DmRHrn9durRv"
   },
   "outputs": [],
   "source": [
    "# Vectorized method to classify as successes or failures\n",
    "# takes ~10 mins\n",
    "\n",
    "def classify_encounter_failures(encounter):\n",
    "\n",
    "    # Identify rows where 'is_neuraxial_catheter' == 1\n",
    "    neuraxial_rows = encounter[encounter['is_neuraxial_catheter'] == 1]\n",
    "\n",
    "    # If no neuraxial catheter procedures, return encounter as is\n",
    "    if neuraxial_rows.empty:\n",
    "        return encounter\n",
    "\n",
    "    # Create a mask for failure-defining events within the encounter\n",
    "    # Failure-defining events are neuraxial catheters, spinals, and airways\n",
    "    failure_defining_event_mask = encounter[['is_neuraxial_catheter','is_spinal','is_airway']].any(axis=1)\n",
    "\n",
    "    # Get the indices of events\n",
    "    failure_defining_event_indices = encounter.index[failure_defining_event_mask]\n",
    "\n",
    "    # Iterate over neuraxial catheter rows\n",
    "    for idx in neuraxial_rows.index:\n",
    "        current_time = encounter.at[idx, 'best_timestamp']\n",
    "\n",
    "        # Find subsequent events\n",
    "        # This relies on correct ordering by best_timestamp\n",
    "        subsequent_failure_defining_events = encounter.loc[failure_defining_event_indices]\n",
    "        subsequent_failure_defining_events = subsequent_failure_defining_events[subsequent_failure_defining_events['best_timestamp'] > current_time]\n",
    "\n",
    "        # Initialize flags\n",
    "        has_subsequent_neuraxial_catheter = 0\n",
    "        has_subsequent_spinal = 0\n",
    "        has_subsequent_airway = 0\n",
    "        failed_catheter = 0\n",
    "        subsequent_proof_of_failure_note_id = None\n",
    "\n",
    "        # Check for subsequent procedures\n",
    "        if not subsequent_failure_defining_events.empty:\n",
    "            # Update flags based on any occurrence in subsequent events\n",
    "            has_subsequent_neuraxial_catheter = int((subsequent_failure_defining_events['is_neuraxial_catheter'] == 1).any())\n",
    "            has_subsequent_spinal = int((subsequent_failure_defining_events['is_spinal'] == 1).any())\n",
    "            has_subsequent_airway = int((subsequent_failure_defining_events['is_airway'] == 1).any())\n",
    "            failed_catheter = int(has_subsequent_neuraxial_catheter or has_subsequent_spinal or has_subsequent_airway)\n",
    "            subsequent_proof_of_failure_note_id = subsequent_failure_defining_events['anes_procedure_note_id_2260'].tolist()\n",
    "\n",
    "            encounter.at[idx, 'has_subsequent_neuraxial_catheter'] = has_subsequent_neuraxial_catheter\n",
    "            encounter.at[idx, 'has_subsequent_spinal'] = has_subsequent_spinal\n",
    "            encounter.at[idx, 'has_subsequent_airway'] = has_subsequent_airway\n",
    "            encounter.at[idx, 'failed_catheter'] = failed_catheter\n",
    "            encounter.at[idx, 'subsequent_proof_of_failure_note_id'] = str(subsequent_proof_of_failure_note_id)\n",
    "\n",
    "    return encounter\n",
    "\n",
    "df_anes_procedure_cols['has_subsequent_neuraxial_catheter'] = 0\n",
    "df_anes_procedure_cols['has_subsequent_spinal'] = 0\n",
    "df_anes_procedure_cols['has_subsequent_airway'] = 0\n",
    "df_anes_procedure_cols['failed_catheter'] = 0\n",
    "df_anes_procedure_cols['subsequent_proof_of_failure_note_id'] = None\n",
    "\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.groupby('anes_procedure_encounter_id_2273').apply(classify_encounter_failures, include_groups = False)\n",
    "df_anes_procedure_cols = df_anes_procedure_cols.reset_index('anes_procedure_encounter_id_2273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY63Lf9aV-cZ"
   },
   "outputs": [],
   "source": [
    "df_anes_procedure_cols.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "gzPV1CsfnsJD"
   },
   "outputs": [],
   "source": [
    "# prompt: concatenate new columns from df_anes_procedure_cols into df. only bring the new columns, leave behind the matching ones. Select the new columns via code.\n",
    "\n",
    "# Identify new columns in df_anes_procedure_cols that are not in df\n",
    "new_cols = [col for col in df_anes_procedure_cols.columns if col not in df.columns]\n",
    "\n",
    "# Concatenate only the new columns from df_anes_procedure_cols to df\n",
    "df = pd.concat([df, df_anes_procedure_cols[new_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "WqfMMOV8Do1r"
   },
   "outputs": [],
   "source": [
    "df['is_neuraxial_catheter'] = df['is_neuraxial_catheter'] == 1\n",
    "df['failed_catheter'] = df['failed_catheter'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "likLZC_lwNhJ"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCec8U6S0QeF"
   },
   "outputs": [],
   "source": [
    "# test behavior on a known double-note\n",
    "known_double_note = df.loc[df['anes_procedure_note_id_2260'] == '1188076153']\n",
    "known_double_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP0RDHaa0rmz"
   },
   "outputs": [],
   "source": [
    "df[df['failed_catheter'] == 1].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "In0JgcPXBgtB"
   },
   "outputs": [],
   "source": [
    "known_failed_catheter_encounter_ids = ['3259099621','3081317750', '3081399139', '3081675427', '3081686082', '3081711691', '3081729928', '3081884584', '3081893356', '3082275619', '3082349091']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Xawf8qwCPXj"
   },
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'].isin(known_failed_catheter_encounter_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPBvuAV6NRli"
   },
   "source": [
    "# Additional Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "757vQkZucKbN"
   },
   "source": [
    "## Handle timeseries data (e.g., pain scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VUtFAxcFdliC"
   },
   "outputs": [],
   "source": [
    "# Extracts the pain scores prior to the timestamp\n",
    "# Takes ~ 1 minute\n",
    "def get_pain_scores_prior_to_timestamp(row, best_timestamp_col=\"best_timestamp\"):\n",
    "    \"\"\"\n",
    "    Extract all pain scores that have timestamp < row[best_timestamp_col].\n",
    "\n",
    "    row: a single row of your DataFrame (a pd.Series)\n",
    "    best_timestamp_col: name of the column in your DataFrame that contains\n",
    "                       the 'best_timestamp' to compare against\n",
    "\n",
    "    Returns a list of 'prior' scores or NaN if none exist.\n",
    "    \"\"\"\n",
    "    # Extract the raw strings\n",
    "    times_str = row[\"timeseries_intrapartum_pain_score_datetime_2242\"]\n",
    "    scores_str = row[\"timeseries_intrapartum_pain_score_2242\"]\n",
    "\n",
    "    # If either is missing, return NaN\n",
    "    if pd.isna(times_str) or pd.isna(scores_str):\n",
    "        return np.nan\n",
    "\n",
    "    # Convert to lists\n",
    "    times_list = times_str.split(\"|\")\n",
    "    scores_list = scores_str.split(\"|\")\n",
    "\n",
    "    # Safely convert both times and best_timestamp to datetime\n",
    "    try:\n",
    "        times_dt = pd.to_datetime(times_list)\n",
    "        # This assumes your row also has a column called best_timestamp_col\n",
    "        best_dt = pd.to_datetime(row[best_timestamp_col])\n",
    "    except:\n",
    "        # If conversion fails, return NaN\n",
    "        return np.nan\n",
    "\n",
    "    # Filter out all scores whose timestamp is strictly less than best_timestamp\n",
    "    prior_scores = []\n",
    "    for t, s in zip(times_dt, scores_list):\n",
    "        if t < best_dt:\n",
    "            prior_scores.append(float(s))\n",
    "\n",
    "    # If no scores remain, return NaN, else return them joined or as list\n",
    "    return prior_scores if prior_scores else np.nan\n",
    "\n",
    "df['prior_pain_scores'] = df.apply(get_pain_scores_prior_to_timestamp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Dto2g0HfeCuC"
   },
   "outputs": [],
   "source": [
    "df[\"prior_pain_scores_max\"] = df[\"prior_pain_scores\"].apply(\n",
    "    lambda scores: max(map(float, scores)) if isinstance(scores, list) and scores else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "x6LMgIHofOYD"
   },
   "outputs": [],
   "source": [
    "df['prior_pain_scores_max'].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3n9mBjG2mKn"
   },
   "source": [
    "## Clean DPE and LOR_Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "18FwO5sbNj3r"
   },
   "outputs": [],
   "source": [
    "# make 'dpe' True/False\n",
    "df['dpe'] = df['anes_procedure_dpe_2262'] == 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7ldb0bDxNTGo"
   },
   "outputs": [],
   "source": [
    "# make 'lor_depth' numeric\n",
    "df['lor_depth'] = df['anes_procedure_lor_depth_2265'].replace('', np.nan).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZuSyUaAeN4r1"
   },
   "outputs": [],
   "source": [
    "# Code to evaluate suspiciously high LORs\n",
    "# For these, if we divide LOR by 10, the the catheter is taped around 4-5 cm deeper\n",
    "# So most likely these suspiciously high LORs are missing decimal points\n",
    "high_LORs = df.sort_values(by='lor_depth',ascending=False).head(100)['lor_depth']\n",
    "print(high_LORs.to_list())\n",
    "plt.hist(high_LORs)\n",
    "\n",
    "print(df.sort_values(by='lor_depth',ascending=False).head(100)['anes_procedure_catheter_depth_2266'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7YS3I4MEN8OG"
   },
   "outputs": [],
   "source": [
    "# prompt: lor_depth = lor_depth / 10 if lor_depth > 20\n",
    "\n",
    "df['lor_depth'] = np.where(df['lor_depth'] > 20, df['lor_depth'] / 10, df['lor_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "EALlbR6-OUaQ"
   },
   "outputs": [],
   "source": [
    "# Code to evaluate suspiciously high LORs\n",
    "high_LORs = df.sort_values(by='lor_depth',ascending=False).head(100)['lor_depth']\n",
    "print(high_LORs.to_list())\n",
    "plt.hist(high_LORs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjq02Q_U2ucI"
   },
   "source": [
    "## Make numerical columns numerical and plausible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "RH4BDg1__d1h"
   },
   "outputs": [],
   "source": [
    "# prompt: set these columns to dtype float: bmi_end_pregnancy_2044, maternal_weight_end_pregnancy_2045, maternal_height_2046,gravidity_2047,parity_2048\n",
    "\n",
    "# Convert specified columns to float dtype\n",
    "columns_to_convert = ['gestational_age_2052','bmi_end_pregnancy_2044', 'maternal_weight_end_pregnancy_2045', 'maternal_height_2046', 'gravidity_2047', 'parity_2048','baby_weight_2196','bmi_before_pregnancy_2161','secs_rom_thru_delivery_2197']\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "        except KeyError:\n",
    "            print(f\"Column '{col}' not found in the DataFrame.\")\n",
    "    else:\n",
    "        print(f\"Column '{col}' not found in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "gkTCwVcyOtX3"
   },
   "outputs": [],
   "source": [
    "# If ROM through Delivery is more than 30 days, assume erroneous and make it NaN\n",
    "df['rom_thru_delivery_hours'] = df['secs_rom_thru_delivery_2197'] / 3600\n",
    "df['rom_thru_delivery_hours'] = np.where(df['rom_thru_delivery_hours'] <= 30*24, df['rom_thru_delivery_hours'],np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rdMZOcI2xZH"
   },
   "source": [
    "## Handle proceduralist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "K44x6YG-9GCD"
   },
   "outputs": [],
   "source": [
    "# Function to regulate names\n",
    "def regulate_name(name):\n",
    "\n",
    "    # Remove degrees and titles\n",
    "    name = re.sub(r',?\\s*(md|do|mbbs|phd|ms|mba|mph|msc|crna)\\b', '', name, flags=re.IGNORECASE)\n",
    "\n",
    "    # Split last name and first name if comma exists\n",
    "    if ',' in name:\n",
    "        last, first = name.split(',', 1)\n",
    "        name = f\"{first.strip()} {last.strip()}\"\n",
    "\n",
    "    # Remove extra spaces\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "    # Remove middle names\n",
    "    parts = name.split()\n",
    "    if len(parts) > 2 :\n",
    "      name = f\"{parts[0]} {parts[-1]}\"\n",
    "\n",
    "    # Capitalize each part of the name\n",
    "    name = name.title()\n",
    "\n",
    "    return name\n",
    "\n",
    "# Apply the function to regulate names\n",
    "df['Regulated_Anesthesiologist_Name'] = df['anes_procedure_anesthesiologist_2255'].dropna().apply(regulate_name)\n",
    "df['Regulated_Resident_Name'] = df['anes_procedure_resident_2256'].dropna().apply(regulate_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "oXOr9Udky9qK"
   },
   "outputs": [],
   "source": [
    "# prompt: set all blank Regulated_Anesthesiologist_Name and Regulated_Resident_Name to NaN\n",
    "\n",
    "df['Regulated_Anesthesiologist_Name'] = df['Regulated_Anesthesiologist_Name'].replace('', np.nan)\n",
    "df['Regulated_Resident_Name'] = df['Regulated_Resident_Name'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Lm5KJJXfZaPD"
   },
   "outputs": [],
   "source": [
    "# prompt: For each catheter, count how many (i.e., earlier best_timestamp) catheters were done by that provider (including the current one)\n",
    "\n",
    "df = df.sort_values('best_timestamp')\n",
    "\n",
    "df['current_anesthesiologist_catheter_count'] = (\n",
    "    df.groupby('Regulated_Anesthesiologist_Name')['is_neuraxial_catheter']\n",
    "      .cumsum()\n",
    ")\n",
    "\n",
    "df['current_resident_catheter_count'] = (\n",
    "    df.groupby('Regulated_Resident_Name')['is_neuraxial_catheter']\n",
    "      .cumsum()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "czc7KflO5Laq"
   },
   "outputs": [],
   "source": [
    "df['highly_experienced_anesthesiologist'] = np.where(df['current_anesthesiologist_catheter_count'] > 500, 'yes',\n",
    "                                                    np.where(df['current_anesthesiologist_catheter_count'] <= 500, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "_Flgn1iczuHP"
   },
   "outputs": [],
   "source": [
    "df['moderately_experienced_anesthesiologist'] = np.where(df['current_anesthesiologist_catheter_count'] > 100, 'yes',\n",
    "                                                        np.where(df['current_anesthesiologist_catheter_count'] <= 100, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "EOo7CtAq5Y6X"
   },
   "outputs": [],
   "source": [
    "# prompt: set df['highly_experienced_resident'] to 1 if current_resident_catheter_count > 50, to 0 if <= 50, and to -1 if NaN\n",
    "\n",
    "df['highly_experienced_resident'] = np.where(df['current_resident_catheter_count'] > 50, 'yes',\n",
    "                                                    np.where(df['current_resident_catheter_count'] <= 50, 'no', 'none'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqbNsz2U26MN"
   },
   "source": [
    "## Feature engineering on categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "Cd-k3VRq4r1e"
   },
   "outputs": [],
   "source": [
    "df['has_scoliosis'] = df['icd_scoliosis_2053'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "tsUb1icS5IAj"
   },
   "outputs": [],
   "source": [
    "df['has_dorsalgia'] = df['icd_dorsalgia_2104'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "zKT4Wd683p7p"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column \"has_back_problems\" that is 1 where any of the following are True, else 0. Handle NaN.\n",
    "\n",
    "# Define the columns related to back problems\n",
    "back_problem_cols = [\n",
    "    'icd_scoliosis_2053',\n",
    "    'icd_spinal_fusion_2056',\n",
    "    'icd_congenital_deformity_spine_2059',\n",
    "    'icd_ra_and_sctds_2086',\n",
    "    'icd_kyphosis_and_lordosis_2089',\n",
    "    'icd_spinal_osteochondrosis_2092',\n",
    "    'icd_spondylopathies_and_deforming_dorsopathies_2095',\n",
    "    'icd_intervertebral_disc_disorders_2098',\n",
    "    'icd_ehlers_minus_danlos_2101',\n",
    "]\n",
    "\n",
    "# Note that spondyolopathies_and_deforming_dorsopathies are by far the biggest contributors\n",
    "\n",
    "# Create the 'has_back_problems' column\n",
    "df['has_back_problems'] = df[back_problem_cols].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "zLsKQUhDDGtI"
   },
   "outputs": [],
   "source": [
    "df['maternal_race'] = np.select(\n",
    "    [\n",
    "        df['maternal_race_2111'] == 'White',\n",
    "        df['maternal_race_2111'] == 'Asian',\n",
    "        df['maternal_race_2111'] == 'Black'\n",
    "    ],\n",
    "    [\n",
    "        'White',\n",
    "        'Asian',\n",
    "        'Black'\n",
    "    ],\n",
    "    default='Other/Unknown'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "5av_qh2lmXoe"
   },
   "outputs": [],
   "source": [
    "composite_social_columns = [\n",
    "    \"drug_abuse_during_parent_2144\",\n",
    "    \"high_risk_social_problems_parent_2154\",\n",
    "    \"high_risk_insufficient_antenatal_care_parent_2157\",\n",
    "    \"icd_major_mental_health_disorder_2178\",\n",
    "    \"education_problems_2203\",\n",
    "    \"employment_problems_2206\",\n",
    "    \"adverse_occupational_2209\",\n",
    "    \"housing_problems_2212\",\n",
    "    \"adjustment_problems_2215\",\n",
    "    \"relationship_problems_2218\",\n",
    "    \"other_psychosocial_2221\",\n",
    "    \"smoker_during_pregnancy_parent_2117\",\n",
    "    \"drug_abuse_before_parent_2142\",\n",
    "    \"alcohol_during_parent_2147\",\n",
    "]\n",
    "\n",
    "df['composite_psychosocial_problems'] = df[composite_social_columns].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "nf7G1is51Ipc"
   },
   "outputs": [],
   "source": [
    "# prompt: create column 'any_public_insurance' for any row where public_insurance_2114 contains the string \"public\", ignore case\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['any_public_insurance'] = df['public_insurance_2114'].str.contains('public', case=False, na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "Vmdv_72612D3"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column maternal_language_english for any row where maternal_language is english\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['maternal_language_english'] = df['maternal_language_2113'] == 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "IbQIty854NCO"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column marital_status_married_or_partner for any row where marital_status_2184 is 'married' or 'partner'\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['marital_status_married_or_partner'] = df['marital_status_2184'].apply(lambda x: True if x in ['married', 'partner'] else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "S1gl61Vo5z9D"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column country_of_origin_USA that is country_of_origin_2186 == united states\n",
    "\n",
    "# Assuming 'df' is your DataFrame.\n",
    "df['country_of_origin_USA'] = df['country_of_origin_2186'] == 'united states'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "RDTPeP9U6VUZ"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column employment_status_fulltime that is employment_status_2187 == full time\n",
    "\n",
    "df['employment_status_fulltime'] = df['employment_status_2187'] == 'full time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jR7Kx62O8BNX"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column epidural_needle_type based on anes_procedure_epidural_needle_2263 that can have values \"tuohy\",\"weiss\", or \"other\"\n",
    "\n",
    "# Create the 'epidural_needle_type' column based on 'anes_procedure_epidural_needle_2263'\n",
    "df['epidural_needle_type'] = df['anes_procedure_epidural_needle_2263'].map({\n",
    "    'tuohy': 'tuohy',\n",
    "    'weiss': 'weiss',\n",
    "}).fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "g5Kp4dAM8pQ7"
   },
   "outputs": [],
   "source": [
    "# prompt: create a column paresthesias_present that is anes_procedure_paresthesias_2270 either \"transient\" or \"yes\"\n",
    "\n",
    "# Create the 'paresthesias_present' column\n",
    "df['paresthesias_present'] = df['anes_procedure_paresthesias_2270'].apply(lambda x: True if x == 'yes' or x == 'transient' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSroCYMT-ivC"
   },
   "source": [
    "# Manually analyze some successes and failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6ZbxgXCJ-oyn"
   },
   "outputs": [],
   "source": [
    "# prompt: Choose 10 random failed_catheters and 10 random non-failed_catheters\n",
    "\n",
    "# Assuming 'df' is your DataFrame and it contains a column 'failed_catheter'\n",
    "failed_catheters = df[df['failed_catheter'] == 1]\n",
    "non_failed_catheters = df[df['failed_catheter'] == 0]\n",
    "\n",
    "# Randomly choose 10 failed catheters\n",
    "random_failed_catheters = failed_catheters.sample(n=10, random_state=42)  # random_state for reproducibility\n",
    "chosen_failed_catheter_encounter_ids = ['3324914343','3272008150','3234765502','3305371022','3216449190','3186345033','3493903332','3285273066','3320528828','3191160118']\n",
    "chosen_failed_catheters = df[df['anes_procedure_encounter_id_2273'].isin(chosen_failed_catheter_encounter_ids)]\n",
    "\n",
    "# Randomly choose 10 non-failed catheters\n",
    "random_non_failed_catheters = non_failed_catheters.sample(n=10, random_state=42) # random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gL3Ch3cqssS8"
   },
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"anes_procedure_encounter_id_2273\",\n",
    "    \"best_timestamp\",\n",
    "    \"failed_catheter\",\n",
    "    \"true_procedure_type\",\n",
    "    \"anes_procedure_note_id_2260\",\n",
    "    \"subsequent_proof_of_failure_note_id\",\n",
    "    \"Regulated_Anesthesiologist_Name\",\n",
    "    \"Regulated_Resident_Name\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8zp4dCl5AETI"
   },
   "outputs": [],
   "source": [
    "random_failed_catheters[column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9P_kVEUcgp_z"
   },
   "outputs": [],
   "source": [
    "chosen_failed_catheters[column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sHxyrIgEAalV"
   },
   "outputs": [],
   "source": [
    "random_non_failed_catheters[column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KHxNRJ4YDEHO"
   },
   "outputs": [],
   "source": [
    "df[df['anes_procedure_encounter_id_2273'] == '3191160118']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5mjv9mmfl2r"
   },
   "source": [
    "# Save processed data prior to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "LAF1Cqkc04aE"
   },
   "outputs": [],
   "source": [
    "complete_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "SWdKTtPTflV9"
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a pickle file\n",
    "complete_data.to_pickle('C:\\\\Users\\\\dfber\\\\Desktop\\\\processed_merlin_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "3AIT25V7f_vj"
   },
   "outputs": [],
   "source": [
    "# prompt: Import libraries and open CSV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2pxsgBzbfzOz"
   },
   "outputs": [],
   "source": [
    "# Load the pickled DataFrame\n",
    "complete_data = pd.read_pickle('C:\\\\Users\\\\dfber\\\\Desktop\\\\processed_merlin_data.pkl')\n",
    "\n",
    "# Now you can work with the DataFrame\n",
    "complete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "zwIzc7441Cot"
   },
   "outputs": [],
   "source": [
    "df = complete_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KddNYcoUiEWD"
   },
   "source": [
    "# Reduce Table to Chosen Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wouftr6X4Z57"
   },
   "outputs": [],
   "source": [
    "# prompt: print all columns as a list and make it easy to read over multiple lines\n",
    "\n",
    "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
    "all_columns = df.columns.tolist()\n",
    "\n",
    "# Print the list of columns, formatted for readability\n",
    "print(\"Columns of the DataFrame:\")\n",
    "for i, col in enumerate(all_columns):\n",
    "    print(f\"{i+1}. {col} ||| {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "EFrTx2-X-Jyx"
   },
   "outputs": [],
   "source": [
    "chosen_features = [\n",
    "#    \"id\",\n",
    "    \"gestational_age_2052\",\n",
    "    \"delivery_site_2188\",\n",
    "    \"baby_weight_2196\",\n",
    "    \"rom_thru_delivery_hours\",\n",
    "    \"fetal_presentation_category_2243\",\n",
    "    \"fetal_presentation_subcategory_2244\",\n",
    "    \"fetal_presentation_position_2247\",\n",
    "    \"bmi_end_pregnancy_2044\",\n",
    "    \"maternal_weight_end_pregnancy_2045\",\n",
    "    \"bmi_before_pregnancy_2161\",\n",
    "#    \"zipcode_2185\",\n",
    "    \"gravidity_2047\",\n",
    "    \"parity_2048\",\n",
    "#    \"anes_procedure_note_text_2271\",\n",
    "#    \"best_timestamp\",\n",
    "    \"true_procedure_type\",\n",
    "    \"is_neuraxial_catheter\",\n",
    "    \"failed_catheter\",\n",
    "    \"dpe\",\n",
    "    \"lor_depth\",\n",
    "    \"current_resident_catheter_count\",\n",
    "    \"highly_experienced_anesthesiologist\",\n",
    "    \"highly_experienced_resident\",\n",
    "    \"current_anesthesiologist_catheter_count\",\n",
    "    \"moderately_experienced_anesthesiologist\",\n",
    "    \"has_scoliosis\",\n",
    "    \"has_dorsalgia\",\n",
    "    \"has_back_problems\",\n",
    "    \"maternal_race\",\n",
    " #   \"prior_pain_scores\",\n",
    "    \"prior_pain_scores_max\",\n",
    "    \"composite_psychosocial_problems\",\n",
    "    \"any_public_insurance\",\n",
    "    \"maternal_language_english\",\n",
    "    \"marital_status_married_or_partner\",\n",
    "    \"country_of_origin_USA\",\n",
    "    \"employment_status_fulltime\",\n",
    "    \"epidural_needle_type\",\n",
    "    \"paresthesias_present\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "Nr0wa_Zq-RfA"
   },
   "outputs": [],
   "source": [
    "df = df[chosen_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIr75B_tGNEV"
   },
   "outputs": [],
   "source": [
    "# prompt: print all columns as a list and make it easy to read over multiple lines\n",
    "\n",
    "all_columns = df.columns.tolist()\n",
    "\n",
    "# Print the list of columns, formatted for readability\n",
    "print(\"Columns of the DataFrame:\")\n",
    "for i, col in enumerate(all_columns):\n",
    "    print(f\"{i+1}. {col} ||| {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download / Upload Minimal Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:\\\\Users\\\\dfber\\\\Desktop\\\\minimal_merlin_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAy0JHRJuZfl"
   },
   "source": [
    "# Describe Dataframe\n",
    "\n",
    "There are 158364 total rows, of which 22218 have NaN true_procedure_type.\n",
    "\n",
    "Every row receives a value for all Boolean variables: thus if no value is present, they become False. Furthermore, NaN procedures become False is_neuraxial_catheter and failed_catheter.\n",
    "\n",
    "is_neuraxial_catheter includes epidurals + CSEs + intrathecals\n",
    "\n",
    "failed_catheter is applied to BOTH neuraxial_catheters (which may be coded True or False for failure) and also to all procedures that are not neuraxial_catheters (will always be coded False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nVeS0kuud88"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0AVFFcc6AdO"
   },
   "outputs": [],
   "source": [
    "def describe_dataframe(df):\n",
    "    \"\"\"\n",
    "    For each column in df:\n",
    "      - If dtype is object or int64 or bool, list each unique value and its counts.\n",
    "      - If dtype is float64, display min, Q1, median, Q3, and max.\n",
    "      - Otherwise, handle accordingly (datetime, etc.).\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        print(f\"Column: {col}\")\n",
    "        print(f\"  Data Type: {col_type}\")\n",
    "\n",
    "        if col_type == 'object' or col_type == 'int64' or col_type == 'bool':\n",
    "            # Show unique values and their counts\n",
    "            value_counts = df[col].value_counts(dropna=False)\n",
    "            print(\"  Value counts:\")\n",
    "            for val, count in value_counts.items():\n",
    "                print(f\"    {val}: {count}\")\n",
    "\n",
    "        elif col_type == 'float64':\n",
    "            # Show min, Q1 (25%), median (50%), Q3 (75%), and max\n",
    "            desc = df[col].describe(percentiles=[0.25, 0.5, 0.75])\n",
    "            na_count = df[col].isna().sum()\n",
    "            print(\"  Summary stats:\")\n",
    "            print(f\"    NaN:    {na_count}\")\n",
    "            print(f\"    Min:    {desc['min']}\")\n",
    "            print(f\"    Q1:     {desc['25%']}\")\n",
    "            print(f\"    Median: {desc['50%']}\")\n",
    "            print(f\"    Q3:     {desc['75%']}\")\n",
    "            print(f\"    Max:    {desc['max']}\")\n",
    "\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            # Example handling for datetime columns\n",
    "            print(\"  (Datetime column – no numeric summary or value counts shown.)\")\n",
    "\n",
    "        else:\n",
    "            # Handle any other data types as needed\n",
    "            print(\"  (No specific handling implemented for this data type.)\")\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "describe_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "14EFH7YNAXU0"
   },
   "outputs": [],
   "source": [
    "def describe_as_tables(df):\n",
    "    # Separate columns by dtype\n",
    "    categorical_cols = []\n",
    "    numeric_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' or df[col].dtype == 'int64' or df[col].dtype == 'bool':\n",
    "            categorical_cols.append(col)\n",
    "        elif df[col].dtype == 'float64':\n",
    "            numeric_cols.append(col)\n",
    "        else:\n",
    "            # skip or handle datetime, etc. if desired\n",
    "            pass\n",
    "\n",
    "    # --- Build table for categorical variables ---\n",
    "    cat_data = {}\n",
    "    for col in categorical_cols:\n",
    "        # Get value counts (including NaN as a separate category)\n",
    "        vc = df[col].value_counts(dropna=False)\n",
    "        # Convert value counts to a dict, or a formatted string\n",
    "        vc_str = \", \".join(f\"{val}: {count}\" for val, count in vc.items())\n",
    "        cat_data[col] = {\n",
    "            'value_counts': vc_str\n",
    "        }\n",
    "    cat_df = pd.DataFrame(cat_data).T  # Transpose so rows = columns, col = 'value_counts'\n",
    "\n",
    "    # --- Build table for numeric variables ---\n",
    "    num_data = {}\n",
    "    for col in numeric_cols:\n",
    "        desc = df[col].describe(percentiles=[0.25, 0.5, 0.75])\n",
    "        na_count = df[col].isna().sum()\n",
    "        num_data[col] = {\n",
    "            'count': desc['count'],\n",
    "            'count_nan': na_count,\n",
    "            'min': desc['min'],\n",
    "            'Q1': desc['25%'],\n",
    "            'median': desc['50%'],\n",
    "            'Q3': desc['75%'],\n",
    "            'max': desc['max']\n",
    "        }\n",
    "    num_df = pd.DataFrame(num_data).T  # Transpose so rows = columns\n",
    "\n",
    "    return cat_df, num_df\n",
    "\n",
    "cat_table, num_table = describe_as_tables(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAML_9nKGOVg"
   },
   "outputs": [],
   "source": [
    "cat_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TszpTBFVF2vb"
   },
   "outputs": [],
   "source": [
    "num_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KslZS4yFDiRp"
   },
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "FI5AVmce5NA9"
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only neuraxial catheter (ie, epidural + CSE + intrathecal) or epidural-only catheter procedures\n",
    "neuraxial_catheter_df = df[df['is_neuraxial_catheter'] == 1]\n",
    "epidural_df = df[(df['true_procedure_type'] == 'epidural')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1kTsSHsKme0"
   },
   "source": [
    "## Procedure Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhYO66Sye3Xq"
   },
   "outputs": [],
   "source": [
    "# prompt: make a histogram of procedure note types using different colors\n",
    "\n",
    "# Assuming 'procedure_type' column exists in your DataFrame 'df'\n",
    "procedure_type_counts = df['true_procedure_type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(procedure_type_counts.index, procedure_type_counts.values, color=['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'orange'])\n",
    "plt.xlabel('Procedure Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Procedure Note Types')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCQc6lyDpt9l"
   },
   "outputs": [],
   "source": [
    "# Histogram of successes/failures\n",
    "\n",
    "# Group by procedure type and whether it has subsequent anesthesia\n",
    "procedure_counts = pd.crosstab(neuraxial_catheter_df['true_procedure_type'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Sort the bars in descending order based on the total count of each procedure type\n",
    "procedure_counts = procedure_counts.sort_values(by=False, ascending=False)\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = procedure_counts.plot(kind='bar', stacked=True, figsize=(6\n",
    ", 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "  width = p.get_width()\n",
    "  height = p.get_height()\n",
    "  x, y = p.get_xy()\n",
    "  ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Procedure Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Successful/Failed')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2E0hm6ir1lr"
   },
   "outputs": [],
   "source": [
    "# Display the table with the same information\n",
    "print(\"Table of Neuraxial Catheter Procedures by Success/Failure:\")\n",
    "print(procedure_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "av35D_tCIiPT"
   },
   "source": [
    "## Anesthesiologist Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAD6DnIJ59Oh"
   },
   "outputs": [],
   "source": [
    "# prompt: Create a similar histogram for failure rate vs highly experienced anesthesiologist\n",
    "\n",
    "# Group by 'highly_experienced_anesthesiologist' and 'failed_catheter'\n",
    "experience_failure_counts = pd.crosstab(neuraxial_catheter_df['highly_experienced_anesthesiologist'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = experience_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Anesthesiologist Experience')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Anesthesiologist Experience')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0,1,2], labels=['No Anesthesiologist','Not Highly Experienced', 'Highly Experienced'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Anesthesiologist Experience:\")\n",
    "experience_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tgzfy3U20JFu"
   },
   "outputs": [],
   "source": [
    "# prompt: create a similar histogram for failure rate vs moderately experienced anesthesiologist\n",
    "\n",
    "# Group by 'moderately_experienced_anesthesiologist' and 'failed_catheter'\n",
    "experience_failure_counts = pd.crosstab(neuraxial_catheter_df['moderately_experienced_anesthesiologist'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = experience_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Anesthesiologist Experience')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Moderately Experienced Anesthesiologist')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0,1,2], labels=['No Anesthesiologist','Not Moderately Experienced', 'Moderately Experienced'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Moderately Experienced Anesthesiologist:\")\n",
    "experience_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5XJUmZmiZ0Q"
   },
   "outputs": [],
   "source": [
    "# prompt: Create a similar histogram for failure rate vs highly experienced resident\n",
    "\n",
    "# Group by 'highly_experienced_resident' and 'failed_catheter'\n",
    "experience_failure_counts = pd.crosstab(neuraxial_catheter_df['highly_experienced_resident'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = experience_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Resident Experience')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Resident Experience')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0,1,2], labels=['No Resident','Not Highly Experienced', 'Highly Experienced'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Resident Experience:\")\n",
    "experience_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxS3hVAPjPmO"
   },
   "outputs": [],
   "source": [
    "# prompt: Create a similar histogram but look at all combinations of resident and anesthesiologist experience. Make the x-axis labels vertical.\n",
    "\n",
    "# Group by 'highly_experienced_anesthesiologist', 'highly_experienced_resident', and 'failed_catheter'\n",
    "experience_failure_counts = pd.crosstab([neuraxial_catheter_df['highly_experienced_anesthesiologist'], neuraxial_catheter_df['highly_experienced_resident']], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = experience_failure_counts.plot(kind='bar', stacked=True, figsize=(8, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Anesthesiologist and Resident Experience')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Anesthesiologist and Resident Experience')\n",
    "\n",
    "\n",
    "# Customize x-axis labels\n",
    "import itertools\n",
    "anesth_levels = [\"Anes=None\", \"Anes=Not Exp\", \"Anes=Exp\"]\n",
    "resident_levels = [\"Res=None\", \"Res=Not Exp\", \"Res=Exp\"]\n",
    "labels = list(itertools.product(anesth_levels, resident_levels))\n",
    "plt.xticks(rotation=90, ha='center', ticks=range(len(labels)), labels=labels)\n",
    "\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Anesthesiologist and Resident Experience:\")\n",
    "experience_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwKq70Ue2leN"
   },
   "outputs": [],
   "source": [
    "# prompt: crosstab resident experience by BMI and make violin plots\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
    "# and it contains columns 'bmi_end_pregnancy_2044' and 'resident_experience' (or a similar column)\n",
    "\n",
    "# Create the cross-tabulation\n",
    "crosstab_data = pd.crosstab(neuraxial_catheter_df['bmi_end_pregnancy_2044'], neuraxial_catheter_df['highly_experienced_resident'])\n",
    "\n",
    "# Display the cross-tabulation\n",
    "print(\"Crosstab of Resident Experience by BMI:\")\n",
    "print(crosstab_data)\n",
    "\n",
    "# Create violin plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='highly_experienced_resident', y='bmi_end_pregnancy_2044', data=df)\n",
    "plt.xlabel('Resident Experience')  # Customize the x-axis label\n",
    "plt.ylabel('BMI') # Customize the y-axis label\n",
    "plt.title('Violin Plot of BMI by Resident Experience')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MayiICLInFU"
   },
   "source": [
    "## Delivery Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAq0KgpgOOK9"
   },
   "outputs": [],
   "source": [
    "# prompt: create a similar histogram of delivery_site_2188 using crosstab\n",
    "\n",
    "# Create a crosstab for 'delivery_site_2188' and visualize it as a histogram\n",
    "delivery_site_counts = pd.crosstab(neuraxial_catheter_df['delivery_site_2188'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Sort the bars in descending order based on the total count of each delivery site\n",
    "delivery_site_counts = delivery_site_counts.sort_values(by=False, ascending=False)\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = delivery_site_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Delivery Site')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Delivery Site by Success/Failure')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Delivery Site by Success/Failure:\")\n",
    "delivery_site_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVaN_FfqIpBD"
   },
   "source": [
    "## DPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeDO9JblHPDi"
   },
   "outputs": [],
   "source": [
    "# prompt: # prompt: create a pie chart of the fraction of DPE in epidural_df\n",
    "\n",
    "# Count DPE values, treating NaN and '' as \"no\"\n",
    "dpe_counts = epidural_df['dpe'].value_counts()\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(dpe_counts, labels=dpe_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Fraction of DPE in Epidural Procedures')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "tXDQLTGCQ6Vu"
   },
   "outputs": [],
   "source": [
    "# prompt: reproduce the above histogram using crosstab on delivery_site_2188 and dpe\n",
    "\n",
    "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
    "\n",
    "# Create a crosstab for 'delivery_site_2188' and 'dpe' and visualize it as a histogram\n",
    "delivery_site_dpe_counts = pd.crosstab(epidural_df['delivery_site_2188'], epidural_df['dpe'])\n",
    "\n",
    "# Sort the bars in descending order based on the total count of each delivery site\n",
    "delivery_site_dpe_counts = delivery_site_dpe_counts.sort_values(by=True, ascending=False) # Sort by 'no'\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = delivery_site_dpe_counts.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Delivery Site')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Delivery Site by DPE')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['DPE: no', 'DPE: yes']) # Update legend labels\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Delivery Site by DPE:\")\n",
    "delivery_site_dpe_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "etnS4LFswP2W"
   },
   "outputs": [],
   "source": [
    "# Histogram of successes/failures by DPE status\n",
    "\n",
    "# Group by procedure type and whether it has subsequent anesthesia\n",
    "dpe_crosstab = pd.crosstab(epidural_df['dpe'], epidural_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = dpe_crosstab.plot(kind='bar', stacked=True, figsize=(6\n",
    ", 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "  width = p.get_width()\n",
    "  height = p.get_height()\n",
    "  x, y = p.get_xy()\n",
    "  ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('DPE Status')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Successful/Failed')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "E2YE9-N_Rc8Y"
   },
   "outputs": [],
   "source": [
    "# prompt: do a crosstab histogram of failure versus delivery_site_2188 and dpe\n",
    "\n",
    "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
    "\n",
    "# Create a crosstab for 'delivery_site_2188', 'dpe', and 'failed_catheter'\n",
    "crosstab_df = pd.crosstab([df['delivery_site_2188'], df['dpe']], df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = crosstab_df.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Annotate the bars with percentages\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "\n",
    "plt.xlabel('Delivery Site and DPE')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Crosstab Histogram: Failure vs. Delivery Site and DPE')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the crosstab table\n",
    "print(\"Crosstab Table:\")\n",
    "crosstab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1KjAXKyIvSe"
   },
   "source": [
    "## Scoliosis and back problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "pTpcI3_i6OTi"
   },
   "outputs": [],
   "source": [
    "# prompt: create a histogram of the crosstab of has_scoliosis vs failure_rate\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame (as defined in the provided code)\n",
    "\n",
    "# Group by 'has_scoliosis' and 'failed_catheter'\n",
    "scoliosis_failure_counts = pd.crosstab(neuraxial_catheter_df['has_scoliosis'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = scoliosis_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Has Scoliosis')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Scoliosis')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0, 1], labels=['No Scoliosis', 'Scoliosis'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Scoliosis:\")\n",
    "scoliosis_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "yt-YMDQJ6ez6"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same but for has_back_problems\n",
    "\n",
    "# Group by 'has_back_problems' and 'failed_catheter'\n",
    "back_problems_failure_counts = pd.crosstab(neuraxial_catheter_df['has_back_problems'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = back_problems_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Has Back Problems')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Back Problems')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0, 1], labels=['No Back Problems', 'Back Problems'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Back Problems:\")\n",
    "back_problems_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lWungLk36zfB"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same but for has_dorsalgia\n",
    "\n",
    "# Group by 'has_dorsalgia' and 'failed_catheter'\n",
    "back_pain_failure_counts = pd.crosstab(neuraxial_catheter_df['has_dorsalgia'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = back_pain_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Has Back Pain')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Back Pain')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0, 1], labels=['No Back Pain', 'Back Pain'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Back Pain:\")\n",
    "back_pain_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gv3ifVAI1Vz"
   },
   "source": [
    "## Fetal Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hHJ5Dj_Y_Hez"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same histogram, but for fetal_presentation_category vs failure\n",
    "\n",
    "# Group by 'fetal_presentation_category_2243' and 'failed_catheter'\n",
    "fetal_presentation_failure_counts = pd.crosstab(neuraxial_catheter_df['fetal_presentation_category_2243'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = fetal_presentation_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Fetal Presentation Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Fetal Presentation Category')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Fetal Presentation Category:\")\n",
    "fetal_presentation_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "MlDCkD5L-k7b"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same histogram, but for fetal_presentation_position vs failure\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame (as defined in the provided code)\n",
    "\n",
    "# Group by 'fetal_presentation_position_2247' and 'failed_catheter'\n",
    "fetal_position_failure_counts = pd.crosstab(neuraxial_catheter_df['fetal_presentation_position_2247'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = fetal_position_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Fetal Presentation Position')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Fetal Presentation Position')\n",
    "plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Fetal Presentation Position:\")\n",
    "fetal_position_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nh0U-I5JELL"
   },
   "source": [
    "## Race and SES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5rLASpgnEbbd"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same histogram, but for maternal_race vs failure\n",
    "\n",
    "# Group by 'maternal_race' and 'failed_catheter'\n",
    "race_failure_counts = pd.crosstab(neuraxial_catheter_df['maternal_race'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = race_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Maternal Race')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Maternal Race')\n",
    "plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Maternal Race:\")\n",
    "race_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tREZEFcyJHYc"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same histogram, but for each of these: 32. composite_psychosocial_problems ||| int64\n",
    "# 33. any_public_insurance ||| int64\n",
    "# 34. maternal_language_english ||| int64\n",
    "# 35. marital_status_married_or_partner ||| int64\n",
    "# 36. country_of_origin_USA ||| int64\n",
    "# 37. employment_status_fulltime ||| int64\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "columns_to_analyze = [\n",
    "    'composite_psychosocial_problems',\n",
    "    'any_public_insurance',\n",
    "    'maternal_language_english',\n",
    "    'marital_status_married_or_partner',\n",
    "    'country_of_origin_USA',\n",
    "    'employment_status_fulltime'\n",
    "]\n",
    "\n",
    "for column in columns_to_analyze:\n",
    "  # Group by the current column and 'failed_catheter'\n",
    "  failure_counts = pd.crosstab(neuraxial_catheter_df[column], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "  # Create a stacked bar chart\n",
    "  ax = failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "  # Add percentages within each bar\n",
    "  for p in ax.patches:\n",
    "      width = p.get_width()\n",
    "      height = p.get_height()\n",
    "      x, y = p.get_xy()\n",
    "      ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "  plt.xlabel(column)\n",
    "  plt.ylabel('Count')\n",
    "  plt.title(f'Histogram of Failure Rate vs. {column}')\n",
    "\n",
    "  # Customize x-axis ticks and labels (adjust as needed for each column)\n",
    "  plt.xticks(rotation=0, ha='center')\n",
    "\n",
    "  plt.legend(['Successful', 'Failed'])\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "  # Display the table with the same information\n",
    "  print(f\"Table of Failure Rate vs. {column}:\")\n",
    "failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3GOeiuRKMBs"
   },
   "source": [
    "## Pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQPN3DmxJg18"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same histogram but for prior_pain_scores_max\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "# Group by 'prior_pain_scores_max' and 'failed_catheter'\n",
    "prior_pain_failure_counts = pd.crosstab(neuraxial_catheter_df['prior_pain_scores_max'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = prior_pain_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Prior Pain Scores Max')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Prior Pain Scores Max')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels if needed\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Prior Pain Scores Max:\")\n",
    "prior_pain_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Tzqh_csSOjn"
   },
   "source": [
    "## Gravidity and Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljlBjLAuR7po"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same histogram but for gravidity_2047 and parity_2048\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "# Group by 'gravidity_2047' and 'failed_catheter'\n",
    "gravidity_failure_counts = pd.crosstab(neuraxial_catheter_df['gravidity_2047'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = gravidity_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Gravidity')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Gravidity')\n",
    "plt.xticks(rotation=0)  # Adjust rotation if needed\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table\n",
    "print(\"Table of Failure Rate vs. Gravidity:\")\n",
    "print(gravidity_failure_counts)\n",
    "\n",
    "\n",
    "# Group by 'parity_2048' and 'failed_catheter'\n",
    "parity_failure_counts = pd.crosstab(neuraxial_catheter_df['parity_2048'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = parity_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Parity')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Parity')\n",
    "plt.xticks(rotation=0)  # Adjust rotation if needed\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table\n",
    "print(\"Table of Failure Rate vs. Parity:\")\n",
    "parity_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjCeDTpmS9Do"
   },
   "source": [
    "## Needle Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mHwj9OASn0o"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same histogram but for epidural_needle_type\n",
    "\n",
    "# Assuming 'epidural_df' is your DataFrame (as defined in the provided code)\n",
    "\n",
    "# Group by 'epidural_needle_type' and 'failed_catheter'\n",
    "needle_type_failure_counts = pd.crosstab(epidural_df['epidural_needle_type'], epidural_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = needle_type_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Epidural Needle Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Epidural Needle Type')\n",
    "plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Epidural Needle Type:\")\n",
    "needle_type_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnO_r6MJS-og"
   },
   "source": [
    "## Paresthesias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQZSLz7uSttY"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same histogram but for paresthesias_present\n",
    "\n",
    "# Group by 'paresthesias_present' and 'failed_catheter'\n",
    "paresthesias_failure_counts = pd.crosstab(neuraxial_catheter_df['paresthesias_present'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = paresthesias_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Paresthesias Present')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Paresthesias Present')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0, 1], labels=['No Paresthesias', 'Paresthesias'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Paresthesias Present:\")\n",
    "paresthesias_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxP_JY6rKOgd"
   },
   "source": [
    "## Number of Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mWVejseC0vVV"
   },
   "outputs": [],
   "source": [
    "# prompt: create a histogram of the number of attempts. Only show integers on the x-axis\n",
    "\n",
    "# Assuming 'number_of_neuraxial_attempts' is a column in your DataFrame 'df'\n",
    "attempts_counts = df['number_of_neuraxial_attempts'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(attempts_counts.index, attempts_counts.values)\n",
    "plt.xlabel('Number of Attempts')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Number of Neuraxial Attempts')\n",
    "plt.xticks(range(int(attempts_counts.index.min()), int(attempts_counts.index.max()) + 1))  # Show only integer ticks on x-axis\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOVju1ofKScs"
   },
   "source": [
    "## Loss of Resistance Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "W6V9pTQo8LIz"
   },
   "outputs": [],
   "source": [
    "# prompt: create a histogram of loss of resistance depth. Center the bars over the tick marks and make space between the bars. Bins should be every 0.5\n",
    "\n",
    "# Assuming 'LOR_depth' is a column in your DataFrame 'df'\n",
    "lor_depths = neuraxial_catheter_df['lor_depth'].dropna()  # Remove NaN values\n",
    "\n",
    "# Create the histogram with centered bars and spacing\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(lor_depths, bins=np.arange(lor_depths.min(), lor_depths.max() + 0.5, 0.5), rwidth=0.8, align='left')\n",
    "plt.xlabel('Loss of Resistance Depth')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Loss of Resistance Depth')\n",
    "plt.xticks(np.arange(0, lor_depths.max() + 0.5, 1))  # Set x-axis ticks to be at every 1\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vw06uLwvCLt8"
   },
   "outputs": [],
   "source": [
    "# prompt: Plot number of neuraxial attempts vs LOR depth on the x-axis. Add jiggle to both x and y axes\n",
    "\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['number_of_neuraxial_attempts', 'lor_depth'])\n",
    "\n",
    "# Add random jiggle to both x and y axes\n",
    "jiggle_x = np.random.normal(scale = 0.1, size=len(df_plot))\n",
    "jiggle_y = np.random.normal(scale = 0.1, size=len(df_plot))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_plot['LOR_depth'] + jiggle_x, df_plot['number_of_neuraxial_attempts'] + jiggle_y, alpha=0.5)\n",
    "plt.xlabel('LOR Depth')\n",
    "plt.ylabel('Number of Neuraxial Attempts')\n",
    "plt.title('Number of Neuraxial Attempts vs. LOR Depth with Jiggle')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lH5MiqatZjRY"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same but add shaded error bars for +/- standard error of the mean\n",
    "\n",
    "# Assuming 'number_of_neuraxial_attempts' and 'failed_catheter' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['number_of_neuraxial_attempts'])\n",
    "\n",
    "# Group by number of attempts and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_attempts = df_plot.groupby('number_of_neuraxial_attempts')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot with error bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_attempts.index, failure_by_attempts['mean'], marker='o')\n",
    "plt.fill_between(failure_by_attempts.index,\n",
    "                 failure_by_attempts['mean'] - failure_by_attempts['sem'],\n",
    "                 failure_by_attempts['mean'] + failure_by_attempts['sem'],\n",
    "                 alpha=0.2) # Add shaded error bars\n",
    "plt.errorbar(failure_by_attempts.index, failure_by_attempts['mean'], yerr=failure_by_attempts['sem'], fmt='o-', capsize=5, elinewidth=1)  # Added error bars\n",
    "plt.xlabel('Number of Neuraxial Attempts')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Number of Neuraxial Attempts with Error Bars')\n",
    "plt.xticks(np.arange(0, failure_by_attempts['number_of_neuraxial_attempts'].max() + 0.5, 1))  # Set x-axis ticks to be at every 0.5\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "FP1Fos7aCUBH"
   },
   "outputs": [],
   "source": [
    "# prompt: Plot lor-depth against bmi\n",
    "\n",
    "# Assuming 'lor_depth' and 'bmi_end_pregnancy_2044' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['lor_depth', 'bmi_end_pregnancy_2044'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_plot['bmi_end_pregnancy_2044'], df_plot['lor_depth'])\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('LOR Depth')\n",
    "plt.title('LOR Depth vs. BMI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ac3cjN1dCn5p"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Extract the data, dropping NaNs\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['lor_depth', 'bmi_end_pregnancy_2044'])\n",
    "x = df_plot['bmi_end_pregnancy_2044'].values\n",
    "y = df_plot['lor_depth'].values\n",
    "\n",
    "# Perform kernel density estimation\n",
    "xy = np.vstack([x, y])\n",
    "kde = gaussian_kde(xy)\n",
    "\n",
    "# Define grid over data range\n",
    "xmin, xmax = x.min() - 1, x.max() + 1\n",
    "ymin, ymax = y.min() - 1, y.max() + 1\n",
    "X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "Z = np.reshape(kde(positions).T, X.shape)\n",
    "\n",
    "# Create the contour plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.contourf(X, Y, Z, levels=15, cmap='viridis')\n",
    "plt.colorbar(label='Density')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('LOR Depth')\n",
    "plt.title('Contour Plot of LOR Depth vs. BMI (KDE)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mEqCtyPnK8pf"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same but for failure vs loss of resistance depth. Bin the depth by units of 1\n",
    "\n",
    "# Assuming 'LOR_depth' and 'failed_catheter' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['lor_depth', 'failed_catheter'])\n",
    "\n",
    "# Bin the LOR depth\n",
    "df_plot['LOR_depth_bin'] = (df_plot['lor_depth'] // 1).astype(int)\n",
    "\n",
    "# Group by the binned LOR depth and calculate the mean of failed_catheter\n",
    "failure_by_lor_depth = df_plot.groupby('LOR_depth_bin')['failed_catheter'].mean()\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_lor_depth.index, failure_by_lor_depth.values, marker='o')\n",
    "plt.xlabel('Loss of Resistance Depth (binned)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Loss of Resistance Depth (binned by 1)')\n",
    "plt.xticks(np.arange(0, df_plot['lor_depth'].max() + 0.5, 1))  # Set x-axis ticks to be at every 1\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4ZsvxhSYVntZ"
   },
   "outputs": [],
   "source": [
    "# prompt: Reproduce the same plot, but add shaded error bars for +/- standard error of the mean\n",
    "\n",
    "# Assuming 'LOR_depth' and 'failed_catheter' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['lor_depth', 'failed_catheter'])\n",
    "\n",
    "# Bin the LOR depth\n",
    "df_plot['LOR_depth_bin'] = (df_plot['lor_depth'] // 1).astype(int)\n",
    "\n",
    "# Group by the binned LOR depth and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_lor_depth = df_plot.groupby('LOR_depth_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_lor_depth.index, failure_by_lor_depth['mean'], marker='o')\n",
    "plt.fill_between(failure_by_lor_depth.index,\n",
    "                 failure_by_lor_depth['mean'] - failure_by_lor_depth['sem'],\n",
    "                 failure_by_lor_depth['mean'] + failure_by_lor_depth['sem'],\n",
    "                 alpha=0.5) # Add shaded error bars\n",
    "\n",
    "plt.xlabel('Loss of Resistance Depth (binned)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Loss of Resistance Depth (binned by 1) with Error Bars')\n",
    "plt.xticks(np.arange(0, df_plot['lor_depth'].max() + 0.5, 1))  # Set x-axis ticks to be at every 1\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhwd5_TTAklq"
   },
   "source": [
    "## BMI / height / weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzaiAlE926QH"
   },
   "outputs": [],
   "source": [
    "# prompt: plot bmi end pregnancy against failure rate using binning as above.\n",
    "\n",
    "# Assuming 'bmi_end_pregnancy' and 'failed_catheter' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['bmi_end_pregnancy_2044', 'failed_catheter'])\n",
    "\n",
    "# Bin the bmi_end_pregnancy\n",
    "df_plot['bmi_end_pregnancy_bin'] = (df_plot['bmi_end_pregnancy_2044'] // 1).astype(int)\n",
    "\n",
    "# Group by the binned bmi_end_pregnancy and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_bmi = df_plot.groupby('bmi_end_pregnancy_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_bmi.index, failure_by_bmi['mean'], marker='o')\n",
    "plt.fill_between(failure_by_bmi.index,\n",
    "                 failure_by_bmi['mean'] - failure_by_bmi['sem'],\n",
    "                 failure_by_bmi['mean'] + failure_by_bmi['sem'],\n",
    "                 alpha=0.5) # Add shaded error bars\n",
    "\n",
    "plt.xlabel('BMI (kg/m^2) at End of Pregnancy (binned by 1)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. BMI at End of Pregnancy (binned by 1) with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1zcraGpDz5A"
   },
   "outputs": [],
   "source": [
    "# prompt: # prompt: plot weight end pregnancy against failure rate using binning as above.\n",
    "\n",
    "# Assuming 'maternal_weight_end_pregnancy_2045' and 'failed_catheter' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['maternal_weight_end_pregnancy_2045', 'failed_catheter'])\n",
    "\n",
    "# Bin the maternal weight at the end of pregnancy\n",
    "df_plot['weight_end_pregnancy_bin'] = (df_plot['maternal_weight_end_pregnancy_2045'] // 10).astype(int) * 10\n",
    "\n",
    "# Group by the binned weight and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_weight = df_plot.groupby('weight_end_pregnancy_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_weight.index, failure_by_weight['mean'], marker='o')\n",
    "plt.fill_between(failure_by_weight.index,\n",
    "                 failure_by_weight['mean'] - failure_by_weight['sem'],\n",
    "                 failure_by_weight['mean'] + failure_by_weight['sem'],\n",
    "                 alpha=0.5)  # Add shaded error bars\n",
    "\n",
    "plt.xlabel('Maternal Weight (kg) at End of Pregnancy (binned by 10)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Maternal Weight at End of Pregnancy (binned by 10) with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LflbXJmL8aw5"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same but for height\n",
    "\n",
    "# Assuming 'height' is a column in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['maternal_height_2046', 'failed_catheter'])\n",
    "\n",
    "# Drop heights greater than 250\n",
    "df_plot = df_plot[df_plot['maternal_height_2046'] <= 250]\n",
    "\n",
    "# Bin the height\n",
    "df_plot['height_bin'] = (df_plot['maternal_height_2046'] // 1).astype(int)\n",
    "\n",
    "# Group by the binned height and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_height = df_plot.groupby('height_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_height.index, failure_by_height['mean'], marker='o')\n",
    "plt.fill_between(failure_by_height.index,\n",
    "                 failure_by_height['mean'] - failure_by_height['sem'],\n",
    "                 failure_by_height['mean'] + failure_by_height['sem'],\n",
    "                 alpha=0.5) # Add shaded error bars\n",
    "\n",
    "plt.xlabel('Height (binned by 1)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Height (binned by 1) with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Nq1ZO64Kh5U"
   },
   "source": [
    "## Gestational Age and Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LLxJhJ3VEWWG"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same but for gestational age\n",
    "\n",
    "# Histogram of gestational age\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['gestational_age_2052'].dropna(), bins=20) # Adjust bins as needed\n",
    "plt.xlabel('Gestational Age (days)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Gestational Age')\n",
    "plt.show()\n",
    "\n",
    "# Analyze gestational age in relation to failed catheter\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['gestational_age_2052', 'failed_catheter'])\n",
    "df_plot['gestational_age_bin'] = (df_plot['gestational_age_2052'] // 7).astype(int) * 7\n",
    "failure_by_gestational_age = df_plot.groupby('gestational_age_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_gestational_age.index, failure_by_gestational_age['mean'], marker='o')\n",
    "plt.fill_between(failure_by_gestational_age.index,\n",
    "                failure_by_gestational_age['mean'] - failure_by_gestational_age['sem'],\n",
    "                failure_by_gestational_age['mean'] + failure_by_gestational_age['sem'],\n",
    "                alpha=0.5)\n",
    "plt.xlabel('Gestational Age (days) (binned by 7)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Gestational Age (binned by 7) with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sh5mnKdxMx1u"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same histogram and binned failure rate but for baby_weight_2196\n",
    "\n",
    "# Assuming 'baby_weight_2196' is a column in your DataFrame 'df' or 'neuraxial_catheter_df'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(neuraxial_catheter_df['baby_weight_2196'].dropna(), bins=20)  # Adjust bins as needed\n",
    "plt.xlabel('Baby Weight (kg)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Baby Weight')\n",
    "plt.show()\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['baby_weight_2196', 'failed_catheter'])\n",
    "\n",
    "# Bin the baby weight\n",
    "df_plot['baby_weight_bin'] = (df_plot['baby_weight_2196'] // 0.5) * 0.5\n",
    "\n",
    "# Group by the binned baby weight and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_baby_weight = df_plot.groupby('baby_weight_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_baby_weight.index, failure_by_baby_weight['mean'], marker='o')\n",
    "plt.fill_between(failure_by_baby_weight.index,\n",
    "                 failure_by_baby_weight['mean'] - failure_by_baby_weight['sem'],\n",
    "                 failure_by_baby_weight['mean'] + failure_by_baby_weight['sem'],\n",
    "                 alpha=0.5)  # Add shaded error bars\n",
    "\n",
    "plt.xlabel('Baby Weight (kg) (binned by 0.5)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Baby Weight with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BIbUrpyOLfe"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same count histogram but for secs_rom_thru_delivery_2197\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "# Drop NaN values in 'secs_rom_thru_delivery_2197'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['rom_thru_delivery_hours'])\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_plot['rom_thru_delivery_hours'], bins=200)  # Adjust bins as needed\n",
    "plt.xlabel('Hours from ROM to Delivery')\n",
    "plt.xlim(0,100)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Hours from ROM to Delivery')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SInJjFCNxW2"
   },
   "outputs": [],
   "source": [
    "# prompt: do the same binned plot for rom_thru_delivery_hours\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['rom_thru_delivery_hours', 'failed_catheter'])\n",
    "\n",
    "# Bin the rom_thru_delivery_hours\n",
    "df_plot['rom_thru_delivery_hours_bin'] = (df_plot['rom_thru_delivery_hours'] // 1).astype(int)\n",
    "\n",
    "# Group by the binned rom_thru_delivery_hours and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_rom_delivery = df_plot.groupby('rom_thru_delivery_hours_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_rom_delivery.index, failure_by_rom_delivery['mean'], marker='o')\n",
    "plt.fill_between(failure_by_rom_delivery.index,\n",
    "                 failure_by_rom_delivery['mean'] - failure_by_rom_delivery['sem'],\n",
    "                 failure_by_rom_delivery['mean'] + failure_by_rom_delivery['sem'],\n",
    "                 alpha=0.5)  # Add shaded error bars\n",
    "plt.xlim(0,100)\n",
    "plt.xlabel('Hours from ROM to Delivery (binned)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Hours from ROM to Delivery (binned by 1) with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECN0irIBKt7g"
   },
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Je-DyX8WXqoq"
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df_corr = neuraxial_catheter_df.dropna(subset=['LOR_depth', 'number_of_neuraxial_attempts'])\n",
    "\n",
    "# Fit the model using the formula\n",
    "model = smf.ols('number_of_neuraxial_attempts ~ LOR_depth', data=df_corr).fit()\n",
    "\n",
    "# Print the summary of the regression results\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0BQ8K2IaLJBu"
   },
   "outputs": [],
   "source": [
    "# For categorical variables like DPE and failed_catheter\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "dpe_crosstab = pd.crosstab(epidural_df['DPE'], epidural_df['failed_catheter'])\n",
    "chi2, p, _, _ = chi2_contingency(dpe_crosstab)\n",
    "\n",
    "print(dpe_crosstab.div(dpe_crosstab.sum(axis=1), axis=0) * 100)\n",
    "print(\"Chi-squared statistic:\", chi2)\n",
    "print(\"P-value:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ubX3mPToFLSk"
   },
   "outputs": [],
   "source": [
    "# prompt: Do univariate logistic regression separately using number of attempts and loss of resistance depth to predict failure\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Prepare the data for logistic regression with number of attempts as the predictor\n",
    "df_logreg_attempts = neuraxial_catheter_df.dropna(subset=['number_of_neuraxial_attempts', 'failed_catheter'])\n",
    "# Fit the logistic regression model\n",
    "model_attempts = smf.logit('failed_catheter ~ number_of_neuraxial_attempts', data=df_logreg_attempts).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model_attempts.summary())\n",
    "\n",
    "\n",
    "# Prepare the data for logistic regression with loss of resistance depth as the predictor\n",
    "df_logreg_lor = neuraxial_catheter_df.dropna(subset=['LOR_depth', 'failed_catheter'])\n",
    "# Fit the logistic regression model\n",
    "model_lor = smf.logit('failed_catheter ~ LOR_depth', data=df_logreg_lor).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model_lor.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xfS9A4f1H2ji"
   },
   "outputs": [],
   "source": [
    "# prompt: Now do multivariate analysis using the same two predictors\n",
    "\n",
    "# Prepare the data for logistic regression with both predictors\n",
    "df_logreg_multi = neuraxial_catheter_df.dropna(subset=['number_of_neuraxial_attempts', 'LOR_depth', 'failed_catheter'])\n",
    "\n",
    "# Fit the logistic regression model with both predictors\n",
    "model_multi = smf.logit('failed_catheter ~ number_of_neuraxial_attempts + LOR_depth', data=df_logreg_multi).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model_multi.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only neuraxial catheter (ie, epidural + CSE + intrathecal) or epidural-only catheter procedures\n",
    "neuraxial_catheter_df = df[df['is_neuraxial_catheter'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = neuraxial_catheter_df\n",
    "\n",
    "# Drop columns with more than 80% missing values\n",
    "threshold = len(data) * 0.5\n",
    "data_cleaned = data.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Drop rows where target variable is missing\n",
    "data_cleaned = data_cleaned.dropna(subset=[\"failed_catheter\"])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data_cleaned.drop(columns=[\"failed_catheter\", \"best_timestamp\"], errors='ignore')\n",
    "y = data_cleaned[\"failed_catheter\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                           ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing into a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Train logistic regression with class weights\n",
    "logistic_model = LogisticRegression(max_iter=1000, solver='liblinear', class_weight='balanced', n_jobs=1)\n",
    "logistic_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logistic_model.predict(X_test_preprocessed)\n",
    "y_pred_prob = logistic_model.predict_proba(X_test_preprocessed)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_pred_prob),\n",
    "    \"classification_report\": classification_report(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Model Evaluation:\")\n",
    "for metric, value in evaluation_metrics.items():\n",
    "    if metric == \"classification_report\":\n",
    "        print(\"\\nClassification Report:\\n\", value)\n",
    "    else:\n",
    "        print(f\"{metric.capitalize()}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKPV6NaW7+ZRxbDtLw/frD",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
