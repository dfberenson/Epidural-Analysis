{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19472\\3751139265.py:1: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('minimal_merlin_data.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('minimal_merlin_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19472\\3074727906.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.replace({True: 1, False: 0})\n"
     ]
    }
   ],
   "source": [
    "df = df.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only neuraxial catheter (ie, epidural + CSE + intrathecal) or epidural-only catheter procedures\n",
    "neuraxial_catheter_df = df[df['is_neuraxial_catheter'] == 1]\n",
    "epidural_df = df[(df['true_procedure_type'] == 'epidural')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe Dataframe\n",
    "\n",
    "There are 158364 total rows, of which 22218 have NaN true_procedure_type.\n",
    "\n",
    "Every row receives a value for all Boolean variables: thus if no value is present, they become False. Furthermore, NaN procedures become False is_neuraxial_catheter and failed_catheter.\n",
    "\n",
    "is_neuraxial_catheter includes epidurals + CSEs + intrathecals\n",
    "\n",
    "failed_catheter is applied to BOTH neuraxial_catheters (which may be coded True or False for failure) and also to all procedures that are not neuraxial_catheters (will always be coded False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158364, 35)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: gestational_age_2052\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    2339\n",
      "    Min:    87.0\n",
      "    Q1:     267.0\n",
      "    Median: 275.0\n",
      "    Q3:     281.0\n",
      "    Max:    308.0\n",
      "--------------------------------------------------\n",
      "Column: delivery_site_2188\n",
      "  Data Type: object\n",
      "  Value counts:\n",
      "    bwh: 64334\n",
      "    mgh: 35716\n",
      "    nwh: 35053\n",
      "    slm: 9973\n",
      "    wdh: 7380\n",
      "    cdh: 3901\n",
      "    nch: 1002\n",
      "    mvh: 982\n",
      "    mgb: 14\n",
      "    nsc: 9\n",
      "--------------------------------------------------\n",
      "Column: baby_weight_2196\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    3251\n",
      "    Min:    0.0\n",
      "    Q1:     2.9766996\n",
      "    Median: 3.3299346192\n",
      "    Q3:     3.6551036136\n",
      "    Max:    7.1698771032\n",
      "--------------------------------------------------\n",
      "Column: rom_thru_delivery_hours\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    20054\n",
      "    Min:    0.0\n",
      "    Q1:     1.45\n",
      "    Median: 5.45\n",
      "    Q3:     12.066666666666666\n",
      "    Max:    711.8166666666667\n",
      "--------------------------------------------------\n",
      "Column: fetal_presentation_category_2243\n",
      "  Data Type: object\n",
      "  Value counts:\n",
      "    cephalic: 134205\n",
      "    nan: 12656\n",
      "    breech: 7827\n",
      "    compound: 2990\n",
      "    lie: 686\n",
      "--------------------------------------------------\n",
      "Column: fetal_presentation_subcategory_2244\n",
      "  Data Type: object\n",
      "  Value counts:\n",
      "    vertex: 134037\n",
      "    nan: 20328\n",
      "    compound: 2990\n",
      "    transverse: 686\n",
      "    face: 119\n",
      "    frank: 115\n",
      "    brow: 49\n",
      "    footling: 40\n",
      "--------------------------------------------------\n",
      "Column: fetal_presentation_position_2247\n",
      "  Data Type: object\n",
      "  Value counts:\n",
      "    nan: 80824\n",
      "    anterior: 67514\n",
      "    posterior: 7255\n",
      "    transverse: 2771\n",
      "--------------------------------------------------\n",
      "Column: bmi_end_pregnancy_2044\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    8230\n",
      "    Min:    5.8\n",
      "    Q1:     27.0\n",
      "    Median: 30.1\n",
      "    Q3:     34.2\n",
      "    Max:    69.9\n",
      "--------------------------------------------------\n",
      "Column: maternal_weight_end_pregnancy_2045\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    6325\n",
      "    Min:    0.0890175026125\n",
      "    Q1:     70.76040972\n",
      "    Median: 79.786897883\n",
      "    Q3:     91.126707133\n",
      "    Max:    218.997798178775\n",
      "--------------------------------------------------\n",
      "Column: bmi_before_pregnancy_2161\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    48776\n",
      "    Min:    6.66\n",
      "    Q1:     22.1\n",
      "    Median: 25.0\n",
      "    Q3:     29.3\n",
      "    Max:    67.7\n",
      "--------------------------------------------------\n",
      "Column: gravidity_2047\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    50652\n",
      "    Min:    0.0\n",
      "    Q1:     1.0\n",
      "    Median: 2.0\n",
      "    Q3:     3.0\n",
      "    Max:    18.0\n",
      "--------------------------------------------------\n",
      "Column: parity_2048\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    63700\n",
      "    Min:    0.0\n",
      "    Q1:     0.0\n",
      "    Median: 1.0\n",
      "    Q3:     1.0\n",
      "    Max:    12.0\n",
      "--------------------------------------------------\n",
      "Column: true_procedure_type\n",
      "  Data Type: object\n",
      "  Value counts:\n",
      "    epidural: 93221\n",
      "    spinal: 25186\n",
      "    nan: 22402\n",
      "    cse: 14169\n",
      "    airway: 3253\n",
      "    intrathecal: 133\n",
      "--------------------------------------------------\n",
      "Column: is_neuraxial_catheter\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    1: 107523\n",
      "    0: 50841\n",
      "--------------------------------------------------\n",
      "Column: failed_catheter\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    0: 152023\n",
      "    1: 6341\n",
      "--------------------------------------------------\n",
      "Column: dpe\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    0: 142193\n",
      "    1: 16171\n",
      "--------------------------------------------------\n",
      "Column: lor_depth\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    53087\n",
      "    Min:    0.0\n",
      "    Q1:     4.8\n",
      "    Median: 5.0\n",
      "    Q3:     6.0\n",
      "    Max:    18.0\n",
      "--------------------------------------------------\n",
      "Column: current_resident_catheter_count\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    81897\n",
      "    Min:    0.0\n",
      "    Q1:     15.0\n",
      "    Median: 36.0\n",
      "    Q3:     67.0\n",
      "    Max:    332.0\n",
      "--------------------------------------------------\n",
      "Column: highly_experienced_anesthesiologist\n",
      "  Data Type: object\n",
      "  Value counts:\n",
      "    no: 63149\n",
      "    yes: 47811\n",
      "    none: 47404\n",
      "--------------------------------------------------\n",
      "Column: highly_experienced_resident\n",
      "  Data Type: object\n",
      "  Value counts:\n",
      "    none: 81897\n",
      "    no: 47821\n",
      "    yes: 28646\n",
      "--------------------------------------------------\n",
      "Column: current_anesthesiologist_catheter_count\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    47404\n",
      "    Min:    0.0\n",
      "    Q1:     135.0\n",
      "    Median: 390.0\n",
      "    Q3:     930.0\n",
      "    Max:    4212.0\n",
      "--------------------------------------------------\n",
      "Column: moderately_experienced_anesthesiologist\n",
      "  Data Type: object\n",
      "  Value counts:\n",
      "    yes: 88748\n",
      "    none: 47404\n",
      "    no: 22212\n",
      "--------------------------------------------------\n",
      "Column: has_scoliosis\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    0: 156460\n",
      "    1: 1904\n",
      "--------------------------------------------------\n",
      "Column: has_dorsalgia\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    0: 119698\n",
      "    1: 38666\n",
      "--------------------------------------------------\n",
      "Column: has_back_problems\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    0: 131672\n",
      "    1: 26692\n",
      "--------------------------------------------------\n",
      "Column: maternal_race\n",
      "  Data Type: object\n",
      "  Value counts:\n",
      "    White: 103664\n",
      "    Other/Unknown: 24563\n",
      "    Asian: 15671\n",
      "    Black: 14466\n",
      "--------------------------------------------------\n",
      "Column: prior_pain_scores_max\n",
      "  Data Type: float64\n",
      "  Summary stats:\n",
      "    NaN:    88895\n",
      "    Min:    0.0\n",
      "    Q1:     30.0\n",
      "    Median: 60.0\n",
      "    Q3:     80.0\n",
      "    Max:    100.0\n",
      "--------------------------------------------------\n",
      "Column: composite_psychosocial_problems\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    0: 115571\n",
      "    1: 42793\n",
      "--------------------------------------------------\n",
      "Column: any_public_insurance\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    0: 126325\n",
      "    1: 32039\n",
      "--------------------------------------------------\n",
      "Column: maternal_language_english\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    1: 143337\n",
      "    0: 15027\n",
      "--------------------------------------------------\n",
      "Column: marital_status_married_or_partner\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    1: 120337\n",
      "    0: 38027\n",
      "--------------------------------------------------\n",
      "Column: country_of_origin_USA\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    1: 91864\n",
      "    0: 66500\n",
      "--------------------------------------------------\n",
      "Column: employment_status_fulltime\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    1: 97852\n",
      "    0: 60512\n",
      "--------------------------------------------------\n",
      "Column: epidural_needle_type\n",
      "  Data Type: object\n",
      "  Value counts:\n",
      "    weiss: 55186\n",
      "    other: 51677\n",
      "    tuohy: 51501\n",
      "--------------------------------------------------\n",
      "Column: paresthesias_present\n",
      "  Data Type: int64\n",
      "  Value counts:\n",
      "    0: 147325\n",
      "    1: 11039\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def describe_dataframe(df):\n",
    "    \"\"\"\n",
    "    For each column in df:\n",
    "      - If dtype is object or int64 or bool, list each unique value and its counts.\n",
    "      - If dtype is float64, display min, Q1, median, Q3, and max.\n",
    "      - Otherwise, handle accordingly (datetime, etc.).\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        print(f\"Column: {col}\")\n",
    "        print(f\"  Data Type: {col_type}\")\n",
    "\n",
    "        if col_type == 'object' or col_type == 'int64' or col_type == 'bool':\n",
    "            # Show unique values and their counts\n",
    "            value_counts = df[col].value_counts(dropna=False)\n",
    "            print(\"  Value counts:\")\n",
    "            for val, count in value_counts.items():\n",
    "                print(f\"    {val}: {count}\")\n",
    "\n",
    "        elif col_type == 'float64':\n",
    "            # Show min, Q1 (25%), median (50%), Q3 (75%), and max\n",
    "            desc = df[col].describe(percentiles=[0.25, 0.5, 0.75])\n",
    "            na_count = df[col].isna().sum()\n",
    "            print(\"  Summary stats:\")\n",
    "            print(f\"    NaN:    {na_count}\")\n",
    "            print(f\"    Min:    {desc['min']}\")\n",
    "            print(f\"    Q1:     {desc['25%']}\")\n",
    "            print(f\"    Median: {desc['50%']}\")\n",
    "            print(f\"    Q3:     {desc['75%']}\")\n",
    "            print(f\"    Max:    {desc['max']}\")\n",
    "\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            # Example handling for datetime columns\n",
    "            print(\"  (Datetime column – no numeric summary or value counts shown.)\")\n",
    "\n",
    "        else:\n",
    "            # Handle any other data types as needed\n",
    "            print(\"  (No specific handling implemented for this data type.)\")\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "describe_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_as_tables(df):\n",
    "    # Separate columns by dtype\n",
    "    categorical_cols = []\n",
    "    numeric_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' or df[col].dtype == 'int64' or df[col].dtype == 'bool':\n",
    "            categorical_cols.append(col)\n",
    "        elif df[col].dtype == 'float64':\n",
    "            numeric_cols.append(col)\n",
    "        else:\n",
    "            # skip or handle datetime, etc. if desired\n",
    "            pass\n",
    "\n",
    "    # --- Build table for categorical variables ---\n",
    "    cat_data = {}\n",
    "    for col in categorical_cols:\n",
    "        # Get value counts (including NaN as a separate category)\n",
    "        vc = df[col].value_counts(dropna=False)\n",
    "        # Convert value counts to a dict, or a formatted string\n",
    "        vc_str = \", \".join(f\"{val}: {count}\" for val, count in vc.items())\n",
    "        cat_data[col] = {\n",
    "            'value_counts': vc_str\n",
    "        }\n",
    "    cat_df = pd.DataFrame(cat_data).T  # Transpose so rows = columns, col = 'value_counts'\n",
    "\n",
    "    # --- Build table for numeric variables ---\n",
    "    num_data = {}\n",
    "    for col in numeric_cols:\n",
    "        desc = df[col].describe(percentiles=[0.25, 0.5, 0.75])\n",
    "        na_count = df[col].isna().sum()\n",
    "        num_data[col] = {\n",
    "            'count': desc['count'],\n",
    "            'count_nan': na_count,\n",
    "            'min': desc['min'],\n",
    "            'Q1': desc['25%'],\n",
    "            'median': desc['50%'],\n",
    "            'Q3': desc['75%'],\n",
    "            'max': desc['max']\n",
    "        }\n",
    "    num_df = pd.DataFrame(num_data).T  # Transpose so rows = columns\n",
    "\n",
    "    return cat_df, num_df\n",
    "\n",
    "cat_table, num_table = describe_as_tables(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delivery_site_2188</th>\n",
       "      <td>bwh: 64334, mgh: 35716, nwh: 35053, slm: 9973,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fetal_presentation_category_2243</th>\n",
       "      <td>cephalic: 134205, nan: 12656, breech: 7827, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fetal_presentation_subcategory_2244</th>\n",
       "      <td>vertex: 134037, nan: 20328, compound: 2990, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fetal_presentation_position_2247</th>\n",
       "      <td>nan: 80824, anterior: 67514, posterior: 7255, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_procedure_type</th>\n",
       "      <td>epidural: 93221, spinal: 25186, nan: 22402, cs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_neuraxial_catheter</th>\n",
       "      <td>1: 107523, 0: 50841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed_catheter</th>\n",
       "      <td>0: 152023, 1: 6341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dpe</th>\n",
       "      <td>0: 142193, 1: 16171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highly_experienced_anesthesiologist</th>\n",
       "      <td>no: 63149, yes: 47811, none: 47404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highly_experienced_resident</th>\n",
       "      <td>none: 81897, no: 47821, yes: 28646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderately_experienced_anesthesiologist</th>\n",
       "      <td>yes: 88748, none: 47404, no: 22212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_scoliosis</th>\n",
       "      <td>0: 156460, 1: 1904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_dorsalgia</th>\n",
       "      <td>0: 119698, 1: 38666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_back_problems</th>\n",
       "      <td>0: 131672, 1: 26692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maternal_race</th>\n",
       "      <td>White: 103664, Other/Unknown: 24563, Asian: 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>composite_psychosocial_problems</th>\n",
       "      <td>0: 115571, 1: 42793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any_public_insurance</th>\n",
       "      <td>0: 126325, 1: 32039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maternal_language_english</th>\n",
       "      <td>1: 143337, 0: 15027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_status_married_or_partner</th>\n",
       "      <td>1: 120337, 0: 38027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country_of_origin_USA</th>\n",
       "      <td>1: 91864, 0: 66500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status_fulltime</th>\n",
       "      <td>1: 97852, 0: 60512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epidural_needle_type</th>\n",
       "      <td>weiss: 55186, other: 51677, tuohy: 51501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paresthesias_present</th>\n",
       "      <td>0: 147325, 1: 11039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              value_counts\n",
       "delivery_site_2188                       bwh: 64334, mgh: 35716, nwh: 35053, slm: 9973,...\n",
       "fetal_presentation_category_2243         cephalic: 134205, nan: 12656, breech: 7827, co...\n",
       "fetal_presentation_subcategory_2244      vertex: 134037, nan: 20328, compound: 2990, tr...\n",
       "fetal_presentation_position_2247         nan: 80824, anterior: 67514, posterior: 7255, ...\n",
       "true_procedure_type                      epidural: 93221, spinal: 25186, nan: 22402, cs...\n",
       "is_neuraxial_catheter                                                  1: 107523, 0: 50841\n",
       "failed_catheter                                                         0: 152023, 1: 6341\n",
       "dpe                                                                    0: 142193, 1: 16171\n",
       "highly_experienced_anesthesiologist                     no: 63149, yes: 47811, none: 47404\n",
       "highly_experienced_resident                             none: 81897, no: 47821, yes: 28646\n",
       "moderately_experienced_anesthesiologist                 yes: 88748, none: 47404, no: 22212\n",
       "has_scoliosis                                                           0: 156460, 1: 1904\n",
       "has_dorsalgia                                                          0: 119698, 1: 38666\n",
       "has_back_problems                                                      0: 131672, 1: 26692\n",
       "maternal_race                            White: 103664, Other/Unknown: 24563, Asian: 15...\n",
       "composite_psychosocial_problems                                        0: 115571, 1: 42793\n",
       "any_public_insurance                                                   0: 126325, 1: 32039\n",
       "maternal_language_english                                              1: 143337, 0: 15027\n",
       "marital_status_married_or_partner                                      1: 120337, 0: 38027\n",
       "country_of_origin_USA                                                   1: 91864, 0: 66500\n",
       "employment_status_fulltime                                              1: 97852, 0: 60512\n",
       "epidural_needle_type                              weiss: 55186, other: 51677, tuohy: 51501\n",
       "paresthesias_present                                                   0: 147325, 1: 11039"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count_nan</th>\n",
       "      <th>min</th>\n",
       "      <th>Q1</th>\n",
       "      <th>median</th>\n",
       "      <th>Q3</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gestational_age_2052</th>\n",
       "      <td>156025.0</td>\n",
       "      <td>2339.0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>267.00000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baby_weight_2196</th>\n",
       "      <td>155113.0</td>\n",
       "      <td>3251.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.97670</td>\n",
       "      <td>3.329935</td>\n",
       "      <td>3.655104</td>\n",
       "      <td>7.169877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rom_thru_delivery_hours</th>\n",
       "      <td>138310.0</td>\n",
       "      <td>20054.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.45000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>12.066667</td>\n",
       "      <td>711.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi_end_pregnancy_2044</th>\n",
       "      <td>150134.0</td>\n",
       "      <td>8230.0</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>69.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maternal_weight_end_pregnancy_2045</th>\n",
       "      <td>152039.0</td>\n",
       "      <td>6325.0</td>\n",
       "      <td>0.089018</td>\n",
       "      <td>70.76041</td>\n",
       "      <td>79.786898</td>\n",
       "      <td>91.126707</td>\n",
       "      <td>218.997798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi_before_pregnancy_2161</th>\n",
       "      <td>109588.0</td>\n",
       "      <td>48776.0</td>\n",
       "      <td>6.660000</td>\n",
       "      <td>22.10000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>29.300000</td>\n",
       "      <td>67.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gravidity_2047</th>\n",
       "      <td>107712.0</td>\n",
       "      <td>50652.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parity_2048</th>\n",
       "      <td>94664.0</td>\n",
       "      <td>63700.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lor_depth</th>\n",
       "      <td>105277.0</td>\n",
       "      <td>53087.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.80000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_resident_catheter_count</th>\n",
       "      <td>76467.0</td>\n",
       "      <td>81897.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>332.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_anesthesiologist_catheter_count</th>\n",
       "      <td>110960.0</td>\n",
       "      <td>47404.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>135.00000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>4212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prior_pain_scores_max</th>\n",
       "      <td>69469.0</td>\n",
       "      <td>88895.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            count  count_nan        min  \\\n",
       "gestational_age_2052                     156025.0     2339.0  87.000000   \n",
       "baby_weight_2196                         155113.0     3251.0   0.000000   \n",
       "rom_thru_delivery_hours                  138310.0    20054.0   0.000000   \n",
       "bmi_end_pregnancy_2044                   150134.0     8230.0   5.800000   \n",
       "maternal_weight_end_pregnancy_2045       152039.0     6325.0   0.089018   \n",
       "bmi_before_pregnancy_2161                109588.0    48776.0   6.660000   \n",
       "gravidity_2047                           107712.0    50652.0   0.000000   \n",
       "parity_2048                               94664.0    63700.0   0.000000   \n",
       "lor_depth                                105277.0    53087.0   0.000000   \n",
       "current_resident_catheter_count           76467.0    81897.0   0.000000   \n",
       "current_anesthesiologist_catheter_count  110960.0    47404.0   0.000000   \n",
       "prior_pain_scores_max                     69469.0    88895.0   0.000000   \n",
       "\n",
       "                                                Q1      median          Q3  \\\n",
       "gestational_age_2052                     267.00000  275.000000  281.000000   \n",
       "baby_weight_2196                           2.97670    3.329935    3.655104   \n",
       "rom_thru_delivery_hours                    1.45000    5.450000   12.066667   \n",
       "bmi_end_pregnancy_2044                    27.00000   30.100000   34.200000   \n",
       "maternal_weight_end_pregnancy_2045        70.76041   79.786898   91.126707   \n",
       "bmi_before_pregnancy_2161                 22.10000   25.000000   29.300000   \n",
       "gravidity_2047                             1.00000    2.000000    3.000000   \n",
       "parity_2048                                0.00000    1.000000    1.000000   \n",
       "lor_depth                                  4.80000    5.000000    6.000000   \n",
       "current_resident_catheter_count           15.00000   36.000000   67.000000   \n",
       "current_anesthesiologist_catheter_count  135.00000  390.000000  930.000000   \n",
       "prior_pain_scores_max                     30.00000   60.000000   80.000000   \n",
       "\n",
       "                                                 max  \n",
       "gestational_age_2052                      308.000000  \n",
       "baby_weight_2196                            7.169877  \n",
       "rom_thru_delivery_hours                   711.816667  \n",
       "bmi_end_pregnancy_2044                     69.900000  \n",
       "maternal_weight_end_pregnancy_2045        218.997798  \n",
       "bmi_before_pregnancy_2161                  67.700000  \n",
       "gravidity_2047                             18.000000  \n",
       "parity_2048                                12.000000  \n",
       "lor_depth                                  18.000000  \n",
       "current_resident_catheter_count           332.000000  \n",
       "current_anesthesiologist_catheter_count  4212.000000  \n",
       "prior_pain_scores_max                     100.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: make a histogram of procedure note types using different colors\n",
    "\n",
    "# Assuming 'procedure_type' column exists in your DataFrame 'df'\n",
    "procedure_type_counts = df['true_procedure_type'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(procedure_type_counts.index, procedure_type_counts.values, color=['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'orange'])\n",
    "plt.xlabel('Procedure Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Procedure Note Types')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of successes/failures\n",
    "\n",
    "# Group by procedure type and whether it has subsequent anesthesia\n",
    "procedure_counts = pd.crosstab(neuraxial_catheter_df['true_procedure_type'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Sort the bars in descending order based on the total count of each procedure type\n",
    "procedure_counts = procedure_counts.sort_values(by=False, ascending=False)\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = procedure_counts.plot(kind='bar', stacked=True, figsize=(6\n",
    ", 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "  width = p.get_width()\n",
    "  height = p.get_height()\n",
    "  x, y = p.get_xy()\n",
    "  ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Procedure Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Successful/Failed')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the table with the same information\n",
    "print(\"Table of Neuraxial Catheter Procedures by Success/Failure:\")\n",
    "print(procedure_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anesthesiologist Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Create a similar histogram for failure rate vs highly experienced anesthesiologist\n",
    "\n",
    "# Group by 'highly_experienced_anesthesiologist' and 'failed_catheter'\n",
    "experience_failure_counts = pd.crosstab(neuraxial_catheter_df['highly_experienced_anesthesiologist'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = experience_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Anesthesiologist Experience')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Anesthesiologist Experience')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0,1,2], labels=['No Anesthesiologist','Not Highly Experienced', 'Highly Experienced'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Anesthesiologist Experience:\")\n",
    "experience_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: create a similar histogram for failure rate vs moderately experienced anesthesiologist\n",
    "\n",
    "# Group by 'moderately_experienced_anesthesiologist' and 'failed_catheter'\n",
    "experience_failure_counts = pd.crosstab(neuraxial_catheter_df['moderately_experienced_anesthesiologist'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = experience_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Anesthesiologist Experience')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Moderately Experienced Anesthesiologist')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0,1,2], labels=['No Anesthesiologist','Not Moderately Experienced', 'Moderately Experienced'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Moderately Experienced Anesthesiologist:\")\n",
    "experience_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Create a similar histogram for failure rate vs highly experienced resident\n",
    "\n",
    "# Group by 'highly_experienced_resident' and 'failed_catheter'\n",
    "experience_failure_counts = pd.crosstab(neuraxial_catheter_df['highly_experienced_resident'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = experience_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Resident Experience')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Resident Experience')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0,1,2], labels=['No Resident','Not Highly Experienced', 'Highly Experienced'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Resident Experience:\")\n",
    "experience_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Create a similar histogram but look at all combinations of resident and anesthesiologist experience. Make the x-axis labels vertical.\n",
    "\n",
    "# Group by 'highly_experienced_anesthesiologist', 'highly_experienced_resident', and 'failed_catheter'\n",
    "experience_failure_counts = pd.crosstab([neuraxial_catheter_df['highly_experienced_anesthesiologist'], neuraxial_catheter_df['highly_experienced_resident']], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = experience_failure_counts.plot(kind='bar', stacked=True, figsize=(8, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Anesthesiologist and Resident Experience')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Anesthesiologist and Resident Experience')\n",
    "\n",
    "\n",
    "# Customize x-axis labels\n",
    "import itertools\n",
    "anesth_levels = [\"Anes=None\", \"Anes=Not Exp\", \"Anes=Exp\"]\n",
    "resident_levels = [\"Res=None\", \"Res=Not Exp\", \"Res=Exp\"]\n",
    "labels = list(itertools.product(anesth_levels, resident_levels))\n",
    "plt.xticks(rotation=90, ha='center', ticks=range(len(labels)), labels=labels)\n",
    "\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Anesthesiologist and Resident Experience:\")\n",
    "experience_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: crosstab resident experience by BMI and make violin plots\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
    "# and it contains columns 'bmi_end_pregnancy_2044' and 'resident_experience' (or a similar column)\n",
    "\n",
    "# Create the cross-tabulation\n",
    "crosstab_data = pd.crosstab(neuraxial_catheter_df['bmi_end_pregnancy_2044'], neuraxial_catheter_df['highly_experienced_resident'])\n",
    "\n",
    "# Display the cross-tabulation\n",
    "print(\"Crosstab of Resident Experience by BMI:\")\n",
    "print(crosstab_data)\n",
    "\n",
    "# Create violin plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x='highly_experienced_resident', y='bmi_end_pregnancy_2044', data=df)\n",
    "plt.xlabel('Resident Experience')  # Customize the x-axis label\n",
    "plt.ylabel('BMI') # Customize the y-axis label\n",
    "plt.title('Violin Plot of BMI by Resident Experience')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delivery Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: create a similar histogram of delivery_site_2188 using crosstab\n",
    "\n",
    "# Create a crosstab for 'delivery_site_2188' and visualize it as a histogram\n",
    "delivery_site_counts = pd.crosstab(neuraxial_catheter_df['delivery_site_2188'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Sort the bars in descending order based on the total count of each delivery site\n",
    "delivery_site_counts = delivery_site_counts.sort_values(by=False, ascending=False)\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = delivery_site_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Delivery Site')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Delivery Site by Success/Failure')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Delivery Site by Success/Failure:\")\n",
    "delivery_site_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: # prompt: create a pie chart of the fraction of DPE in epidural_df\n",
    "\n",
    "# Count DPE values, treating NaN and '' as \"no\"\n",
    "dpe_counts = epidural_df['dpe'].value_counts()\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(dpe_counts, labels=dpe_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Fraction of DPE in Epidural Procedures')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: reproduce the above histogram using crosstab on delivery_site_2188 and dpe\n",
    "\n",
    "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
    "\n",
    "# Create a crosstab for 'delivery_site_2188' and 'dpe' and visualize it as a histogram\n",
    "delivery_site_dpe_counts = pd.crosstab(epidural_df['delivery_site_2188'], epidural_df['dpe'])\n",
    "\n",
    "# Sort the bars in descending order based on the total count of each delivery site\n",
    "delivery_site_dpe_counts = delivery_site_dpe_counts.sort_values(by=True, ascending=False) # Sort by 'no'\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = delivery_site_dpe_counts.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Delivery Site')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Delivery Site by DPE')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['DPE: no', 'DPE: yes']) # Update legend labels\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Delivery Site by DPE:\")\n",
    "delivery_site_dpe_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of successes/failures by DPE status\n",
    "\n",
    "# Group by procedure type and whether it has subsequent anesthesia\n",
    "dpe_crosstab = pd.crosstab(epidural_df['dpe'], epidural_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = dpe_crosstab.plot(kind='bar', stacked=True, figsize=(6\n",
    ", 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "  width = p.get_width()\n",
    "  height = p.get_height()\n",
    "  x, y = p.get_xy()\n",
    "  ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('DPE Status')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Successful/Failed')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do a crosstab histogram of failure versus delivery_site_2188 and dpe\n",
    "\n",
    "# Assuming 'df' is your DataFrame (as defined in the provided code)\n",
    "\n",
    "# Create a crosstab for 'delivery_site_2188', 'dpe', and 'failed_catheter'\n",
    "crosstab_df = pd.crosstab([df['delivery_site_2188'], df['dpe']], df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = crosstab_df.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "\n",
    "# Annotate the bars with percentages\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "\n",
    "plt.xlabel('Delivery Site and DPE')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Crosstab Histogram: Failure vs. Delivery Site and DPE')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the crosstab table\n",
    "print(\"Crosstab Table:\")\n",
    "crosstab_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoliosis and back problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: create a histogram of the crosstab of has_scoliosis vs failure_rate\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame (as defined in the provided code)\n",
    "\n",
    "# Group by 'has_scoliosis' and 'failed_catheter'\n",
    "scoliosis_failure_counts = pd.crosstab(neuraxial_catheter_df['has_scoliosis'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = scoliosis_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Has Scoliosis')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Scoliosis')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0, 1], labels=['No Scoliosis', 'Scoliosis'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Scoliosis:\")\n",
    "scoliosis_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same but for has_back_problems\n",
    "\n",
    "# Group by 'has_back_problems' and 'failed_catheter'\n",
    "back_problems_failure_counts = pd.crosstab(neuraxial_catheter_df['has_back_problems'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = back_problems_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Has Back Problems')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Back Problems')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0, 1], labels=['No Back Problems', 'Back Problems'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Back Problems:\")\n",
    "back_problems_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same but for has_dorsalgia\n",
    "\n",
    "# Group by 'has_dorsalgia' and 'failed_catheter'\n",
    "back_pain_failure_counts = pd.crosstab(neuraxial_catheter_df['has_dorsalgia'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = back_pain_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Has Back Pain')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Back Pain')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0, 1], labels=['No Back Pain', 'Back Pain'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Back Pain:\")\n",
    "back_pain_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetal Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same histogram, but for fetal_presentation_category vs failure\n",
    "\n",
    "# Group by 'fetal_presentation_category_2243' and 'failed_catheter'\n",
    "fetal_presentation_failure_counts = pd.crosstab(neuraxial_catheter_df['fetal_presentation_category_2243'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = fetal_presentation_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Fetal Presentation Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Fetal Presentation Category')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Fetal Presentation Category:\")\n",
    "fetal_presentation_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same histogram, but for fetal_presentation_position vs failure\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame (as defined in the provided code)\n",
    "\n",
    "# Group by 'fetal_presentation_position_2247' and 'failed_catheter'\n",
    "fetal_position_failure_counts = pd.crosstab(neuraxial_catheter_df['fetal_presentation_position_2247'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = fetal_position_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Fetal Presentation Position')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Fetal Presentation Position')\n",
    "plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Fetal Presentation Position:\")\n",
    "fetal_position_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race and SES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same histogram, but for maternal_race vs failure\n",
    "\n",
    "# Group by 'maternal_race' and 'failed_catheter'\n",
    "race_failure_counts = pd.crosstab(neuraxial_catheter_df['maternal_race'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = race_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Maternal Race')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Maternal Race')\n",
    "plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Maternal Race:\")\n",
    "race_failure_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same histogram, but for each of these: 32. composite_psychosocial_problems ||| int64\n",
    "# 33. any_public_insurance ||| int64\n",
    "# 34. maternal_language_english ||| int64\n",
    "# 35. marital_status_married_or_partner ||| int64\n",
    "# 36. country_of_origin_USA ||| int64\n",
    "# 37. employment_status_fulltime ||| int64\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "columns_to_analyze = [\n",
    "    'composite_psychosocial_problems',\n",
    "    'any_public_insurance',\n",
    "    'maternal_language_english',\n",
    "    'marital_status_married_or_partner',\n",
    "    'country_of_origin_USA',\n",
    "    'employment_status_fulltime'\n",
    "]\n",
    "\n",
    "for column in columns_to_analyze:\n",
    "  # Group by the current column and 'failed_catheter'\n",
    "  failure_counts = pd.crosstab(neuraxial_catheter_df[column], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "  # Create a stacked bar chart\n",
    "  ax = failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "  # Add percentages within each bar\n",
    "  for p in ax.patches:\n",
    "      width = p.get_width()\n",
    "      height = p.get_height()\n",
    "      x, y = p.get_xy()\n",
    "      ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "  plt.xlabel(column)\n",
    "  plt.ylabel('Count')\n",
    "  plt.title(f'Histogram of Failure Rate vs. {column}')\n",
    "\n",
    "  # Customize x-axis ticks and labels (adjust as needed for each column)\n",
    "  plt.xticks(rotation=0, ha='center')\n",
    "\n",
    "  plt.legend(['Successful', 'Failed'])\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "  # Display the table with the same information\n",
    "  print(f\"Table of Failure Rate vs. {column}:\")\n",
    "failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same histogram but for prior_pain_scores_max\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "# Group by 'prior_pain_scores_max' and 'failed_catheter'\n",
    "prior_pain_failure_counts = pd.crosstab(neuraxial_catheter_df['prior_pain_scores_max'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = prior_pain_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Prior Pain Scores Max')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Prior Pain Scores Max')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels if needed\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Prior Pain Scores Max:\")\n",
    "prior_pain_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gravidity and Parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same histogram but for gravidity_2047 and parity_2048\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "# Group by 'gravidity_2047' and 'failed_catheter'\n",
    "gravidity_failure_counts = pd.crosstab(neuraxial_catheter_df['gravidity_2047'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = gravidity_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Gravidity')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Gravidity')\n",
    "plt.xticks(rotation=0)  # Adjust rotation if needed\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table\n",
    "print(\"Table of Failure Rate vs. Gravidity:\")\n",
    "print(gravidity_failure_counts)\n",
    "\n",
    "\n",
    "# Group by 'parity_2048' and 'failed_catheter'\n",
    "parity_failure_counts = pd.crosstab(neuraxial_catheter_df['parity_2048'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = parity_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Parity')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Parity')\n",
    "plt.xticks(rotation=0)  # Adjust rotation if needed\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table\n",
    "print(\"Table of Failure Rate vs. Parity:\")\n",
    "parity_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needle Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same histogram but for epidural_needle_type\n",
    "\n",
    "# Assuming 'epidural_df' is your DataFrame (as defined in the provided code)\n",
    "\n",
    "# Group by 'epidural_needle_type' and 'failed_catheter'\n",
    "needle_type_failure_counts = pd.crosstab(epidural_df['epidural_needle_type'], epidural_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = needle_type_failure_counts.plot(kind='bar', stacked=True, figsize=(10, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Epidural Needle Type')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Epidural Needle Type')\n",
    "plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Epidural Needle Type:\")\n",
    "needle_type_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paresthesias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same histogram but for paresthesias_present\n",
    "\n",
    "# Group by 'paresthesias_present' and 'failed_catheter'\n",
    "paresthesias_failure_counts = pd.crosstab(neuraxial_catheter_df['paresthesias_present'], neuraxial_catheter_df['failed_catheter'])\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = paresthesias_failure_counts.plot(kind='bar', stacked=True, figsize=(6, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "# Add percentages within each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.annotate(f'{height/sum([p.get_height() for p in ax.patches if p.get_x() == x]) * 100:.1f}%', (x + width/2, y + height/2), ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Paresthesias Present')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Failure Rate vs. Paresthesias Present')\n",
    "plt.xticks(rotation=0, ha='center', ticks=[0, 1], labels=['No Paresthesias', 'Paresthesias'])\n",
    "plt.legend(['Successful', 'Failed'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the table with the same information\n",
    "print(\"Table of Failure Rate vs. Paresthesias Present:\")\n",
    "paresthesias_failure_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: create a histogram of the number of attempts. Only show integers on the x-axis\n",
    "\n",
    "# Assuming 'number_of_neuraxial_attempts' is a column in your DataFrame 'df'\n",
    "attempts_counts = df['number_of_neuraxial_attempts'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(attempts_counts.index, attempts_counts.values)\n",
    "plt.xlabel('Number of Attempts')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Number of Neuraxial Attempts')\n",
    "plt.xticks(range(int(attempts_counts.index.min()), int(attempts_counts.index.max()) + 1))  # Show only integer ticks on x-axis\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss of Resistance Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: create a histogram of loss of resistance depth. Center the bars over the tick marks and make space between the bars. Bins should be every 0.5\n",
    "\n",
    "# Assuming 'lor_depth' is a column in your DataFrame 'df'\n",
    "lor_depths = neuraxial_catheter_df['lor_depth'].dropna()  # Remove NaN values\n",
    "\n",
    "# Create the histogram with centered bars and spacing\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(lor_depths, bins=np.arange(lor_depths.min(), lor_depths.max() + 0.5, 0.5), rwidth=0.8, align='left')\n",
    "plt.xlabel('Loss of Resistance Depth')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Loss of Resistance Depth')\n",
    "plt.xticks(np.arange(0, lor_depths.max() + 0.5, 1))  # Set x-axis ticks to be at every 1\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Plot number of neuraxial attempts vs LOR depth on the x-axis. Add jiggle to both x and y axes\n",
    "\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['number_of_neuraxial_attempts', 'lor_depth'])\n",
    "\n",
    "# Add random jiggle to both x and y axes\n",
    "jiggle_x = np.random.normal(scale = 0.1, size=len(df_plot))\n",
    "jiggle_y = np.random.normal(scale = 0.1, size=len(df_plot))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_plot['lor_depth'] + jiggle_x, df_plot['number_of_neuraxial_attempts'] + jiggle_y, alpha=0.5)\n",
    "plt.xlabel('LOR Depth')\n",
    "plt.ylabel('Number of Neuraxial Attempts')\n",
    "plt.title('Number of Neuraxial Attempts vs. LOR Depth with Jiggle')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same but add shaded error bars for +/- standard error of the mean\n",
    "\n",
    "# Assuming 'number_of_neuraxial_attempts' and 'failed_catheter' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['number_of_neuraxial_attempts'])\n",
    "\n",
    "# Group by number of attempts and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_attempts = df_plot.groupby('number_of_neuraxial_attempts')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot with error bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_attempts.index, failure_by_attempts['mean'], marker='o')\n",
    "plt.fill_between(failure_by_attempts.index,\n",
    "                 failure_by_attempts['mean'] - failure_by_attempts['sem'],\n",
    "                 failure_by_attempts['mean'] + failure_by_attempts['sem'],\n",
    "                 alpha=0.2) # Add shaded error bars\n",
    "plt.errorbar(failure_by_attempts.index, failure_by_attempts['mean'], yerr=failure_by_attempts['sem'], fmt='o-', capsize=5, elinewidth=1)  # Added error bars\n",
    "plt.xlabel('Number of Neuraxial Attempts')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Number of Neuraxial Attempts with Error Bars')\n",
    "plt.xticks(np.arange(0, failure_by_attempts['number_of_neuraxial_attempts'].max() + 0.5, 1))  # Set x-axis ticks to be at every 0.5\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Plot lor-depth against bmi\n",
    "\n",
    "# Assuming 'lor_depth' and 'bmi_end_pregnancy_2044' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['lor_depth', 'bmi_end_pregnancy_2044'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_plot['bmi_end_pregnancy_2044'], df_plot['lor_depth'])\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('LOR Depth')\n",
    "plt.title('LOR Depth vs. BMI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Extract the data, dropping NaNs\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['lor_depth', 'bmi_end_pregnancy_2044'])\n",
    "x = df_plot['bmi_end_pregnancy_2044'].values\n",
    "y = df_plot['lor_depth'].values\n",
    "\n",
    "# Perform kernel density estimation\n",
    "xy = np.vstack([x, y])\n",
    "kde = gaussian_kde(xy)\n",
    "\n",
    "# Define grid over data range\n",
    "xmin, xmax = x.min() - 1, x.max() + 1\n",
    "ymin, ymax = y.min() - 1, y.max() + 1\n",
    "X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "Z = np.reshape(kde(positions).T, X.shape)\n",
    "\n",
    "# Create the contour plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.contourf(X, Y, Z, levels=15, cmap='viridis')\n",
    "plt.colorbar(label='Density')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('LOR Depth')\n",
    "plt.title('Contour Plot of LOR Depth vs. BMI (KDE)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same but for failure vs loss of resistance depth. Bin the depth by units of 1\n",
    "\n",
    "# Assuming 'lor_depth' and 'failed_catheter' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['lor_depth', 'failed_catheter'])\n",
    "\n",
    "# Bin the LOR depth\n",
    "df_plot['lor_depth_bin'] = (df_plot['lor_depth'] // 1).astype(int)\n",
    "\n",
    "# Group by the binned LOR depth and calculate the mean of failed_catheter\n",
    "failure_by_lor_depth = df_plot.groupby('lor_depth_bin')['failed_catheter'].mean()\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_lor_depth.index, failure_by_lor_depth.values, marker='o')\n",
    "plt.xlabel('Loss of Resistance Depth (binned)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Loss of Resistance Depth (binned by 1)')\n",
    "plt.xticks(np.arange(0, df_plot['lor_depth'].max() + 0.5, 1))  # Set x-axis ticks to be at every 1\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Reproduce the same plot, but add shaded error bars for +/- standard error of the mean\n",
    "\n",
    "# Assuming 'lor_depth' and 'failed_catheter' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['lor_depth', 'failed_catheter'])\n",
    "\n",
    "# Bin the LOR depth\n",
    "df_plot['lor_depth_bin'] = (df_plot['lor_depth'] // 1).astype(int)\n",
    "\n",
    "# Group by the binned LOR depth and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_lor_depth = df_plot.groupby('lor_depth_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_lor_depth.index, failure_by_lor_depth['mean'], marker='o')\n",
    "plt.fill_between(failure_by_lor_depth.index,\n",
    "                 failure_by_lor_depth['mean'] - failure_by_lor_depth['sem'],\n",
    "                 failure_by_lor_depth['mean'] + failure_by_lor_depth['sem'],\n",
    "                 alpha=0.5) # Add shaded error bars\n",
    "\n",
    "plt.xlabel('Loss of Resistance Depth (binned)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Loss of Resistance Depth (binned by 1) with Error Bars')\n",
    "plt.xticks(np.arange(0, df_plot['lor_depth'].max() + 0.5, 1))  # Set x-axis ticks to be at every 1\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BMI / height / weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: plot bmi end pregnancy against failure rate using binning as above.\n",
    "\n",
    "# Assuming 'bmi_end_pregnancy' and 'failed_catheter' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['bmi_end_pregnancy_2044', 'failed_catheter'])\n",
    "\n",
    "# Bin the bmi_end_pregnancy\n",
    "df_plot['bmi_end_pregnancy_bin'] = (df_plot['bmi_end_pregnancy_2044'] // 1).astype(int)\n",
    "\n",
    "# Group by the binned bmi_end_pregnancy and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_bmi = df_plot.groupby('bmi_end_pregnancy_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_bmi.index, failure_by_bmi['mean'], marker='o')\n",
    "plt.fill_between(failure_by_bmi.index,\n",
    "                 failure_by_bmi['mean'] - failure_by_bmi['sem'],\n",
    "                 failure_by_bmi['mean'] + failure_by_bmi['sem'],\n",
    "                 alpha=0.5) # Add shaded error bars\n",
    "\n",
    "plt.xlabel('BMI (kg/m^2) at End of Pregnancy (binned by 1)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. BMI at End of Pregnancy (binned by 1) with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: # prompt: plot weight end pregnancy against failure rate using binning as above.\n",
    "\n",
    "# Assuming 'maternal_weight_end_pregnancy_2045' and 'failed_catheter' are columns in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['maternal_weight_end_pregnancy_2045', 'failed_catheter'])\n",
    "\n",
    "# Bin the maternal weight at the end of pregnancy\n",
    "df_plot['weight_end_pregnancy_bin'] = (df_plot['maternal_weight_end_pregnancy_2045'] // 10).astype(int) * 10\n",
    "\n",
    "# Group by the binned weight and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_weight = df_plot.groupby('weight_end_pregnancy_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_weight.index, failure_by_weight['mean'], marker='o')\n",
    "plt.fill_between(failure_by_weight.index,\n",
    "                 failure_by_weight['mean'] - failure_by_weight['sem'],\n",
    "                 failure_by_weight['mean'] + failure_by_weight['sem'],\n",
    "                 alpha=0.5)  # Add shaded error bars\n",
    "\n",
    "plt.xlabel('Maternal Weight (kg) at End of Pregnancy (binned by 10)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Maternal Weight at End of Pregnancy (binned by 10) with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same but for height\n",
    "\n",
    "# Assuming 'height' is a column in your DataFrame 'df'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['maternal_height_2046', 'failed_catheter'])\n",
    "\n",
    "# Drop heights greater than 250\n",
    "df_plot = df_plot[df_plot['maternal_height_2046'] <= 250]\n",
    "\n",
    "# Bin the height\n",
    "df_plot['height_bin'] = (df_plot['maternal_height_2046'] // 1).astype(int)\n",
    "\n",
    "# Group by the binned height and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_height = df_plot.groupby('height_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_height.index, failure_by_height['mean'], marker='o')\n",
    "plt.fill_between(failure_by_height.index,\n",
    "                 failure_by_height['mean'] - failure_by_height['sem'],\n",
    "                 failure_by_height['mean'] + failure_by_height['sem'],\n",
    "                 alpha=0.5) # Add shaded error bars\n",
    "\n",
    "plt.xlabel('Height (binned by 1)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Height (binned by 1) with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestational Age and Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same but for gestational age\n",
    "\n",
    "# Histogram of gestational age\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['gestational_age_2052'].dropna(), bins=20) # Adjust bins as needed\n",
    "plt.xlabel('Gestational Age (days)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Gestational Age')\n",
    "plt.show()\n",
    "\n",
    "# Analyze gestational age in relation to failed catheter\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['gestational_age_2052', 'failed_catheter'])\n",
    "df_plot['gestational_age_bin'] = (df_plot['gestational_age_2052'] // 7).astype(int) * 7\n",
    "failure_by_gestational_age = df_plot.groupby('gestational_age_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_gestational_age.index, failure_by_gestational_age['mean'], marker='o')\n",
    "plt.fill_between(failure_by_gestational_age.index,\n",
    "                failure_by_gestational_age['mean'] - failure_by_gestational_age['sem'],\n",
    "                failure_by_gestational_age['mean'] + failure_by_gestational_age['sem'],\n",
    "                alpha=0.5)\n",
    "plt.xlabel('Gestational Age (days) (binned by 7)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Gestational Age (binned by 7) with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same histogram and binned failure rate but for baby_weight_2196\n",
    "\n",
    "# Assuming 'baby_weight_2196' is a column in your DataFrame 'df' or 'neuraxial_catheter_df'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(neuraxial_catheter_df['baby_weight_2196'].dropna(), bins=20)  # Adjust bins as needed\n",
    "plt.xlabel('Baby Weight (kg)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Baby Weight')\n",
    "plt.show()\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['baby_weight_2196', 'failed_catheter'])\n",
    "\n",
    "# Bin the baby weight\n",
    "df_plot['baby_weight_bin'] = (df_plot['baby_weight_2196'] // 0.5) * 0.5\n",
    "\n",
    "# Group by the binned baby weight and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_baby_weight = df_plot.groupby('baby_weight_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_baby_weight.index, failure_by_baby_weight['mean'], marker='o')\n",
    "plt.fill_between(failure_by_baby_weight.index,\n",
    "                 failure_by_baby_weight['mean'] - failure_by_baby_weight['sem'],\n",
    "                 failure_by_baby_weight['mean'] + failure_by_baby_weight['sem'],\n",
    "                 alpha=0.5)  # Add shaded error bars\n",
    "\n",
    "plt.xlabel('Baby Weight (kg) (binned by 0.5)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Baby Weight with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same count histogram but for secs_rom_thru_delivery_2197\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "# Drop NaN values in 'secs_rom_thru_delivery_2197'\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['rom_thru_delivery_hours'])\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_plot['rom_thru_delivery_hours'], bins=200)  # Adjust bins as needed\n",
    "plt.xlabel('Hours from ROM to Delivery')\n",
    "plt.xlim(0,100)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Hours from ROM to Delivery')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: do the same binned plot for rom_thru_delivery_hours\n",
    "\n",
    "# Assuming 'neuraxial_catheter_df' is your DataFrame\n",
    "\n",
    "df_plot = neuraxial_catheter_df.dropna(subset=['rom_thru_delivery_hours', 'failed_catheter'])\n",
    "\n",
    "# Bin the rom_thru_delivery_hours\n",
    "df_plot['rom_thru_delivery_hours_bin'] = (df_plot['rom_thru_delivery_hours'] // 1).astype(int)\n",
    "\n",
    "# Group by the binned rom_thru_delivery_hours and calculate the mean and standard error of the mean of failed_catheter\n",
    "failure_by_rom_delivery = df_plot.groupby('rom_thru_delivery_hours_bin')['failed_catheter'].agg(['mean', 'sem'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(failure_by_rom_delivery.index, failure_by_rom_delivery['mean'], marker='o')\n",
    "plt.fill_between(failure_by_rom_delivery.index,\n",
    "                 failure_by_rom_delivery['mean'] - failure_by_rom_delivery['sem'],\n",
    "                 failure_by_rom_delivery['mean'] + failure_by_rom_delivery['sem'],\n",
    "                 alpha=0.5)  # Add shaded error bars\n",
    "plt.xlim(0,100)\n",
    "plt.xlabel('Hours from ROM to Delivery (binned)')\n",
    "plt.ylabel('Average Failure Rate')\n",
    "plt.title('Failure Rate vs. Hours from ROM to Delivery (binned by 1) with Error Bars')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df_corr = neuraxial_catheter_df.dropna(subset=['lor_depth', 'number_of_neuraxial_attempts'])\n",
    "\n",
    "# Fit the model using the formula\n",
    "model = smf.ols('number_of_neuraxial_attempts ~ lor_depth', data=df_corr).fit()\n",
    "\n",
    "# Print the summary of the regression results\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical variables like DPE and failed_catheter\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "dpe_crosstab = pd.crosstab(epidural_df['DPE'], epidural_df['failed_catheter'])\n",
    "chi2, p, _, _ = chi2_contingency(dpe_crosstab)\n",
    "\n",
    "print(dpe_crosstab.div(dpe_crosstab.sum(axis=1), axis=0) * 100)\n",
    "print(\"Chi-squared statistic:\", chi2)\n",
    "print(\"P-value:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.219833\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        failed_catheter   No. Observations:               103125\n",
      "Model:                          Logit   Df Residuals:                   103123\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Fri, 10 Jan 2025   Pseudo R-squ.:                0.004623\n",
      "Time:                        16:22:31   Log-Likelihood:                -22670.\n",
      "converged:                       True   LL-Null:                       -22776.\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.032e-47\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -3.6014      0.057    -63.100      0.000      -3.713      -3.490\n",
      "lor_depth      0.1439      0.010     14.891      0.000       0.125       0.163\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# prompt: Do univariate logistic regression separately using number of attempts and loss of resistance depth to predict failure\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# # Prepare the data for logistic regression with number of attempts as the predictor\n",
    "# df_logreg_attempts = neuraxial_catheter_df.dropna(subset=['number_of_neuraxial_attempts', 'failed_catheter'])\n",
    "# # Fit the logistic regression model\n",
    "# model_attempts = smf.logit('failed_catheter ~ number_of_neuraxial_attempts', data=df_logreg_attempts).fit()\n",
    "\n",
    "# # Print the summary of the model\n",
    "# print(model_attempts.summary())\n",
    "\n",
    "\n",
    "# Prepare the data for logistic regression with loss of resistance depth as the predictor\n",
    "df_logreg_lor = neuraxial_catheter_df.dropna(subset=['lor_depth', 'failed_catheter'])\n",
    "# Fit the logistic regression model\n",
    "model_lor = smf.logit('failed_catheter ~ lor_depth', data=df_logreg_lor).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model_lor.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Now do multivariate analysis using the same two predictors\n",
    "\n",
    "# Prepare the data for logistic regression with both predictors\n",
    "df_logreg_multi = neuraxial_catheter_df.dropna(subset=['number_of_neuraxial_attempts', 'LOR_depth', 'failed_catheter'])\n",
    "\n",
    "# Fit the logistic regression model with both predictors\n",
    "model_multi = smf.logit('failed_catheter ~ number_of_neuraxial_attempts + LOR_depth', data=df_logreg_multi).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model_multi.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping column gestational_age_2052 due to fitting error: endog has evaluated to an array with multiple columns that has shape (107512, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column delivery_site_2188 due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column baby_weight_2196 due to fitting error: endog has evaluated to an array with multiple columns that has shape (106766, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column rom_thru_delivery_hours due to fitting error: endog has evaluated to an array with multiple columns that has shape (101989, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column fetal_presentation_category_2243 due to fitting error: endog has evaluated to an array with multiple columns that has shape (102123, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column fetal_presentation_subcategory_2244 due to fitting error: endog has evaluated to an array with multiple columns that has shape (100651, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column fetal_presentation_position_2247 due to fitting error: endog has evaluated to an array with multiple columns that has shape (60555, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column bmi_end_pregnancy_2044 due to fitting error: endog has evaluated to an array with multiple columns that has shape (104155, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column maternal_weight_end_pregnancy_2045 due to fitting error: endog has evaluated to an array with multiple columns that has shape (105299, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column bmi_before_pregnancy_2161 due to fitting error: endog has evaluated to an array with multiple columns that has shape (75681, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column gravidity_2047 due to fitting error: endog has evaluated to an array with multiple columns that has shape (75968, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column parity_2048 due to fitting error: endog has evaluated to an array with multiple columns that has shape (63569, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column true_procedure_type due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column dpe due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column lor_depth due to fitting error: endog has evaluated to an array with multiple columns that has shape (103125, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column current_resident_catheter_count due to fitting error: endog has evaluated to an array with multiple columns that has shape (60013, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column highly_experienced_anesthesiologist due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column highly_experienced_resident due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column current_anesthesiologist_catheter_count due to fitting error: endog has evaluated to an array with multiple columns that has shape (87739, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column moderately_experienced_anesthesiologist due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column has_scoliosis due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column has_dorsalgia due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column has_back_problems due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column maternal_race due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column prior_pain_scores_max due to fitting error: endog has evaluated to an array with multiple columns that has shape (61143, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column composite_psychosocial_problems due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column any_public_insurance due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column maternal_language_english due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column marital_status_married_or_partner due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column country_of_origin_USA due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column employment_status_fulltime due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column epidural_needle_type due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n",
      "Skipping column paresthesias_present due to fitting error: endog has evaluated to an array with multiple columns that has shape (107523, 2). This occurs when the variable converted to endog is non-numeric (e.g., bool or str).\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19472\\3005641523.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;31m# Usage:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m \u001b[0mresults_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_regressions_single_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuraxial_catheter_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'failed_catheter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;31m# results_df will have columns [column, coef, pval].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m# The plot shows each predictor's slope vs. its -log10(p-value).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19472\\3005641523.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df, outcome_col)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;34m'pval'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m# Create a results DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mresults_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pval'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# Plot: x=coefficient, y=-log10(p-value)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7185\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7186\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7187\u001b[0m             \u001b[1;31m# len(by) == 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7189\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7191\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7192\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pval'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def all_regressions_single_plot(df, outcome_col='failed_catheter'):\n",
    "    \"\"\"\n",
    "    1) For each column in df (except the outcome_col and unsupported dtypes),\n",
    "       fit a logistic regression of outcome_col ~ predictor.\n",
    "    2) Extract the predictor's coefficient and p-value.\n",
    "    3) Combine into a single DataFrame and plot x=coefficient, y=-log10(p-value).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Safety check: ensure the outcome is binary (0/1)\n",
    "    # If it's not, you may need:\n",
    "    # df[outcome_col] = df[outcome_col].map({False:0, True:1})\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        # Skip the outcome column itself\n",
    "        if col == outcome_col:\n",
    "            continue\n",
    "        \n",
    "        # Skip datetime or other unsupported dtypes\n",
    "        if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            continue\n",
    "        \n",
    "        # Drop rows that are NaN in either outcome or predictor (to avoid fitting errors)\n",
    "        temp_df = df[[outcome_col, col]].dropna()\n",
    "\n",
    "        # If the column is all one value or empty, skip\n",
    "        if temp_df[col].nunique() < 2:\n",
    "            continue\n",
    "\n",
    "        # Build the formula\n",
    "        # For categorical columns, wrap in C()\n",
    "        if pd.api.types.is_numeric_dtype(temp_df[col]):\n",
    "            formula = f\"{outcome_col} ~ {col}\"\n",
    "        else:\n",
    "            formula = f\"{outcome_col} ~ C({col})\"\n",
    "\n",
    "        # Fit the logistic regression\n",
    "        try:\n",
    "            model = smf.logit(formula, data=temp_df).fit(disp=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping column {col} due to fitting error: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # model.params and model.pvalues each contain:\n",
    "        #   Index 0 = Intercept\n",
    "        #   Index 1,2,... = Coefficients for the variable(s)\n",
    "        # For numeric or 2-level categorical, there's only 1 predictor coefficient.\n",
    "        # For multi-level categorical, there will be multiple dummy variables.\n",
    "        \n",
    "        # We'll capture only the *first* coefficient for the predictor (index 1).\n",
    "        if len(model.params) < 2:\n",
    "            # Means no separate predictor param was generated\n",
    "            continue\n",
    "        \n",
    "        # The predictor is at index 1 in model.params\n",
    "        coef = model.params[1]\n",
    "        pval = model.pvalues[1]\n",
    "        \n",
    "        results.append({\n",
    "            'column': col,\n",
    "            'coef': coef,\n",
    "            'pval': pval\n",
    "        })\n",
    "\n",
    "    # Create a results DataFrame\n",
    "    results_df = pd.DataFrame(results).sort_values('pval')\n",
    "\n",
    "    # Plot: x=coefficient, y=-log10(p-value)\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # We add a small offset so we don't try to take log10 of 0\n",
    "    # In case any p-values are extremely small or exactly 0\n",
    "    offset = 1e-300\n",
    "    x_vals = results_df['coef']\n",
    "    y_vals = -np.log10(results_df['pval'] + offset)\n",
    "    \n",
    "    sc = ax.scatter(x_vals, y_vals, color='blue')\n",
    "    \n",
    "    # Annotate each point with the column name\n",
    "    for i, row in results_df.iterrows():\n",
    "        ax.text(row['coef'], -np.log10(row['pval'] + offset), row['column'],\n",
    "                fontsize=8, ha='left', va='bottom')\n",
    "\n",
    "    ax.axhline(-np.log10(0.05), color='red', linestyle='--', label='p=0.05')\n",
    "    ax.set_xlabel('Coefficient')\n",
    "    ax.set_ylabel('-log10(p-value)')\n",
    "    ax.set_title(f'Logistic Regressions for {outcome_col} ~ Each Predictor')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Usage:\n",
    "results_df = all_regressions_single_plot(neuraxial_catheter_df, 'failed_catheter')\n",
    "# results_df will have columns [column, coef, pval].\n",
    "# The plot shows each predictor's slope vs. its -log10(p-value).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only neuraxial catheter (ie, epidural + CSE + intrathecal) or epidural-only catheter procedures\n",
    "neuraxial_catheter_df = df[df['is_neuraxial_catheter'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = neuraxial_catheter_df\n",
    "\n",
    "# Drop columns with more than 80% missing values\n",
    "threshold = len(data) * 0.5\n",
    "data_cleaned = data.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Drop rows where target variable is missing\n",
    "data_cleaned = data_cleaned.dropna(subset=[\"failed_catheter\"])\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data_cleaned.drop(columns=[\"failed_catheter\", \"best_timestamp\"], errors='ignore')\n",
    "y = data_cleaned[\"failed_catheter\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                           ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing into a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Train logistic regression with class weights\n",
    "logistic_model = LogisticRegression(max_iter=1000, solver='liblinear', class_weight='balanced', n_jobs=1)\n",
    "logistic_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logistic_model.predict(X_test_preprocessed)\n",
    "y_pred_prob = logistic_model.predict_proba(X_test_preprocessed)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_pred_prob),\n",
    "    \"classification_report\": classification_report(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Model Evaluation:\")\n",
    "for metric, value in evaluation_metrics.items():\n",
    "    if metric == \"classification_report\":\n",
    "        print(\"\\nClassification Report:\\n\", value)\n",
    "    else:\n",
    "        print(f\"{metric.capitalize()}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
